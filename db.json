{"meta":{"version":1,"warehouse":"4.0.0"},"models":{"Asset":[{"_id":"source/CNAME","path":"CNAME","modified":0,"renderable":0},{"_id":"themes/next_8.8/source/js/bookmark.js","path":"js/bookmark.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/comments-buttons.js","path":"js/comments-buttons.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/config.js","path":"js/config.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/comments.js","path":"js/comments.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/motion.js","path":"js/motion.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/next-boot.js","path":"js/next-boot.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/pjax.js","path":"js/pjax.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/schedule.js","path":"js/schedule.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/utils.js","path":"js/utils.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/css/main.styl","path":"css/main.styl","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/css/noscript.styl","path":"css/noscript.styl","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/images/apple-touch-icon-next.png","path":"images/apple-touch-icon-next.png","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/images/avatar.gif","path":"images/avatar.gif","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/images/avatar.jpg","path":"images/avatar.jpg","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/images/avatar_100.jpg","path":"images/avatar_100.jpg","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/images/avatar_200.jpg","path":"images/avatar_200.jpg","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/images/avatar_300.jpg","path":"images/avatar_300.jpg","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/images/avatar_80.jpg","path":"images/avatar_80.jpg","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/images/avatar_500.jpg","path":"images/avatar_500.jpg","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/images/favicon-16x16-next.png","path":"images/favicon-16x16-next.png","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/images/favicon-32x32-next.png","path":"images/favicon-32x32-next.png","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/images/logo-algolia-nebula-blue-full.svg","path":"images/logo-algolia-nebula-blue-full.svg","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/images/logo.svg","path":"images/logo.svg","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/images/ye_16.ico","path":"images/ye_16.ico","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/images/ye_32.ico","path":"images/ye_32.ico","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/schemes/muse.js","path":"js/schemes/muse.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/third-party/fancybox.js","path":"js/third-party/fancybox.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/third-party/quicklink.js","path":"js/third-party/quicklink.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/third-party/pace.js","path":"js/third-party/pace.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/third-party/rating.js","path":"js/third-party/rating.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/third-party/analytics/baidu-analytics.js","path":"js/third-party/analytics/baidu-analytics.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/third-party/analytics/google-analytics.js","path":"js/third-party/analytics/google-analytics.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/third-party/analytics/growingio.js","path":"js/third-party/analytics/growingio.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/third-party/chat/chatra.js","path":"js/third-party/chat/chatra.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/third-party/chat/gitter.js","path":"js/third-party/chat/gitter.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/third-party/chat/tidio.js","path":"js/third-party/chat/tidio.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/third-party/comments/changyan.js","path":"js/third-party/comments/changyan.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/third-party/comments/disqus.js","path":"js/third-party/comments/disqus.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/third-party/comments/disqusjs.js","path":"js/third-party/comments/disqusjs.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/third-party/comments/gitalk.js","path":"js/third-party/comments/gitalk.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/third-party/comments/isso.js","path":"js/third-party/comments/isso.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/third-party/comments/livere.js","path":"js/third-party/comments/livere.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/third-party/comments/utterances.js","path":"js/third-party/comments/utterances.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/third-party/math/mathjax.js","path":"js/third-party/math/mathjax.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/third-party/math/katex.js","path":"js/third-party/math/katex.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/third-party/search/algolia-search.js","path":"js/third-party/search/algolia-search.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/third-party/search/local-search.js","path":"js/third-party/search/local-search.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/third-party/statistics/firestore.js","path":"js/third-party/statistics/firestore.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/third-party/statistics/lean-analytics.js","path":"js/third-party/statistics/lean-analytics.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/third-party/tags/mermaid.js","path":"js/third-party/tags/mermaid.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/third-party/tags/pdf.js","path":"js/third-party/tags/pdf.js","modified":0,"renderable":1}],"Cache":[{"_id":"source/CNAME","hash":"55c55444033af34e797e2d3cb1c1b4cf7889b3db","modified":1642412587966},{"_id":"source/_posts/An-Introduction-to-Git.md","hash":"5bffb32f7ea47f70f18c5367a9654afc2457ea19","modified":1642412587967},{"_id":"source/_posts/Algorithm.md","hash":"d3c8265f341b1f479f940fd01f845a33c26cbc93","modified":1642412587967},{"_id":"source/_posts/Construct-Your-Blog-with-Hexo-and-Github.md","hash":"294cabd5a5d7ece70c5bbbfeaa380867fab6ee67","modified":1642412587971},{"_id":"source/_posts/Config-Vim.md","hash":"3396d8bd3980b8136a768449bf5076df8af8fd3c","modified":1644305443760},{"_id":"source/_posts/Experiments.md","hash":"4ebc470b4e205051bacff945d720fdb46ebef582","modified":1642412587972},{"_id":"source/_posts/First-Step-to-RL.md","hash":"340b91cc1af7f8283e826cfe40fcf7725baa8fa8","modified":1642412587972},{"_id":"source/_posts/Foundation-for-Topological-Data-Analysis.md","hash":"c6a8f658f8e0195e4c2dff516c014dd89844ec04","modified":1642412587975},{"_id":"source/_posts/How-to-Blance-Losses-in-Multi-Task-Training.md","hash":"7ff02c2b270e746db8e333eedfad6cf3d8046440","modified":1642412587977},{"_id":"source/_posts/Personal-Thought.md","hash":"16a7b4ab87f88a826c506fff8c68e8bd123df18b","modified":1642412587977},{"_id":"source/_posts/Shorcut-on-Linux.md","hash":"976dea1004bb4676762551667c500cdee1a62db0","modified":1644546361098},{"_id":"source/_posts/Tips-in-Papers.md","hash":"1272658464982b4ab97e8805fd5a151b62675999","modified":1642412587978},{"_id":"source/_posts/Transformer-and-BERT.md","hash":"9b91961c25864f2d2849ebb5421700af045308b3","modified":1644312281330},{"_id":"source/about/index.md","hash":"9aab11db0791297a1fa5e1b1767eb3a05bfb42ef","modified":1642412587988},{"_id":"source/tags/index.md","hash":"3207ebf9794561395cf0c54633880ab070040ade","modified":1642412587990},{"_id":"source/categories/index.md","hash":"408ea9b07f3b1a1339731fe7b364d88bc5644aff","modified":1642412587989},{"_id":"source/_posts/First-Step-to-RL/q_learning.py","hash":"3a68ec1153d26f2c18c9d34ee5deb5e495b8dca9","modified":1642412587974},{"_id":"source/_posts/First-Step-to-RL/policy_network.py","hash":"b3e8f06360cad0084a0656edaed4539f1b01e327","modified":1642412587973},{"_id":"source/_posts/Tips-in-Papers/ADCM.jpg","hash":"ee5b75f3a063e07624c5f03111f98902d885cd8e","modified":1642412587979},{"_id":"source/_posts/Tips-in-Papers/Saccader_eq2.jpg","hash":"cf5832e89b29e39275d2fa4a2e39592e97f9a39e","modified":1642412587983},{"_id":"source/_posts/Tips-in-Papers/Saccader_gl.jpg","hash":"fb8050f8b71a7c667cfa85672b505b3340d2231b","modified":1642412587985},{"_id":"source/_posts/Tips-in-Papers/Saccader_eq3.jpg","hash":"8fa845242bb6f737736d91485ca237e7132e19b5","modified":1642412587984},{"_id":"source/_posts/Tips-in-Papers/Saccader_eq1.jpg","hash":"2ea2a74f960377a6a9d0bc98ecfadd8ba09cd316","modified":1642412587982},{"_id":"source/_posts/Tips-in-Papers/Saccader_Cell.jpg","hash":"b17e79bf86bb3422527bf51d200ceceeb53ce936","modified":1642412587980},{"_id":"source/_posts/Tips-in-Papers/Saccader_Over.jpg","hash":"deaccd942ffca9e163a9f2c9bdfb69251d1004cb","modified":1642412587981},{"_id":"source/_posts/Tips-in-Papers/Tnet_over.jpg","hash":"ed04ca4049c6f909b0bf51ea57ffa9a2b445e1c8","modified":1642412587986},{"_id":"source/_posts/An-Introduction-to-Git/git.jpg","hash":"db9ed8bb86df7e73d5be3bcae4cc8656e4a7a0ed","modified":1642412587970},{"_id":"themes/next_8.8/.editorconfig","hash":"8570735a8d8d034a3a175afd1dd40b39140b3e6a","modified":1642412590952},{"_id":"themes/next_8.8/.eslintrc.json","hash":"9c0762486f24a8c5e60f8b6c875e4c4728942649","modified":1642412590953},{"_id":"themes/next_8.8/.gitignore","hash":"417520c4dbbeab9c7e3ab10d944da0886366a0ee","modified":1642412590974},{"_id":"themes/next_8.8/.gitattributes","hash":"ec43734985e1cafd53d88ded3020103f7416123c","modified":1642412590955},{"_id":"themes/next_8.8/.stylintrc","hash":"2cf4d637b56d8eb423f59656a11f6403aa90f550","modified":1642412590974},{"_id":"themes/next_8.8/README.md","hash":"fab15a85d9d8d90ecd8879525b9b74fb1c197978","modified":1642412590976},{"_id":"themes/next_8.8/LICENSE.md","hash":"68fc9a03d50fd4b5ea97092b05967d1819dea2c4","modified":1642412590975},{"_id":"themes/next_8.8/_config.yml","hash":"7340c7dc0fca708749cabbe6fdf7bad82417e725","modified":1644499425227},{"_id":"themes/next_8.8/_vendors.yml","hash":"c88f3a82361ddb32cf62846a2ae1b7192b7e3af2","modified":1642412590977},{"_id":"themes/next_8.8/package.json","hash":"cc9a8e5bd83dd293552ed7cc1d0d2304a6b448ba","modified":1642412591062},{"_id":"themes/next_8.8/renovate.json","hash":"cb29cc16e61b0b8a6dac34657d76822ae29ad5aa","modified":1642412591063},{"_id":"themes/next_8.8/crowdin.yml","hash":"e026078448c77dcdd9ef50256bb6635a8f83dca6","modified":1642412590978},{"_id":"themes/next_8.8/.githooks/install.js","hash":"4d77dbddf2eac1f3fc78f151d12ed22208ed655b","modified":1642412590957},{"_id":"themes/next_8.8/.githooks/pre-commit","hash":"f473eac1aaaa96c947d67988bbed140bbab1a821","modified":1642412590957},{"_id":"themes/next_8.8/.github/CONTRIBUTING.md","hash":"330656d93b6c03df9fb1f2f0e3534c971969473b","modified":1642412590959},{"_id":"themes/next_8.8/.github/CODE_OF_CONDUCT.md","hash":"21cbff565a0445d3a880fff1ee417e309740a9ab","modified":1642412590958},{"_id":"themes/next_8.8/.github/issue_label_bot.yaml","hash":"fca600ddef6f80c5e61aeed21722d191e5606e5b","modified":1642412590965},{"_id":"themes/next_8.8/.github/config.yml","hash":"7984e665e9de481a0e0e51fca5668337713f810b","modified":1642412590964},{"_id":"themes/next_8.8/.github/PULL_REQUEST_TEMPLATE.md","hash":"3e9fbb78e3dee0ca1dc886d0c28b0148ba0ca499","modified":1642412590963},{"_id":"themes/next_8.8/.github/label-commenter-config.yml","hash":"1097fc47beeacfc1edb0248c27b17bf64bde3565","modified":1642412590965},{"_id":"themes/next_8.8/.github/labeler.yml","hash":"5c4bc2bd561e6d9b33ee118cc12218c5de46f72d","modified":1642412590966},{"_id":"themes/next_8.8/.github/release-drafter.yml","hash":"423275ec021104b263cd88776936a8c8d6872b66","modified":1642412590967},{"_id":"themes/next_8.8/docs/AGPL3.md","hash":"0d2b8c5fa8a614723be0767cc3bca39c49578036","modified":1642412590979},{"_id":"themes/next_8.8/docs/AUTHORS.md","hash":"a648823121563c34a177ae91f5a774b5e29f01a0","modified":1642412590980},{"_id":"themes/next_8.8/languages/ar.yml","hash":"bca66db21c015dbd32970d8708b898518a773e1e","modified":1642412590986},{"_id":"themes/next_8.8/docs/LICENSE.txt","hash":"f5b14f791b7cfa1d16da981d929152e088a5d1b8","modified":1642412590981},{"_id":"themes/next_8.8/languages/README.md","hash":"b2567e32805dda79601157351a07e5ca9fe01315","modified":1642412590986},{"_id":"themes/next_8.8/languages/de.yml","hash":"4be7b8b76c81bf1853eb36d2e874b17546a0e792","modified":1642412590987},{"_id":"themes/next_8.8/languages/default.yml","hash":"ea5e6aee4cb14510793ac4593a3bddffe23e530c","modified":1642412590988},{"_id":"themes/next_8.8/languages/en.yml","hash":"814d81c27fed736055ee300e0a6505b26ff4313c","modified":1642412590988},{"_id":"themes/next_8.8/languages/es.yml","hash":"651e3b33d86a7cdb9fd7895ca28279f8b1a24faa","modified":1642412590989},{"_id":"themes/next_8.8/languages/fa.yml","hash":"6456d40dd42f44101d9d6e7054e9884e9163f948","modified":1642412590990},{"_id":"themes/next_8.8/languages/id.yml","hash":"14e794db4eca36b257994d81eb513e61d1edcbd6","modified":1642412590991},{"_id":"themes/next_8.8/languages/ja.yml","hash":"d48c4157e0e02e847aac7b513580d3364c81948c","modified":1642412590993},{"_id":"themes/next_8.8/languages/fr.yml","hash":"b15dc05afdc94de02e5d3fee4f8d3dc5594dd37e","modified":1642412590991},{"_id":"themes/next_8.8/languages/ko.yml","hash":"6387357ac2dd498e8b8d630d27050a59180d7e8f","modified":1642412590993},{"_id":"themes/next_8.8/languages/nl.yml","hash":"ecb8e39c6225f3c068a5fdd569ee7dafd5c41a1f","modified":1642412590994},{"_id":"themes/next_8.8/languages/it.yml","hash":"c1eeab4992c76bfd436bb205ce58b1cfeef55ee6","modified":1642412590992},{"_id":"themes/next_8.8/languages/pt.yml","hash":"63a3e1e728ba5e6e22150de7331bb8a654f34960","modified":1642412590995},{"_id":"themes/next_8.8/languages/si.yml","hash":"615d18d044f44df476d6bfbf73f7b0edc2632168","modified":1642412590997},{"_id":"themes/next_8.8/languages/vi.yml","hash":"c669c34da544a563ceae3e196addc9df6a78e024","modified":1642412590999},{"_id":"themes/next_8.8/languages/ru.yml","hash":"e9af1afe529ca747a04b801401d394b2ad696fde","modified":1642412590996},{"_id":"themes/next_8.8/languages/tr.yml","hash":"0bebba73d6f06c7dad61f80c0d7ad5f6f1791a01","modified":1642412590997},{"_id":"themes/next_8.8/languages/pt-BR.yml","hash":"a1f27b3a592fc58f17d247f5563ff4a90a3da5f2","modified":1642412590995},{"_id":"themes/next_8.8/languages/uk.yml","hash":"7dd24580c0865c5a7bc4d391855045366a598936","modified":1642412590998},{"_id":"themes/next_8.8/languages/zh-CN.yml","hash":"5a3ab21210304efef736e96bad254f789f42c567","modified":1642412591000},{"_id":"themes/next_8.8/languages/zh-HK.yml","hash":"f195bb0502ffe66e850077a1af1033455ea65f93","modified":1642412591000},{"_id":"themes/next_8.8/languages/zh-TW.yml","hash":"92256b90028de9a1e79c6bc0e5885b93e7fb4b17","modified":1642412591001},{"_id":"themes/next_8.8/layout/index.njk","hash":"dd63e488ae8cc144335a5958acedf6a16edd7a92","modified":1642412591058},{"_id":"themes/next_8.8/layout/archive.njk","hash":"d759f4d2cf5ddc6875ea250113a00662c1caf6d1","modified":1642412591057},{"_id":"themes/next_8.8/layout/page.njk","hash":"6c40aa438c658eb7f0cd0f6a759f18b43e7e8f93","modified":1642412591059},{"_id":"themes/next_8.8/layout/_layout.njk","hash":"20e4160cd0deb4fa272cc3aed0f43520b3cf4a9c","modified":1642412591002},{"_id":"themes/next_8.8/layout/category.njk","hash":"c68b7343d0f8145010f93351908cc36ef6212ec1","modified":1642412591058},{"_id":"themes/next_8.8/layout/tag.njk","hash":"9e16ba20c28a7f2c6bc75aa427f48122301a30aa","modified":1642412591061},{"_id":"themes/next_8.8/layout/post.njk","hash":"6abeb85fb3e4c382ed4bb6049b12a807e6226e67","modified":1642412591060},{"_id":"themes/next_8.8/.github/ISSUE_TEMPLATE/config.yml","hash":"c40ae7903b6cc99f94c9d45ac7ba8c2850bb1309","modified":1642412590961},{"_id":"themes/next_8.8/.github/ISSUE_TEMPLATE/bug-report.md","hash":"fc4dce84ed9a5d21d3a8833ff6d776c46f876115","modified":1642412590960},{"_id":"themes/next_8.8/test/index.js","hash":"6bf0289846538be3e9a63809af98f00e1fbdd90b","modified":1642412591222},{"_id":"themes/next_8.8/.github/workflows/labeler.yml","hash":"8b73c439dc796be141d521a4546bcfb7a5485534","modified":1642412590969},{"_id":"themes/next_8.8/.github/ISSUE_TEMPLATE/other.md","hash":"8cc5b5c116f6a052865a324512362f145d699202","modified":1642412590963},{"_id":"themes/next_8.8/.github/ISSUE_TEMPLATE/feature-request.md","hash":"4ecac91716eac59d7c2bc53cf6e95612d44da97b","modified":1642412590962},{"_id":"themes/next_8.8/.github/workflows/label-commenter.yml","hash":"44405477660289d4ed9beba1d054b15bb67bba06","modified":1642412590968},{"_id":"themes/next_8.8/.github/workflows/linter.yml","hash":"276a91c7179926f410c784c99fa635dc0a016c2d","modified":1642412590970},{"_id":"themes/next_8.8/.github/workflows/lock.yml","hash":"e48d1ced9a673d3f0911a700d3e68c0f4ca79263","modified":1642412590971},{"_id":"themes/next_8.8/.github/workflows/stale.yml","hash":"0feb3e1afd1b2dca9dbc7811ce4cf5520e2d186c","modified":1642412590972},{"_id":"themes/next_8.8/.github/workflows/release-drafter.yml","hash":"4f3af81009cb922be91f718a67425377515ea69d","modified":1642412590972},{"_id":"themes/next_8.8/docs/ru/README.md","hash":"87edab5a3eb7577a409c01df3f1631de40f8956f","modified":1642412590982},{"_id":"themes/next_8.8/.github/workflows/tester.yml","hash":"22aaaa3eba1a7ebcf0f78417fd9a7113ee7b6c6c","modified":1642412590973},{"_id":"themes/next_8.8/docs/zh-CN/CODE_OF_CONDUCT.md","hash":"7a06d443f374bd1e84294067a0ac796afd9fbe60","modified":1642412590983},{"_id":"themes/next_8.8/docs/zh-CN/CONTRIBUTING.md","hash":"a089f7a8368ab0b7d7b9b7ec0ac3767a453435df","modified":1642412590984},{"_id":"themes/next_8.8/docs/zh-CN/README.md","hash":"02bafc6ee86263790603861e356596f0c916e392","modified":1642412590984},{"_id":"themes/next_8.8/layout/_macro/post-collapse.njk","hash":"1a30d751871dabfa80940042ddb1f77d07d830b9","modified":1642412591003},{"_id":"themes/next_8.8/layout/_macro/sidebar.njk","hash":"a1575da8a34d7b7b8cf37e23ffb5d0ed2edee0fe","modified":1642412591005},{"_id":"themes/next_8.8/layout/_macro/sidebar.njk_backup","hash":"eb786e8b35e354287cda345c524cd35ec955f692","modified":1642412591006},{"_id":"themes/next_8.8/layout/_partials/comments.njk","hash":"c12f8a7497596441503f2541d2f746f2ee7dd594","modified":1642412591007},{"_id":"themes/next_8.8/layout/_macro/post.njk","hash":"d0ed41b9b05254e19d051b5f91fdcaa125ee7ca6","modified":1642412591004},{"_id":"themes/next_8.8/layout/_partials/languages.njk","hash":"e43f22198cccb5f6e306b1ce0d28d12a4fb891f8","modified":1642412591014},{"_id":"themes/next_8.8/layout/_partials/footer.njk","hash":"a6197cc0d418d87919f929905a5e90e21b969ffa","modified":1642412591008},{"_id":"themes/next_8.8/layout/_partials/pagination.njk","hash":"9876dbfc15713c7a47d4bcaa301f4757bd978269","modified":1642412591018},{"_id":"themes/next_8.8/layout/_third-party/fancybox.njk","hash":"844559f46e2ff1c8be234d5763703106e2072a7b","modified":1642412591042},{"_id":"themes/next_8.8/layout/_partials/widgets.njk","hash":"852a750524decf1efa587cd52b09e387ed8315de","modified":1642412591027},{"_id":"themes/next_8.8/layout/_scripts/vendors.njk","hash":"be80b9fe415a9a09d74c28e230995fd292dfc123","modified":1642412591029},{"_id":"themes/next_8.8/layout/_scripts/index.njk","hash":"6668878a0f9a1166c6a879755f54a08d942da870","modified":1642412591028},{"_id":"themes/next_8.8/layout/_third-party/pace.njk","hash":"d7ad5714079f7f65446f880baf14722435ca9061","modified":1642412591046},{"_id":"themes/next_8.8/layout/_third-party/index.njk","hash":"d41eeb262978e34de4679d8971a9e7ac5d90ecbc","modified":1642412591043},{"_id":"themes/next_8.8/layout/_third-party/rating.njk","hash":"1bcdbc7fde26d6d9ef4e7fa43ffcff5a9506b20e","modified":1642412591048},{"_id":"themes/next_8.8/layout/_third-party/quicklink.njk","hash":"0efed71ed530447718c4ea5bbd5fc8695b0b0d5f","modified":1642412591047},{"_id":"themes/next_8.8/scripts/helpers/engine.js","hash":"b9785bc737470e9b8e910e7da9e8c45c2ead58fa","modified":1642412591082},{"_id":"themes/next_8.8/scripts/helpers/font.js","hash":"3394185a7f0393c16ce52c8028f90da3e9239c55","modified":1642412591082},{"_id":"themes/next_8.8/scripts/events/index.js","hash":"1ce12eda88fa5df7e76ec7b78b8463fc6618410c","modified":1642412591065},{"_id":"themes/next_8.8/scripts/helpers/next-url.js","hash":"a11b71ba0c5012e2cdcab31c15439156b215563e","modified":1642412591084},{"_id":"themes/next_8.8/scripts/helpers/next-config.js","hash":"9a07f2d979fc8fe0c5e07d48304187b9b03ea7ff","modified":1642412591083},{"_id":"themes/next_8.8/scripts/helpers/next-vendors.js","hash":"afdd6a188a74c188f0dd154fac70efd4080ca262","modified":1642412591084},{"_id":"themes/next_8.8/scripts/filters/minify.js","hash":"0af64049db8188d5f8cc226b353e0d7909819feb","modified":1642412591080},{"_id":"themes/next_8.8/scripts/filters/locals.js","hash":"0cd7da6755459d60779f0a7ccf311e26e184d55d","modified":1642412591079},{"_id":"themes/next_8.8/scripts/filters/default-injects.js","hash":"872f01cb10e422a648ea505436532e776e92926b","modified":1642412591078},{"_id":"themes/next_8.8/scripts/tags/button.js","hash":"c6ad2ed544fbb25ecb5d820c36e76302504271b7","modified":1642412591086},{"_id":"themes/next_8.8/scripts/filters/post.js","hash":"ab8bb12e4d55640b1ac4252514468ce37ebcb0b0","modified":1642412591081},{"_id":"themes/next_8.8/scripts/tags/group-pictures.js","hash":"9ed799c329abf830f623689d7e136991256a24ca","modified":1642412591088},{"_id":"themes/next_8.8/scripts/tags/center-quote.js","hash":"92c19d796bdb3320df9caea59bf52df7a95d9da9","modified":1642412591087},{"_id":"themes/next_8.8/scripts/tags/caniuse.js","hash":"935a311142a409c1896b3ae3f01fe7a9e2db1134","modified":1642412591087},{"_id":"themes/next_8.8/scripts/filters/number.js","hash":"63735cb9d02921e25b2606490340a70db89abbec","modified":1642412591080},{"_id":"themes/next_8.8/scripts/tags/index.js","hash":"17f9451ce1f10f78437f52218757d38d4e1591b0","modified":1642412591088},{"_id":"themes/next_8.8/scripts/tags/link-grid.js","hash":"18a483c2d5afd701f6080ffdddf2d1321370336c","modified":1642412591090},{"_id":"themes/next_8.8/scripts/tags/pdf.js","hash":"344636b6fd7e27e8831c1e194039afc0d61931cd","modified":1642412591092},{"_id":"themes/next_8.8/scripts/tags/tabs.js","hash":"0eabe51da40b4b13e16419c8fe02452d9a4fef73","modified":1642412591094},{"_id":"themes/next_8.8/scripts/tags/label.js","hash":"8a73348186113bae0a51ea2f891c1bb882fab05a","modified":1642412591089},{"_id":"themes/next_8.8/scripts/tags/mermaid.js","hash":"4fb01ca650fa8b256b8d48f50dc1b18350bd3d6d","modified":1642412591090},{"_id":"themes/next_8.8/scripts/tags/note.js","hash":"7b94ddb46b7d4b0fe815f2fbe4bd375f07f55363","modified":1642412591091},{"_id":"themes/next_8.8/scripts/tags/video.js","hash":"2ee926448583be8f95af1f2884ae2c9c4830151d","modified":1642412591094},{"_id":"themes/next_8.8/test/tags/button.js","hash":"48f2aa4c513e9e24bd6a811410520b74cd7ea88b","modified":1642412591223},{"_id":"themes/next_8.8/test/helpers/next-url.js","hash":"a91d880cb75e0a8e65a7be4c7362b2c8ebfb7c4f","modified":1642412591222},{"_id":"themes/next_8.8/test/helpers/font.js","hash":"342ef3c6fd2dcca2a8802a516ed6d7f389fd2ca2","modified":1642412591221},{"_id":"themes/next_8.8/test/tags/caniuse.js","hash":"aa5e728445caeaf7c2ccd0f3fcb2cad0c93ca6d1","modified":1642412591224},{"_id":"themes/next_8.8/test/validate/index.js","hash":"5a95ccc8598667535bd022e988055c0e019f3670","modified":1642412591231},{"_id":"themes/next_8.8/test/tags/index.js","hash":"e8779e54f0979b221858f8bb74dd081bb503b910","modified":1642412591225},{"_id":"themes/next_8.8/test/tags/center-quote.js","hash":"7667342fd1a1417eaf6a254012b84ae40e8d13dd","modified":1642412591224},{"_id":"themes/next_8.8/test/helpers/index.js","hash":"63ba28afed697f7b3574436b1133b8ecc9c0c357","modified":1642412591221},{"_id":"themes/next_8.8/test/tags/group-pictures.js","hash":"5c68ae0184f9da6e00ba199f2554d503d8e6da71","modified":1642412591225},{"_id":"themes/next_8.8/test/tags/mermaid.js","hash":"ab77be5f3c6d9a57c7b9dda6decf1906a736fef9","modified":1642412591227},{"_id":"themes/next_8.8/test/tags/label.js","hash":"4ebf3698c258ca978b997acbdd0dece44069c09d","modified":1642412591226},{"_id":"themes/next_8.8/test/tags/note.js","hash":"3dcfcd65bf9f326972ea7571fdb1444200f5d07e","modified":1642412591228},{"_id":"themes/next_8.8/test/tags/pdf.js","hash":"fd6ea5123560a90f7e7c1eface23dbe1455db25f","modified":1642412591229},{"_id":"themes/next_8.8/test/tags/link-grid.js","hash":"43d298fafb7c45a874b766d443843bd26346e689","modified":1642412591226},{"_id":"themes/next_8.8/test/tags/video.js","hash":"b796fc4dceb20a30e730c322bb5474c0162464cc","modified":1642412591230},{"_id":"themes/next_8.8/source/js/bookmark.js","hash":"0f563ffbf05fad30e854e413ab17ff7164ab5a53","modified":1642412591191},{"_id":"themes/next_8.8/source/js/comments-buttons.js","hash":"1a7344440321713426a0b2ab17e276b5bdf85ade","modified":1642412591192},{"_id":"themes/next_8.8/source/js/config.js","hash":"4c4ebbe3b3f3841a26f9d5af6d0ba8bc6da01c54","modified":1642412591194},{"_id":"themes/next_8.8/source/js/motion.js","hash":"9c4c861dfb080b6244d4d9eba33ac686735754f3","modified":1642412591195},{"_id":"themes/next_8.8/test/tags/tabs.js","hash":"d63722919f9da2e44d6b952801e10a2915ea9c12","modified":1642412591230},{"_id":"themes/next_8.8/source/js/pjax.js","hash":"919f5281c4a04d11cfd94573ecf57b3dbabd3cc8","modified":1642412591196},{"_id":"themes/next_8.8/source/css/_colors.styl","hash":"3c6798c10cc220d83481cb3f3782e78558cee789","modified":1642412591096},{"_id":"themes/next_8.8/source/js/next-boot.js","hash":"48497e2156a10155dc42311633a110c9685692c9","modified":1642412591196},{"_id":"themes/next_8.8/source/css/noscript.styl","hash":"76bba5d7916e9930e68215a0fce3a7d81c44510f","modified":1642412591172},{"_id":"themes/next_8.8/source/js/utils.js","hash":"e447160d342b1f93df5214b6a733441039ced439","modified":1642412591220},{"_id":"themes/next_8.8/source/js/schedule.js","hash":"2b43e2d576a308289880befc27580dbb2aa34439","modified":1642412591197},{"_id":"themes/next_8.8/source/js/comments.js","hash":"66ae2e26ea36a41b72c638ea8b220296638ae952","modified":1642412591193},{"_id":"themes/next_8.8/source/css/_mixins.styl","hash":"acef5acc728f24cb657be8d7010d836b4d556b0e","modified":1642412591151},{"_id":"themes/next_8.8/source/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1642412591173},{"_id":"themes/next_8.8/source/images/avatar.gif","hash":"2dbc3e2f2d624b2ca1afe6edc2ca17307f1950c8","modified":1642412591174},{"_id":"themes/next_8.8/source/css/main.styl","hash":"78ce791cc4ac95386cf6839ca72f5f7b51f86ee9","modified":1642412591171},{"_id":"themes/next_8.8/source/images/avatar_100.jpg","hash":"a0f0a00c9326c57a5cc181aeb80dfda8e947920a","modified":1642412591176},{"_id":"themes/next_8.8/source/images/avatar_80.jpg","hash":"465e53598964df3852f08794cb73c5e459855e92","modified":1642412591180},{"_id":"themes/next_8.8/source/images/avatar_200.jpg","hash":"4a76d1527e511350c9112e899046a34be59ad278","modified":1642412591176},{"_id":"themes/next_8.8/source/images/logo-algolia-nebula-blue-full.svg","hash":"b85e274207b1392782476a0430feac98db1e7da0","modified":1642412591184},{"_id":"themes/next_8.8/source/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1642412591182},{"_id":"themes/next_8.8/source/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1642412591181},{"_id":"themes/next_8.8/source/images/ye_16.ico","hash":"b8fb01b5361da89831d232a831a1532e9822bd72","modified":1642412591187},{"_id":"themes/next_8.8/source/images/logo.svg","hash":"2cb74fd3ea2635e015eabc58a8d488aed6cf6417","modified":1642412591185},{"_id":"themes/next_8.8/source/images/ye_32.ico","hash":"375c99cd785d93dd989c36604ffbd10ada71322a","modified":1642412591190},{"_id":"themes/next_8.8/layout/_partials/header/index.njk","hash":"650de421a8ce4cf685428ffbe0087ff84cbd1356","modified":1642412591011},{"_id":"themes/next_8.8/layout/_partials/head/head-unique.njk","hash":"9167e429a459686c9fc140790124a46d677e6b15","modified":1642412591009},{"_id":"themes/next_8.8/layout/_partials/header/menu-item.njk","hash":"b46f412c0b4f775fd329d50357f722f5d7c1a3ba","modified":1642412591012},{"_id":"themes/next_8.8/layout/_partials/head/head.njk","hash":"d3c094aaef1431fbc9df333529a7b1789ccd134c","modified":1642412591009},{"_id":"themes/next_8.8/layout/_partials/header/brand.njk","hash":"aff4613756456be26415febc668860fdab8d33c5","modified":1642412591010},{"_id":"themes/next_8.8/layout/_partials/page/page-header.njk","hash":"7ed4f102a1825195cff8d7995bf9219f323a9034","modified":1642412591016},{"_id":"themes/next_8.8/layout/_partials/header/menu.njk","hash":"8561e4125b227e5134cb058e2a76fb2e5233ca29","modified":1642412591012},{"_id":"themes/next_8.8/layout/_partials/page/categories.njk","hash":"17156d99941f28a225951ffdcfa9a115e20dc2d2","modified":1642412591015},{"_id":"themes/next_8.8/layout/_partials/header/sub-menu.njk","hash":"75a158a5b54a3a76ee6590f5e0e2dd4a9f0be869","modified":1642412591013},{"_id":"themes/next_8.8/layout/_partials/page/tags.njk","hash":"a18d1598e36cc72f2b0b24c3cc3c5990dfaa3254","modified":1642412591018},{"_id":"themes/next_8.8/layout/_partials/page/schedule.njk","hash":"ca2ccf3cf1874c45712f192ad45dea96fbd9920d","modified":1642412591017},{"_id":"themes/next_8.8/layout/_partials/post/post-copyright.njk","hash":"133942922e34abae9e4de7ea5591d77c0caa4b37","modified":1642412591020},{"_id":"themes/next_8.8/layout/_partials/page/breadcrumb.njk","hash":"edb3bb6d644b7407673c5ef3a426a244e98fcf89","modified":1642412591015},{"_id":"themes/next_8.8/layout/_partials/post/post-footer.njk","hash":"bde2c7356d9362972bde41cc206d5816f8ed714d","modified":1642412591021},{"_id":"themes/next_8.8/layout/_partials/post/post-meta.njk","hash":"9fa47e4fb342811da590ee4adc91cf81118c0a39","modified":1642412591022},{"_id":"themes/next_8.8/layout/_partials/post/post-related.njk","hash":"7384e6390067ef2a84e7310d6adb3f6104ed62e2","modified":1642412591022},{"_id":"themes/next_8.8/layout/_partials/post/post-followme.njk","hash":"154df0bb323c332d8c25343f258ee865e5553423","modified":1642412591020},{"_id":"themes/next_8.8/layout/_partials/post/post-reward.njk","hash":"002b51d0cae3f2e2e008bdc58be90c728282de5b","modified":1642412591023},{"_id":"themes/next_8.8/layout/_partials/search/index.njk","hash":"8f6f256ab3b351ffc80f1f3f1d9834e9a7cfac31","modified":1642412591025},{"_id":"themes/next_8.8/layout/_partials/search/localsearch.njk","hash":"661f7acae43f0be694266323320f977d84119abe","modified":1642412591026},{"_id":"themes/next_8.8/layout/_partials/sidebar/site-overview.njk","hash":"3d8591bb92df77ceb9d5b07bc76da1ca89e5bd76","modified":1642412591026},{"_id":"themes/next_8.8/layout/_partials/search/algolia-search.njk","hash":"efb2b6f19df02ba5ae623a1f274fff52aed21e6f","modified":1642412591024},{"_id":"themes/next_8.8/layout/_third-party/analytics/baidu-analytics.njk","hash":"6215309aee028dcb734452beec448c5afb6c63fc","modified":1642412591030},{"_id":"themes/next_8.8/layout/_third-party/analytics/google-analytics.njk","hash":"d89066ff53879693f023e540d59c86137172c529","modified":1642412591031},{"_id":"themes/next_8.8/layout/_third-party/analytics/cloudflare.njk","hash":"c978e9efd472c4825f93b83524b11f1c4f7efaab","modified":1642412591030},{"_id":"themes/next_8.8/layout/_third-party/analytics/index.njk","hash":"2d36a481a70d5f450f1f166dc556ac1218b18537","modified":1642412591032},{"_id":"themes/next_8.8/layout/_third-party/chat/chatra.njk","hash":"d7263fca16d0278ccf1f6aa1c6df6902a6344a09","modified":1642412591033},{"_id":"themes/next_8.8/layout/_third-party/analytics/growingio.njk","hash":"8afaa772c390bd9d53a5cff9645ac3168334eb98","modified":1642412591032},{"_id":"themes/next_8.8/layout/_third-party/chat/gitter.njk","hash":"f8cc14b7aa949999a1faaeb7855e2f20b59a386d","modified":1642412591034},{"_id":"themes/next_8.8/layout/_third-party/comments/changyan.njk","hash":"d1c950f8fbdf85e7a3eae5463767a89e858e8220","modified":1642412591035},{"_id":"themes/next_8.8/layout/_third-party/comments/disqus.njk","hash":"9375b19a89b7fa9474e558d085af5448d4c5c50c","modified":1642412591036},{"_id":"themes/next_8.8/layout/_third-party/chat/tidio.njk","hash":"02aab857c27fc103216029be991688b12a73a525","modified":1642412591034},{"_id":"themes/next_8.8/layout/_third-party/comments/isso.njk","hash":"64cc3bdaf644fd32c0d0a247f29f5b6904da9af3","modified":1642412591039},{"_id":"themes/next_8.8/layout/_third-party/comments/gitalk.njk","hash":"b63b7e2ede0d3e66e732fa1a06bda9b19e1e85d4","modified":1642412591039},{"_id":"themes/next_8.8/layout/_third-party/comments/disqusjs.njk","hash":"0749cb6902baecdfd01f779a2a2513f6d2f6a823","modified":1642412591038},{"_id":"themes/next_8.8/layout/_third-party/comments/utterances.njk","hash":"5a94032bc3512a10ad4328fc19ec07b819a1d687","modified":1642412591041},{"_id":"themes/next_8.8/layout/_third-party/math/katex.njk","hash":"d82c24136bbd3443b85f07f5579845833b594684","modified":1642412591045},{"_id":"themes/next_8.8/layout/_third-party/comments/livere.njk","hash":"3b13b09fba84ec6000886890a6710736a2b8fafe","modified":1642412591040},{"_id":"themes/next_8.8/layout/_third-party/math/index.njk","hash":"abf37fc55aa86702118e8fdf5bf2d389dd589aa0","modified":1642412591044},{"_id":"themes/next_8.8/layout/_third-party/search/algolia-search.njk","hash":"24ed76e0c72a25ac152820c750a05826a706b6f4","modified":1642412591049},{"_id":"themes/next_8.8/layout/_third-party/statistics/lean-analytics.njk","hash":"2446e748cdc102c78492216319ac02148db7daf6","modified":1642412591054},{"_id":"themes/next_8.8/layout/_third-party/math/mathjax.njk","hash":"3677017fd4572b158311f5f5d870590ab25184e0","modified":1642412591045},{"_id":"themes/next_8.8/layout/_third-party/search/localsearch.njk","hash":"e45ea3542cdc9ed7ec8447b5e6f35df4c5e82758","modified":1642412591050},{"_id":"themes/next_8.8/layout/_third-party/statistics/busuanzi-counter.njk","hash":"a4bc501da0f22f7e420f0ca47e83988ce90b1368","modified":1642412591051},{"_id":"themes/next_8.8/layout/_third-party/tags/pdf.njk","hash":"2c81984cc4f5123103460442f6e046f5b6c97127","modified":1642412591056},{"_id":"themes/next_8.8/layout/_third-party/tags/mermaid.njk","hash":"099e031f52fb8e47b3af5b2684737efc9e643ee7","modified":1642412591055},{"_id":"themes/next_8.8/layout/_third-party/statistics/firestore.njk","hash":"d32ebe94560fa95824478ebbff531bffc47b194d","modified":1642412591052},{"_id":"themes/next_8.8/scripts/events/lib/highlight.js","hash":"6aec7b2c38c50989a23bfaa0d560e75c7f553e12","modified":1642412591067},{"_id":"themes/next_8.8/scripts/events/lib/config.js","hash":"b0ced2583fdd505da3ef27a9db9c55cc7b936732","modified":1642412591066},{"_id":"themes/next_8.8/scripts/events/lib/utils.js","hash":"b281be775b693f9bf32766c8f6ef703c72ac9b00","modified":1642412591068},{"_id":"themes/next_8.8/layout/_third-party/statistics/index.njk","hash":"568ddf7955d11d93fb5e842b403a7ac8b1b7fdb1","modified":1642412591053},{"_id":"themes/next_8.8/scripts/events/lib/vendors.js","hash":"08dac57e15c9f06c7cf54884b045f2362595f9d2","modified":1642412591069},{"_id":"themes/next_8.8/scripts/events/lib/injects.js","hash":"d987709267a1bc6e5014411e9983d7c49c102c16","modified":1642412591067},{"_id":"themes/next_8.8/scripts/filters/comment/default-config.js","hash":"93ee5f9109dad885dc38c49bcee630c10f9dce6e","modified":1642412591072},{"_id":"themes/next_8.8/scripts/filters/comment/disqusjs.js","hash":"135b87d151055eefdbc711d9e704b112b3214a84","modified":1642412591074},{"_id":"themes/next_8.8/scripts/filters/comment/common.js","hash":"2486f3e0150c753e5f3af1a3665d074704b8ee2c","modified":1642412591071},{"_id":"themes/next_8.8/scripts/filters/comment/changyan.js","hash":"aa05e6b3d613a756178b8ba06832ad27499d4c14","modified":1642412591071},{"_id":"themes/next_8.8/scripts/filters/comment/gitalk.js","hash":"7bb7dafdd7f6bca8464b54e17e552ce7f1714195","modified":1642412591075},{"_id":"themes/next_8.8/scripts/filters/comment/disqus.js","hash":"7f71d6b271ba65ff333d5682e7575711d368c0d2","modified":1642412591073},{"_id":"themes/next_8.8/scripts/filters/comment/livere.js","hash":"5a07d8bb52bc1d51a624ca8db54be144566c306b","modified":1642412591076},{"_id":"themes/next_8.8/scripts/filters/comment/isso.js","hash":"ff8b5b5145220a17d0ecd9508ba9bd2d3b2da47d","modified":1642412591076},{"_id":"themes/next_8.8/source/js/third-party/quicklink.js","hash":"6f58cd7aa8f6f1ab92d5a96551add293f4e55312","modified":1642412591214},{"_id":"themes/next_8.8/scripts/filters/comment/utterances.js","hash":"d3bded697bc32dace689d2a6dfb6eb7514169d15","modified":1642412591078},{"_id":"themes/next_8.8/source/js/third-party/pace.js","hash":"0ef04218b93561ba4d0ff420d556c3d90a756d32","modified":1642412591213},{"_id":"themes/next_8.8/source/js/schemes/muse.js","hash":"9a836d2bcc3defe4bd1ee51f5f4eb7006ebdd41b","modified":1642412591199},{"_id":"themes/next_8.8/source/js/third-party/fancybox.js","hash":"c098d14e65dd170537134358d4b8359ad0539c2c","modified":1642412591210},{"_id":"themes/next_8.8/source/js/third-party/rating.js","hash":"4e92c2d107ba47b47826829f9668030d5ea9bfb8","modified":1642412591214},{"_id":"themes/next_8.8/source/css/_variables/Gemini.styl","hash":"96e0a7c2a65ce68215e17e369085b2ea2f1334f2","modified":1642412591167},{"_id":"themes/next_8.8/source/css/_variables/Mist.styl","hash":"e1fbf169b9b6a194b518240cbd06ec3c48b83d61","modified":1642412591168},{"_id":"themes/next_8.8/source/css/_variables/Pisces.styl","hash":"c65536a128b9bc9dbe2fbb1b235a3cded2891002","modified":1642412591170},{"_id":"themes/next_8.8/source/js/third-party/analytics/baidu-analytics.js","hash":"f629acc46ff40c071ffd31b77d5c7616f0fdd778","modified":1642412591200},{"_id":"themes/next_8.8/source/css/_variables/Muse.styl","hash":"e3be898f5ebcf435a26542653a9297ff2c71aeb0","modified":1642412591169},{"_id":"themes/next_8.8/source/js/third-party/analytics/google-analytics.js","hash":"59684383385059dc4f8a1ff85dbbeb703bcdbcb5","modified":1642412591201},{"_id":"themes/next_8.8/source/css/_variables/base.styl","hash":"163c7441d777bee87042d475e6ce0fde199add28","modified":1642412591170},{"_id":"themes/next_8.8/source/js/third-party/analytics/growingio.js","hash":"78dd3cf04082b7dbe6246e404b2aa8e726922402","modified":1642412591202},{"_id":"themes/next_8.8/source/js/third-party/chat/chatra.js","hash":"c32180522788c10e51df1803aa6842ef0432ddc9","modified":1642412591203},{"_id":"themes/next_8.8/source/js/third-party/chat/tidio.js","hash":"b0079f6a4601e06ca6fe46e83a2f5af553e9bc3c","modified":1642412591204},{"_id":"themes/next_8.8/source/js/third-party/comments/disqus.js","hash":"e1cc671b0d524864fd445e3ab4ade9ee6d07e565","modified":1642412591206},{"_id":"themes/next_8.8/source/js/third-party/comments/disqusjs.js","hash":"b6c58f098473b526d6a3cd35655caf34b77f7cff","modified":1642412591207},{"_id":"themes/next_8.8/source/js/third-party/chat/gitter.js","hash":"cc38c94125f90dadde11b5ebac7d8bf99a1a08a2","modified":1642412591204},{"_id":"themes/next_8.8/source/js/third-party/comments/changyan.js","hash":"8c8ebec444c727b704ea41ad88b0b96ed2e4b8d4","modified":1642412591205},{"_id":"themes/next_8.8/source/js/third-party/comments/utterances.js","hash":"f67f90eb03e284c82da2b8cf2f1e31801813c16d","modified":1642412591210},{"_id":"themes/next_8.8/source/js/third-party/comments/livere.js","hash":"2247d88c934c765c43013337860774aaa99f0b31","modified":1642412591209},{"_id":"themes/next_8.8/source/js/third-party/comments/gitalk.js","hash":"0ec038cf83e8ec067534f16a54041e47a3c1e59a","modified":1642412591207},{"_id":"themes/next_8.8/source/js/third-party/comments/isso.js","hash":"753a873b6f566aff5ba77ca23f91b78eb880ca64","modified":1642412591208},{"_id":"themes/next_8.8/source/js/third-party/math/mathjax.js","hash":"5c749b9c1c3bb738122d0516211ecff6496d4907","modified":1642412591212},{"_id":"themes/next_8.8/source/js/third-party/search/algolia-search.js","hash":"ac401e3736d56a3c9cb85ab885744cce0b813c55","modified":1642412591215},{"_id":"themes/next_8.8/source/js/third-party/math/katex.js","hash":"83c54ee536e487a1031783443fe0cb63b1b4767e","modified":1642412591211},{"_id":"themes/next_8.8/source/js/third-party/statistics/lean-analytics.js","hash":"5a928990856b8e456f0663cf3b6b406733672e39","modified":1642412591217},{"_id":"themes/next_8.8/source/js/third-party/search/local-search.js","hash":"45c485f82258d246f37deb66884bd2643323ef3a","modified":1642412591216},{"_id":"themes/next_8.8/source/js/third-party/tags/mermaid.js","hash":"3dc4628efa6debd6490fc0ebddff2424a7b319d8","modified":1642412591218},{"_id":"themes/next_8.8/source/js/third-party/statistics/firestore.js","hash":"0960f16107ed61452fb0dffc6ed22dc143de34ef","modified":1642412591217},{"_id":"themes/next_8.8/source/css/_common/components/index.styl","hash":"fe1868f47681e00a33a96199302be85377282f63","modified":1642412591098},{"_id":"themes/next_8.8/source/css/_common/components/back-to-top.styl","hash":"bab653bcf226311381e8411a0492202f1bf1fce9","modified":1642412591097},{"_id":"themes/next_8.8/source/js/third-party/tags/pdf.js","hash":"af78c22f0e61c8c8aa8794e585e0d632c6d4fcb8","modified":1642412591219},{"_id":"themes/next_8.8/source/css/_common/components/reading-progress.styl","hash":"90a86045a33c1bae49fc2f6fa1e1b53170c7f77b","modified":1642412591111},{"_id":"themes/next_8.8/source/css/_common/scaffolding/base.styl","hash":"0805d7db96b6c83b31e8d023d1ae88f6d2969133","modified":1642412591135},{"_id":"themes/next_8.8/source/css/_common/outline/mobile.styl","hash":"64775c729512b30b144ab5ae9dc4a4dfd4e13f35","modified":1642412591126},{"_id":"themes/next_8.8/source/css/_common/scaffolding/buttons.styl","hash":"a042571d85ff7265f799004239a45f36b716b8a6","modified":1642412591138},{"_id":"themes/next_8.8/source/css/_common/outline/index.styl","hash":"8e34df131830d4fa3725e4590a672ba1cf1903e5","modified":1642412591125},{"_id":"themes/next_8.8/source/css/_common/scaffolding/comments.styl","hash":"e4fecc889ba3317a64e9abba5842c79dff9b7827","modified":1642412591139},{"_id":"themes/next_8.8/source/css/_common/scaffolding/index.styl","hash":"523fb7b653b87ae37fc91fc8813e4ffad87b0d7e","modified":1642412591142},{"_id":"themes/next_8.8/source/css/_common/scaffolding/normalize.styl","hash":"b56367ea676ea8e8783ea89cd4ab150c7da7a060","modified":1642412591143},{"_id":"themes/next_8.8/source/css/_common/scaffolding/pagination.styl","hash":"b5c7782368889fa9fd93807d28ff2daf270e3703","modified":1642412591143},{"_id":"themes/next_8.8/source/css/_common/scaffolding/base.styl_backup","hash":"d0a7c99095f490b0d2ed6b1be43d435960798cec","modified":1642412591136},{"_id":"themes/next_8.8/source/css/_common/scaffolding/tables.styl","hash":"e840b23d33023e6d45e018f6e84b683dd56efd8d","modified":1642412591144},{"_id":"themes/next_8.8/source/css/_schemes/Gemini/index.styl","hash":"fd49b521d67eaccc629f77b4e095cb7310327565","modified":1642412591153},{"_id":"themes/next_8.8/source/css/_common/scaffolding/toggles.styl","hash":"572a41499391677d84b16d8dbd6a996a3d5ce041","modified":1642412591150},{"_id":"themes/next_8.8/source/css/_schemes/Mist/_layout.styl","hash":"5604ac1e161099a4d3e5657d53507268866dc717","modified":1642412591154},{"_id":"themes/next_8.8/source/css/_schemes/Mist/_posts-expand.styl","hash":"b332868d76d9f1651efd65abfc0d3c9d699b1a45","modified":1642412591156},{"_id":"themes/next_8.8/source/css/_schemes/Mist/_header.styl","hash":"4817e77577896ab5c0da434549917ee703a3f4cf","modified":1642412591154},{"_id":"themes/next_8.8/source/css/_schemes/Mist/index.styl","hash":"ab16a3dcdc0393b9b582ef59dcc13db9320e917c","modified":1642412591157},{"_id":"themes/next_8.8/source/css/_schemes/Mist/_menu.styl","hash":"357b899ac0f0dfbbbebf1ea972030c7cefa463ce","modified":1642412591156},{"_id":"themes/next_8.8/source/css/_schemes/Muse/_layout.styl","hash":"82a29572dd90451f75358a2ee2522b87304a0bb8","modified":1642412591159},{"_id":"themes/next_8.8/source/css/_schemes/Muse/_menu.styl","hash":"8a70d51d8f7cd113e5fbc9f0e70c46a072f282c8","modified":1642412591159},{"_id":"themes/next_8.8/source/css/_schemes/Muse/_header.styl","hash":"06080fd963c904d96c00eff098a284e337953013","modified":1642412591158},{"_id":"themes/next_8.8/source/css/_schemes/Muse/_sidebar.styl","hash":"944364893bd7160d954c10ba931af641c91515a4","modified":1642412591160},{"_id":"themes/next_8.8/source/css/_schemes/Pisces/_layout.styl","hash":"6eee86c8f0175d6c09e434053516cd8556f78d44","modified":1642412591163},{"_id":"themes/next_8.8/source/css/_schemes/Pisces/_menu.styl","hash":"72dc825c50357402c342d62ab60fc0c478ab6bc1","modified":1642412591164},{"_id":"themes/next_8.8/source/css/_schemes/Muse/_sub-menu.styl","hash":"c48ccd8d6651fe1a01faff8f01179456d39ba9b1","modified":1642412591160},{"_id":"themes/next_8.8/source/css/_schemes/Pisces/_sidebar.styl","hash":"d9141e6e14a56b5952488101e9a8388c2170e270","modified":1642412591164},{"_id":"themes/next_8.8/source/css/_schemes/Pisces/index.styl","hash":"8000075b227749a7495eaf417cac6ccfbe441580","modified":1642412591166},{"_id":"themes/next_8.8/source/css/_schemes/Pisces/_sub-menu.styl","hash":"778ed2ad5643b93970c95626b325defeb586733f","modified":1642412591165},{"_id":"themes/next_8.8/source/css/_schemes/Muse/index.styl","hash":"6ad168288b213cec357e9b5a97674ff2ef3a910c","modified":1642412591161},{"_id":"themes/next_8.8/source/css/_schemes/Pisces/_header.styl","hash":"b741ab96e73370711c63a6581159f2ea8b5bfa1b","modified":1642412591162},{"_id":"themes/next_8.8/source/css/_common/components/pages/breadcrumb.styl","hash":"8afdc311c6b8db121758371f95cf1c5e77354f42","modified":1642412591099},{"_id":"themes/next_8.8/source/css/_common/components/pages/categories.styl","hash":"b6e2eb1550a7845cb2adf86081a4ab6c7bde1e68","modified":1642412591099},{"_id":"themes/next_8.8/source/css/_common/components/pages/tag-cloud.styl","hash":"1a81d1a71fcf0699629ce6e72dfd0a15f3a2dd0a","modified":1642412591100},{"_id":"themes/next_8.8/source/css/_common/components/pages/index.styl","hash":"7504dbc5c70262b048143b2c37d2b5aa2809afa2","modified":1642412591100},{"_id":"themes/next_8.8/source/css/_common/components/pages/schedule.styl","hash":"6b816c2511242ee503fb5f34cd3e4dcdafc06b85","modified":1642412591100},{"_id":"themes/next_8.8/source/css/_common/components/post/index.styl","hash":"d0805a763176b3c0003967401644f41dfe3bc9e8","modified":1642412591101},{"_id":"themes/next_8.8/source/css/_common/components/post/post-body.styl","hash":"ea351936d71e0b6259febac3d7d56d1be6927bf9","modified":1642412591102},{"_id":"themes/next_8.8/source/css/_common/components/post/post-followme.styl","hash":"fc1a7bac6493f24aa50665574f37f3dd954f210c","modified":1642412591106},{"_id":"themes/next_8.8/source/css/_common/components/post/post-header.styl","hash":"010c901e4ef49a606f8a350efbf09044e76d2ff3","modified":1642412591108},{"_id":"themes/next_8.8/source/css/_common/components/post/post-collapse.styl","hash":"ec37a36e94ba791663607a5022f763915778578f","modified":1642412591104},{"_id":"themes/next_8.8/source/css/_common/components/post/post-nav.styl","hash":"9ac6f477177264c26a46e8333b8456720a0444dc","modified":1642412591109},{"_id":"themes/next_8.8/source/css/_common/components/post/post-footer.styl","hash":"1d284f3ea03ba9b4feb76b375e539a8e0bccf1c3","modified":1642412591106},{"_id":"themes/next_8.8/source/css/_common/components/post/post-gallery.styl","hash":"aa366d37389760c8595529b850f461569577a1c5","modified":1642412591107},{"_id":"themes/next_8.8/source/css/_common/components/post/post-widgets.styl","hash":"b6677dc2a2368084ab82bb4f145ac79e5966c150","modified":1642412591111},{"_id":"themes/next_8.8/source/css/_common/components/third-party/disqusjs.styl","hash":"c2326ee3e8b724d99c24a818ddee32813ea5bf89","modified":1642412591113},{"_id":"themes/next_8.8/source/css/_common/components/third-party/index.styl","hash":"fb0b9eaca498be8af0bc430171a17becf87f8554","modified":1642412591114},{"_id":"themes/next_8.8/source/css/_common/components/third-party/gitalk.styl","hash":"070737d101e7cd58e997e8c7af09958268c43a21","modified":1642412591113},{"_id":"themes/next_8.8/source/css/_common/components/post/post-reward.styl","hash":"07cff69f2d57e6321595f64c16d8b763dc88df6a","modified":1642412591110},{"_id":"themes/next_8.8/source/css/_common/components/third-party/math.styl","hash":"9d995eb4871a6c273d9d51558676a1fdabf69e72","modified":1642412591115},{"_id":"themes/next_8.8/source/css/_common/components/third-party/utterances.styl","hash":"56d90ae0559caa55b75f3c300ff2711f9ed65fc4","modified":1642412591117},{"_id":"themes/next_8.8/source/css/_common/components/third-party/related-posts.styl","hash":"41ed817e1eb64078074e245e771446ee041e5790","modified":1642412591116},{"_id":"themes/next_8.8/source/css/_common/components/third-party/search.styl","hash":"e72799ce3f9b79753e365b2f8c8ef6c310668d4a","modified":1642412591116},{"_id":"themes/next_8.8/source/css/_common/outline/footer/index.styl","hash":"8b9407e5cfd0571ef8de7df19022b268f962fa2f","modified":1642412591119},{"_id":"themes/next_8.8/source/css/_common/outline/header/bookmark.styl","hash":"e74f4bb47a101b014ee2a1783c87f3b87323f9a0","modified":1642412591120},{"_id":"themes/next_8.8/source/css/_common/outline/header/github-banner.styl","hash":"38c64c2d04e46848382bfa246a0e9c508294767b","modified":1642412591121},{"_id":"themes/next_8.8/source/css/_common/outline/header/index.styl","hash":"650ed4ad6df1b6ff04647e7b6d568304e4d3ed2e","modified":1642412591122},{"_id":"themes/next_8.8/source/css/_common/outline/header/site-nav.styl","hash":"bf3ad8b4268f763a1e26377681644887694bc009","modified":1642412591125},{"_id":"themes/next_8.8/source/css/_common/outline/sidebar/sidebar-author-links.styl","hash":"52fc98b1435129eb3edb9293ced9e507741f1350","modified":1642412591128},{"_id":"themes/next_8.8/source/css/_common/outline/header/site-meta.styl","hash":"759e582d34d08e3386c55d87a835a9523608619f","modified":1642412591124},{"_id":"themes/next_8.8/source/css/_common/outline/sidebar/index.styl","hash":"cee43480eba028c37d51cb620c2d81486aa24e01","modified":1642412591127},{"_id":"themes/next_8.8/source/css/_common/outline/sidebar/sidebar-blogroll.styl","hash":"9950c3188a28e1c63b5498b7bdcd14b12ace3e28","modified":1642412591130},{"_id":"themes/next_8.8/source/css/_common/outline/header/menu.styl","hash":"392fd53a8dd4e3f33a853ebb24290a622300e0ff","modified":1642412591123},{"_id":"themes/next_8.8/source/css/_common/outline/sidebar/sidebar-button.styl","hash":"b926e368f702f8686aaa2eb98d3d2e533418958c","modified":1642412591131},{"_id":"themes/next_8.8/source/css/_common/outline/sidebar/sidebar-nav.styl","hash":"ee94a1a27090ad24e3ed579093088d97ff96d77d","modified":1642412591132},{"_id":"themes/next_8.8/source/css/_common/outline/sidebar/sidebar-dimmer.styl","hash":"fbdb63c6a8887d19b7137325ba7d6806f728139c","modified":1642412591132},{"_id":"themes/next_8.8/source/css/_common/outline/sidebar/sidebar-author.styl","hash":"5b38ac4a0f1ade0e681aff0e3366c481d9cf3dcd","modified":1642412591130},{"_id":"themes/next_8.8/source/css/_common/outline/sidebar/sidebar-toggle.styl","hash":"3103b81fc76b59e1e2c161e2c484625c770ed66f","modified":1642412591134},{"_id":"themes/next_8.8/source/css/_common/scaffolding/highlight/index.styl","hash":"0b3e2696eca39781c3524b2c5a2555ebc616e6e8","modified":1642412591141},{"_id":"themes/next_8.8/source/css/_common/outline/sidebar/sidebar-toc.styl","hash":"021a37cf178440cc341940a299d3bca359996c6b","modified":1642412591133},{"_id":"themes/next_8.8/source/css/_common/outline/sidebar/site-state.styl","hash":"26dd0adfcb1db6df29c6090c8d7e9b5a43583fb0","modified":1642412591134},{"_id":"themes/next_8.8/source/css/_common/scaffolding/tags/blockquote-center.styl","hash":"d6418fd2bbfba7b73ddf11ec62db9637fdf5d8af","modified":1642412591145},{"_id":"themes/next_8.8/source/css/_common/scaffolding/highlight/copy-code.styl","hash":"83ee4993710fc8daa1c8dbfccd5d5091fd244c30","modified":1642412591140},{"_id":"themes/next_8.8/source/css/_common/scaffolding/tags/group-pictures.styl","hash":"393ff96234e4196b569d4b11496774eb78e147de","modified":1642412591146},{"_id":"themes/next_8.8/source/css/_common/scaffolding/tags/index.styl","hash":"3f76c73a891bbc10679753e702feba9e8a5ffdd2","modified":1642412591146},{"_id":"themes/next_8.8/source/css/_common/scaffolding/tags/mermaid.styl","hash":"48d35dba575a7c9e8845b16652e76b7d4a4646de","modified":1642412591148},{"_id":"themes/next_8.8/source/css/_common/scaffolding/tags/label.styl","hash":"debee14539272fbe3835a7d3853af2230baa3501","modified":1642412591146},{"_id":"themes/next_8.8/source/css/_common/scaffolding/tags/link-grid.styl","hash":"7f8a7345e6537a62cd9e9a94c8f7065b541d9b04","modified":1642412591147},{"_id":"themes/next_8.8/source/css/_common/scaffolding/tags/note.styl","hash":"d27fbf7799695295dd5860a161a13ac4d90c5ba4","modified":1642412591148},{"_id":"themes/next_8.8/source/css/_common/scaffolding/tags/tabs.styl","hash":"9b34143aec49e390e18f380026a45096f7477722","modified":1642412591150},{"_id":"themes/next_8.8/source/css/_common/scaffolding/tags/pdf.styl","hash":"b6654a1d7cf82577d8263faffee8af3ad4a5c0e8","modified":1642412591149},{"_id":"themes/next_8.8/source/images/avatar.jpg","hash":"ed5dde31684ebfd99e9965da1140fb919496f1d3","modified":1642412591175},{"_id":"themes/next_8.8/source/images/avatar_300.jpg","hash":"13b3ca4593cd3c96d4f973b26ec9dbe51e28ed29","modified":1642412591178},{"_id":"themes/next_8.8/source/images/avatar_500.jpg","hash":"fa083b4b1260c2ee43810fc4819e958196ff7d49","modified":1642412591179},{"_id":"public/sitemap.xml","hash":"036930614bc9b24d2c86df4500bb16ff4df107a7","modified":1644546117867},{"_id":"public/categories/index.html","hash":"d0c273c40d458b37ac444a6fe742b85bd83f250e","modified":1644546117867},{"_id":"public/tags/index.html","hash":"51dc7e65ff5dcca01969d197bdc0e8f69fd439c2","modified":1644546117867},{"_id":"public/about/index.html","hash":"448cfa12e315d7dc35481e4c2023384b9cfa45f8","modified":1644546117867},{"_id":"public/2022/01/10/How-to-Blance-Losses-in-Multi-Task-Training/index.html","hash":"cf747078e554a1027c97c3e779ea55994703fddb","modified":1644546117867},{"_id":"public/2021/12/18/Transformer-and-BERT/index.html","hash":"55709c002dc10920ab97ba47a19ff57233e50d69","modified":1644546117867},{"_id":"public/2021/12/17/Algorithm/index.html","hash":"a837cfe0f20b4f26befb65d07ab483cf5a684275","modified":1644546117867},{"_id":"public/2021/12/10/An-Introduction-to-Git/index.html","hash":"3c0e7974b020e9d365abf159f0cc6748ea41ab7f","modified":1644546117867},{"_id":"public/archives/index.html","hash":"056a2c6ebbbce7600acb52edf716c08027de642f","modified":1644546117867},{"_id":"public/archives/page/2/index.html","hash":"c1d20c89dd90ee0b1740d8e86e82897d751834e9","modified":1644546117867},{"_id":"public/archives/2021/index.html","hash":"365ceb9b327b08715bd1805cd20b85f212aacebd","modified":1644546117867},{"_id":"public/archives/2021/12/index.html","hash":"893b51f4c93cd80d628808a138abc760a2f3d227","modified":1644546117867},{"_id":"public/archives/2022/index.html","hash":"65cc3a72c9ac33662aa2a97cd3cc78a3ea0083e9","modified":1644546117867},{"_id":"public/archives/2022/01/index.html","hash":"e49cd5dc4c0a126a6ceffb692e8a2f8d6b55350f","modified":1644546117867},{"_id":"public/2022/02/10/Shorcut-on-Linux/index.html","hash":"df7b1251d0a4384bbf9be4b4e41364a96cd3d968","modified":1644546367317},{"_id":"public/2022/01/20/Config-Vim/index.html","hash":"ca594d5c274da646cfeccb35b05cdc5b514c24ee","modified":1644546117867},{"_id":"public/2021/12/30/Foundation-for-Topological-Data-Analysis/index.html","hash":"d083bbff962702e3796b0cc92b67810d5d531705","modified":1644546117867},{"_id":"public/2021/12/17/Experiments/index.html","hash":"7b86c83fb4923d7cb2d92890ae69517ad6106921","modified":1644546117867},{"_id":"public/2021/12/15/Personal-Thought/index.html","hash":"7613f339118bfb75578bd4eba0b4899d6fa61162","modified":1644546117867},{"_id":"public/2021/12/14/Tips-in-Papers/index.html","hash":"48c290ae75fe6e76e1821c03dd6cfc4845444a0d","modified":1644546117867},{"_id":"public/2021/12/03/First-Step-to-RL/index.html","hash":"c52bd4886c88c343dc783f84e84da7b69069dc69","modified":1644546117867},{"_id":"public/2021/11/24/Construct-Your-Blog-with-Hexo-and-Github/index.html","hash":"5859d5cdd3ee0d4ffc9f8cd8670b735f97f5fa29","modified":1644546117867},{"_id":"public/archives/2022/02/index.html","hash":"53ba16e63e00e70b929047a284bd982e19e3e7fb","modified":1644546117867},{"_id":"public/categories/Little-Things/index.html","hash":"348009969b75897d075a59cc1904ea621a402beb","modified":1644546117867},{"_id":"public/categories/Experiments/index.html","hash":"bb6cf674d2accf6321eb97039fa090e6371e32fe","modified":1644546117867},{"_id":"public/categories/Topological-Data-Analysis/index.html","hash":"ccf844582c1a58234226437cef11cadf14f470c3","modified":1644546117867},{"_id":"public/categories/Little-Things/Git/index.html","hash":"fdf56376b21a3957ec866a2a36fe50e4dbcf7e77","modified":1644546117867},{"_id":"public/categories/Programming/index.html","hash":"335501b5be43263bcc592cc7f21b15e39166108b","modified":1644546117867},{"_id":"public/categories/Reinforcement-Learning/index.html","hash":"be5b777b01248cd3afec4d34050a92d0c4ffd082","modified":1644546117867},{"_id":"public/categories/Little-Things/Linux/index.html","hash":"aaf282225e475b309fa33f9b2ff84803a12942fb","modified":1644546117867},{"_id":"public/categories/About-Papers/index.html","hash":"e818f13a5755ded5f3308ac6e9e3f26624fde9ce","modified":1644546117867},{"_id":"public/categories/Natural-Language-Processing/index.html","hash":"bbc7773fcde02837271ccccc865a05d80ad057cc","modified":1644546117867},{"_id":"public/page/2/index.html","hash":"56e050abff56749f5c95bdd44ea7872c783bfa22","modified":1644546117867},{"_id":"public/tags/vim/index.html","hash":"14780b5661f8d49ec0811b166c17275a40153b1c","modified":1644546117867},{"_id":"public/tags/markdown/index.html","hash":"f6fbe9fe5db2828a4abf2ec335d27eaa9ba0924b","modified":1644546117867},{"_id":"public/tags/vimtex/index.html","hash":"8a61137ebebbf64e2bf49b3f9317ce62513b7e8e","modified":1644546117867},{"_id":"public/tags/Git/index.html","hash":"2d688d05118e2e8ac694738389d59b20fec5e2ce","modified":1644546117867},{"_id":"public/tags/Personal-Thought/index.html","hash":"1adcdab15db0507436337fa52c4e7b697d47fc6b","modified":1644546117867},{"_id":"public/tags/Experiments/index.html","hash":"db78b75e3271e8196d0312c3153951daa511f924","modified":1644546117867},{"_id":"public/tags/private/index.html","hash":"53e9d0038479b5cf1fc7b87808798eac27291ad3","modified":1644546117867},{"_id":"public/tags/Topological-Data-Analysis/index.html","hash":"edb582f2263e2974741df6768ea261b64b8ac1f1","modified":1644546117867},{"_id":"public/tags/Multi-Task-Training/index.html","hash":"a769b365fc38c93b2ae673991ffd1816afe21dc6","modified":1644546117867},{"_id":"public/tags/Algorithm/index.html","hash":"14ebc919ae43edea49b3f668caee781be461427b","modified":1644546117867},{"_id":"public/tags/Programming/index.html","hash":"1152f98f7828acc11dbc9e7bdc47eaed53415bd3","modified":1644546117867},{"_id":"public/tags/Reinforcement-Learning/index.html","hash":"0a75b749cb2e4495471e5309bd856adbafb08f68","modified":1644546117867},{"_id":"public/tags/Linux/index.html","hash":"812e131eebbddf45b411712efd77608afd506890","modified":1644546117867},{"_id":"public/tags/Papers/index.html","hash":"03f35a1482cc62a4af18fa75d3c2e4e2f0e4518f","modified":1644546117867},{"_id":"public/tags/Natural-Language-Processing/index.html","hash":"91139b9fc2247008bc8ffaa84fcf8ad0b144084f","modified":1644546117867},{"_id":"public/tags/Transformer/index.html","hash":"0614e2c8c700bde20418b835486a662e0ba37748","modified":1644546117867},{"_id":"public/tags/BERT/index.html","hash":"90e6ac161963a918320c57b2e0355b5b3fcf34a4","modified":1644546117867},{"_id":"public/index.html","hash":"819d1bda923a6aaa2eba4f498969a7845e4e6cfb","modified":1644546367317},{"_id":"public/CNAME","hash":"55c55444033af34e797e2d3cb1c1b4cf7889b3db","modified":1644546117867},{"_id":"public/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1644546117867},{"_id":"public/images/avatar_100.jpg","hash":"a0f0a00c9326c57a5cc181aeb80dfda8e947920a","modified":1644546117867},{"_id":"public/images/avatar.gif","hash":"2dbc3e2f2d624b2ca1afe6edc2ca17307f1950c8","modified":1644546117867},{"_id":"public/images/avatar_200.jpg","hash":"4a76d1527e511350c9112e899046a34be59ad278","modified":1644546117867},{"_id":"public/images/avatar_80.jpg","hash":"465e53598964df3852f08794cb73c5e459855e92","modified":1644546117867},{"_id":"public/images/logo-algolia-nebula-blue-full.svg","hash":"b85e274207b1392782476a0430feac98db1e7da0","modified":1644546117867},{"_id":"public/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1644546117867},{"_id":"public/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1644546117867},{"_id":"public/images/ye_16.ico","hash":"b8fb01b5361da89831d232a831a1532e9822bd72","modified":1644546117867},{"_id":"public/images/logo.svg","hash":"2cb74fd3ea2635e015eabc58a8d488aed6cf6417","modified":1644546117867},{"_id":"public/images/ye_32.ico","hash":"375c99cd785d93dd989c36604ffbd10ada71322a","modified":1644546117867},{"_id":"public/2021/12/03/First-Step-to-RL/policy_network.py","hash":"b3e8f06360cad0084a0656edaed4539f1b01e327","modified":1644546117867},{"_id":"public/2021/12/03/First-Step-to-RL/q_learning.py","hash":"3a68ec1153d26f2c18c9d34ee5deb5e495b8dca9","modified":1644546117867},{"_id":"public/2021/12/14/Tips-in-Papers/ADCM.jpg","hash":"ee5b75f3a063e07624c5f03111f98902d885cd8e","modified":1644546117867},{"_id":"public/2021/12/14/Tips-in-Papers/Saccader_eq1.jpg","hash":"2ea2a74f960377a6a9d0bc98ecfadd8ba09cd316","modified":1644546117867},{"_id":"public/2021/12/14/Tips-in-Papers/Saccader_gl.jpg","hash":"fb8050f8b71a7c667cfa85672b505b3340d2231b","modified":1644546117867},{"_id":"public/2021/12/14/Tips-in-Papers/Saccader_eq2.jpg","hash":"cf5832e89b29e39275d2fa4a2e39592e97f9a39e","modified":1644546117867},{"_id":"public/2021/12/14/Tips-in-Papers/Saccader_eq3.jpg","hash":"8fa845242bb6f737736d91485ca237e7132e19b5","modified":1644546117867},{"_id":"public/lib/hbe.js","hash":"136dba00826bdd086153bf0acb5473aea7183ad1","modified":1644546117867},{"_id":"public/css/hbe.style.css","hash":"b0a0077cb588c0941823905fcc383aa7509ade73","modified":1644546117867},{"_id":"public/images/avatar.jpg","hash":"ed5dde31684ebfd99e9965da1140fb919496f1d3","modified":1644546117867},{"_id":"public/images/avatar_300.jpg","hash":"13b3ca4593cd3c96d4f973b26ec9dbe51e28ed29","modified":1644546117867},{"_id":"public/2021/12/14/Tips-in-Papers/Saccader_Over.jpg","hash":"deaccd942ffca9e163a9f2c9bdfb69251d1004cb","modified":1644546117867},{"_id":"public/2021/12/14/Tips-in-Papers/Saccader_Cell.jpg","hash":"b17e79bf86bb3422527bf51d200ceceeb53ce936","modified":1644546117867},{"_id":"public/js/comments-buttons.js","hash":"1a7344440321713426a0b2ab17e276b5bdf85ade","modified":1644546117867},{"_id":"public/js/comments.js","hash":"66ae2e26ea36a41b72c638ea8b220296638ae952","modified":1644546117867},{"_id":"public/js/bookmark.js","hash":"0f563ffbf05fad30e854e413ab17ff7164ab5a53","modified":1644546117867},{"_id":"public/js/motion.js","hash":"9c4c861dfb080b6244d4d9eba33ac686735754f3","modified":1644546117867},{"_id":"public/js/config.js","hash":"4c4ebbe3b3f3841a26f9d5af6d0ba8bc6da01c54","modified":1644546117867},{"_id":"public/js/schedule.js","hash":"2b43e2d576a308289880befc27580dbb2aa34439","modified":1644546117867},{"_id":"public/js/pjax.js","hash":"919f5281c4a04d11cfd94573ecf57b3dbabd3cc8","modified":1644546117867},{"_id":"public/js/utils.js","hash":"e447160d342b1f93df5214b6a733441039ced439","modified":1644546117867},{"_id":"public/css/noscript.css","hash":"54d14cd43dc297950a4a8d39ec9644dd5fc3499f","modified":1644546117867},{"_id":"public/js/third-party/fancybox.js","hash":"c098d14e65dd170537134358d4b8359ad0539c2c","modified":1644546117867},{"_id":"public/js/next-boot.js","hash":"48497e2156a10155dc42311633a110c9685692c9","modified":1644546117867},{"_id":"public/js/third-party/analytics/growingio.js","hash":"78dd3cf04082b7dbe6246e404b2aa8e726922402","modified":1644546117867},{"_id":"public/js/third-party/analytics/baidu-analytics.js","hash":"f629acc46ff40c071ffd31b77d5c7616f0fdd778","modified":1644546117867},{"_id":"public/js/third-party/quicklink.js","hash":"6f58cd7aa8f6f1ab92d5a96551add293f4e55312","modified":1644546117867},{"_id":"public/js/third-party/rating.js","hash":"4e92c2d107ba47b47826829f9668030d5ea9bfb8","modified":1644546117867},{"_id":"public/js/third-party/chat/chatra.js","hash":"c32180522788c10e51df1803aa6842ef0432ddc9","modified":1644546117867},{"_id":"public/js/third-party/analytics/google-analytics.js","hash":"59684383385059dc4f8a1ff85dbbeb703bcdbcb5","modified":1644546117867},{"_id":"public/js/third-party/chat/gitter.js","hash":"cc38c94125f90dadde11b5ebac7d8bf99a1a08a2","modified":1644546117867},{"_id":"public/js/third-party/comments/gitalk.js","hash":"0ec038cf83e8ec067534f16a54041e47a3c1e59a","modified":1644546117867},{"_id":"public/js/third-party/chat/tidio.js","hash":"b0079f6a4601e06ca6fe46e83a2f5af553e9bc3c","modified":1644546117867},{"_id":"public/js/third-party/comments/disqusjs.js","hash":"b6c58f098473b526d6a3cd35655caf34b77f7cff","modified":1644546117867},{"_id":"public/js/third-party/comments/isso.js","hash":"753a873b6f566aff5ba77ca23f91b78eb880ca64","modified":1644546117867},{"_id":"public/js/third-party/comments/disqus.js","hash":"e1cc671b0d524864fd445e3ab4ade9ee6d07e565","modified":1644546117867},{"_id":"public/js/third-party/comments/utterances.js","hash":"f67f90eb03e284c82da2b8cf2f1e31801813c16d","modified":1644546117867},{"_id":"public/js/third-party/comments/changyan.js","hash":"8c8ebec444c727b704ea41ad88b0b96ed2e4b8d4","modified":1644546117867},{"_id":"public/js/third-party/pace.js","hash":"0ef04218b93561ba4d0ff420d556c3d90a756d32","modified":1644546117867},{"_id":"public/js/third-party/comments/livere.js","hash":"2247d88c934c765c43013337860774aaa99f0b31","modified":1644546117867},{"_id":"public/js/third-party/math/katex.js","hash":"83c54ee536e487a1031783443fe0cb63b1b4767e","modified":1644546117867},{"_id":"public/js/third-party/search/algolia-search.js","hash":"ac401e3736d56a3c9cb85ab885744cce0b813c55","modified":1644546117867},{"_id":"public/js/third-party/search/local-search.js","hash":"45c485f82258d246f37deb66884bd2643323ef3a","modified":1644546117867},{"_id":"public/js/third-party/statistics/firestore.js","hash":"0960f16107ed61452fb0dffc6ed22dc143de34ef","modified":1644546117867},{"_id":"public/js/third-party/statistics/lean-analytics.js","hash":"5a928990856b8e456f0663cf3b6b406733672e39","modified":1644546117867},{"_id":"public/js/third-party/tags/mermaid.js","hash":"3dc4628efa6debd6490fc0ebddff2424a7b319d8","modified":1644546117867},{"_id":"public/js/third-party/tags/pdf.js","hash":"af78c22f0e61c8c8aa8794e585e0d632c6d4fcb8","modified":1644546117867},{"_id":"public/js/schemes/muse.js","hash":"9a836d2bcc3defe4bd1ee51f5f4eb7006ebdd41b","modified":1644546117867},{"_id":"public/js/third-party/math/mathjax.js","hash":"5c749b9c1c3bb738122d0516211ecff6496d4907","modified":1644546117867},{"_id":"public/css/main.css","hash":"b4cd7ab94ab2fdff102e77147fe884d4b2553997","modified":1644546117867},{"_id":"public/images/avatar_500.jpg","hash":"fa083b4b1260c2ee43810fc4819e958196ff7d49","modified":1644546117867},{"_id":"public/2021/12/14/Tips-in-Papers/Tnet_over.jpg","hash":"ed04ca4049c6f909b0bf51ea57ffa9a2b445e1c8","modified":1644546117867},{"_id":"public/2021/12/10/An-Introduction-to-Git/git.jpg","hash":"db9ed8bb86df7e73d5be3bcae4cc8656e4a7a0ed","modified":1644546117867}],"Category":[{"name":"Little Things","_id":"ckzhsa4ga00044fvkelaxcfg7"},{"name":"Experiments","_id":"ckzhsa4gv000k4fvk4ui56yqd"},{"name":"Topological Data Analysis","_id":"ckzhsa4h2000p4fvkaqta1xn2"},{"name":"Git","parent":"ckzhsa4ga00044fvkelaxcfg7","_id":"ckzhsa4h5000w4fvk23z12bsm"},{"name":"Programming","_id":"ckzhsa4h600104fvk0dlk2cf2"},{"name":"Reinforcement Learning","_id":"ckzhsa4h700134fvkgshehna2"},{"name":"Hexo","parent":"ckzhsa4ga00044fvkelaxcfg7","_id":"ckzhsa4h800174fvkh65hdhd8"},{"name":"Linux","parent":"ckzhsa4ga00044fvkelaxcfg7","_id":"ckzhsa4h9001b4fvk86hy8jrs"},{"name":"About Papers","_id":"ckzhsa4hb001h4fvk6r52d82i"},{"name":"Natural Language Processing","_id":"ckzhsa4hd001p4fvk0wetcc1x"}],"Data":[],"Page":[{"title":"categories","date":"2021-11-24T11:46:36.000Z","type":"categories","_content":"","source":"categories/index.md","raw":"---\ntitle: categories\ndate: 2021-11-24 19:46:36\ntype: \"categories\"\n---\n","updated":"2022-01-17T09:43:07.989Z","path":"categories/index.html","comments":1,"layout":"page","_id":"ckzhsa4fw00004fvkfjbrgzzh","content":"<html><head></head><body></body></html>","site":{"data":{}},"excerpt":"<html><head></head><body></body></html>","more":""},{"title":"tags","date":"2021-12-08T06:48:06.000Z","type":"tags","_content":"","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2021-12-08 14:48:06\ntype: \"tags\"\n---\n","updated":"2022-01-17T09:43:07.990Z","path":"tags/index.html","comments":1,"layout":"page","_id":"ckzhsa4g700024fvk9fq6furl","content":"<html><head></head><body></body></html>","site":{"data":{}},"excerpt":"<html><head></head><body></body></html>","more":""},{"title":"about","date":"2021-12-12T13:52:49.000Z","_content":"\n\n\n<!-- I received the B.S. degree in the School of Engineering and Technology, China University of Geosciences (Beijing) in 2015. I am currently working towards the Ph.D degree in the Beijing Key Laboratory of Work Safety Intelligent Monitoring, the Department of EE, BUPT. -->\n\n<!-- I major in deep learning, computer vision, natural language processing, and reinforcement learning. -->\n\n<!-- I am also interested in high performance computing. -->\n\n<br/>\n\n<br/>\n\n---\n\n<br/>\n\n<br/>\n\n>      *There is a pleasure in the pathless woods;*\n>      *there is a rapture on the lonely shore;*\n>      *there is society, where none intrudes,*\n>      *by the deep sea, and music in its roar;*\n>      *I love not man the less, but nature more...*\n>                           *by George Gordon Byron* \n\n","source":"about/index.md","raw":"---\ntitle: about\ndate: 2021-12-12 21:52:49\n---\n\n\n\n<!-- I received the B.S. degree in the School of Engineering and Technology, China University of Geosciences (Beijing) in 2015. I am currently working towards the Ph.D degree in the Beijing Key Laboratory of Work Safety Intelligent Monitoring, the Department of EE, BUPT. -->\n\n<!-- I major in deep learning, computer vision, natural language processing, and reinforcement learning. -->\n\n<!-- I am also interested in high performance computing. -->\n\n<br/>\n\n<br/>\n\n---\n\n<br/>\n\n<br/>\n\n>      *There is a pleasure in the pathless woods;*\n>      *there is a rapture on the lonely shore;*\n>      *there is society, where none intrudes,*\n>      *by the deep sea, and music in its roar;*\n>      *I love not man the less, but nature more...*\n>                           *by George Gordon Byron* \n\n","updated":"2022-01-17T09:43:07.988Z","path":"about/index.html","comments":1,"layout":"page","_id":"ckzhsa4gd00064fvk674w8vs4","content":"<!-- I received the B.S. degree in the School of Engineering and Technology, China University of Geosciences (Beijing) in 2015. I am currently working towards the Ph.D degree in the Beijing Key Laboratory of Work Safety Intelligent Monitoring, the Department of EE, BUPT. --><!-- I major in deep learning, computer vision, natural language processing, and reinforcement learning. --><!-- I am also interested in high performance computing. --><html><head></head><body><br>\n<br>\n<hr>\n<br>\n<br>\n<blockquote>\n<p>     <em>There is a pleasure in the pathless woods;</em>\n     <em>there is a rapture on the lonely shore;</em>\n     <em>there is society, where none intrudes,</em>\n     <em>by the deep sea, and music in its roar;</em>\n     <em>I love not man the less, but nature more</em>\n                          <em>by George Gordon Byron</em></p>\n</blockquote>\n</body></html>","site":{"data":{}},"excerpt":"<html><head></head><body></body></html>","more":"<!-- I received the B.S. degree in the School of Engineering and Technology, China University of Geosciences (Beijing) in 2015. I am currently working towards the Ph.D degree in the Beijing Key Laboratory of Work Safety Intelligent Monitoring, the Department of EE, BUPT. -->\n<!-- I major in deep learning, computer vision, natural language processing, and reinforcement learning. -->\n<!-- I am also interested in high performance computing. -->\n<br/>\n<br/>\n<hr>\n<br/>\n<br/>\n<blockquote>\n<p>     <em>There is a pleasure in the pathless woods;</em>\n     <em>there is a rapture on the lonely shore;</em>\n     <em>there is society, where none intrudes,</em>\n     <em>by the deep sea, and music in its roar;</em>\n     <em>I love not man the less, but nature more</em>\n                          <em>by George Gordon Byron</em></p>\n</blockquote>\n"}],"Post":[{"title":"Config Vim","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2022-01-20T02:24:34.000Z","password":null,"summary":null,"description":"vimmarkdown, vimtex","_content":"\n# anaconda\nanaconda\n`./Anaconda3-2021.11-Linux-x86_64.sh: 489: [[: Exec format error`\n./Anaconda.shsh\nbash Anaconda.sh.\n\n# Linux\n\n## \napt install\n`dpkg -L xxx`\n\n## \n,log\nlog\n\n## linux \n`LIBRARY_PATH`\n`LD_LIBRARY_PATH`\n\n## \nokular: error while loading shared libraries: libQt5Core.so.5: cannot open shared object file: No such file or directory\nstrip\nsudo strip --remove-section=.note.ABI-tag /usr/lib/x86_64-linux-gnu/libQt5Core.so.5\n\n# vim\naptvimvimlatex+clietservice\napt-cache search libc-dev\nln -s libXtst.so.6 libXtst.so\n\nhttps://www.jianshu.com/p/aa5ea81bbc72\nhttps://toutiao.io/posts/runvgs/preview\nconfig \n\n```python\n./configure --with-features=huge \\\n    --enable-multibyte \\\n    --enable-rubyinterp=yes \\\n    --enable-python3interp=yes \\\n    --enable-perlinterp=yes \\\n    --enable-cscope \\\n    --enable-fontset \\\n    --enable-largefile \\\n    --enable-fail-if-missing \\\n    --prefix=/path-to-install\n```\n\n`--enable-fail-if-missing` \n\n## apt\n\nfeature hug+clientserver\nsrc/auto/cofig.log\n`sudo apt-get install vim-gtk`+clientservervim\n\n","source":"_posts/Config-Vim.md","raw":"---\ntitle: Config Vim\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2022-01-20 10:24:34\npassword:\nsummary:\ndescription:  vimmarkdown, vimtex\ncategories:\n- Little Things\ntags:\n- vim\n- markdown\n- vimtex\n---\n\n# anaconda\nanaconda\n`./Anaconda3-2021.11-Linux-x86_64.sh: 489: [[: Exec format error`\n./Anaconda.shsh\nbash Anaconda.sh.\n\n# Linux\n\n## \napt install\n`dpkg -L xxx`\n\n## \n,log\nlog\n\n## linux \n`LIBRARY_PATH`\n`LD_LIBRARY_PATH`\n\n## \nokular: error while loading shared libraries: libQt5Core.so.5: cannot open shared object file: No such file or directory\nstrip\nsudo strip --remove-section=.note.ABI-tag /usr/lib/x86_64-linux-gnu/libQt5Core.so.5\n\n# vim\naptvimvimlatex+clietservice\napt-cache search libc-dev\nln -s libXtst.so.6 libXtst.so\n\nhttps://www.jianshu.com/p/aa5ea81bbc72\nhttps://toutiao.io/posts/runvgs/preview\nconfig \n\n```python\n./configure --with-features=huge \\\n    --enable-multibyte \\\n    --enable-rubyinterp=yes \\\n    --enable-python3interp=yes \\\n    --enable-perlinterp=yes \\\n    --enable-cscope \\\n    --enable-fontset \\\n    --enable-largefile \\\n    --enable-fail-if-missing \\\n    --prefix=/path-to-install\n```\n\n`--enable-fail-if-missing` \n\n## apt\n\nfeature hug+clientserver\nsrc/auto/cofig.log\n`sudo apt-get install vim-gtk`+clientservervim\n\n","slug":"Config-Vim","published":1,"updated":"2022-02-08T07:30:43.760Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckzhsa4g000014fvkci7l3cof","content":"<html><head></head><body><h1><span class=\"post-title-index\">1. </span>anaconda</h1>\n<p>anaconda\n<code>./Anaconda3-2021.11-Linux-x86_64.sh: 489: [[: Exec format error</code>\n./Anaconda.shsh\nbash Anaconda.sh.</p>\n<h1><span class=\"post-title-index\">2. </span>Linux</h1>\n<h2 id=\"\"><span class=\"post-title-index\">2.1. </span></h2>\n<p>apt install\n<code>dpkg -L xxx</code></p>\n<h2 id=\"\"><span class=\"post-title-index\">2.2. </span></h2>\n<p>,log\nlog</p>\n<h2 id=\"linux-\"><span class=\"post-title-index\">2.3. </span>linux </h2>\n<p><code>LIBRARY_PATH</code>\n<code>LD_LIBRARY_PATH</code></p>\n<h2 id=\"\"><span class=\"post-title-index\">2.4. </span></h2>\n<p>okular: error while loading shared libraries: libQt5Core.so.5: cannot open shared object file: No such file or directory\nstrip\nsudo strip --remove-section=.note.ABI-tag /usr/lib/x86_64-linux-gnu/libQt5Core.so.5</p>\n<h1><span class=\"post-title-index\">3. </span>vim</h1>\n<p>aptvimvimlatex+clietservice\napt-cache search libc-dev\nln -s libXtst.so.6 <a href=\"http://libXtst.so\">libXtst.so</a>\n\n<a href=\"https://www.jianshu.com/p/aa5ea81bbc72\">https://www.jianshu.com/p/aa5ea81bbc72</a>\n<a href=\"https://toutiao.io/posts/runvgs/preview\">https://toutiao.io/posts/runvgs/preview</a>\nconfig </p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">./configure --<span class=\"keyword\">with</span>-features=huge \\</span><br><span class=\"line\">    --enable-multibyte \\</span><br><span class=\"line\">    --enable-rubyinterp=yes \\</span><br><span class=\"line\">    --enable-python3interp=yes \\</span><br><span class=\"line\">    --enable-perlinterp=yes \\</span><br><span class=\"line\">    --enable-cscope \\</span><br><span class=\"line\">    --enable-fontset \\</span><br><span class=\"line\">    --enable-largefile \\</span><br><span class=\"line\">    --enable-fail-<span class=\"keyword\">if</span>-missing \\</span><br><span class=\"line\">    --prefix=/path-to-install</span><br></pre></td></tr></tbody></table></figure>\n<p><code>--enable-fail-if-missing</code> </p>\n<h2 id=\"apt\"><span class=\"post-title-index\">3.1. </span>apt</h2>\n<p>feature hug+clientserver\nsrc/auto/cofig.log\n<code>sudo apt-get install vim-gtk</code>+clientservervim</p>\n</body></html>","site":{"data":{}},"excerpt":"<html><head></head><body></body></html>","more":"<h1>anaconda</h1>\n<p>anaconda\n<code>./Anaconda3-2021.11-Linux-x86_64.sh: 489: [[: Exec format error</code>\n./Anaconda.shsh\nbash Anaconda.sh.</p>\n<h1>Linux</h1>\n<h2 id=\"\"></h2>\n<p>apt install\n<code>dpkg -L xxx</code></p>\n<h2 id=\"\"></h2>\n<p>,log\nlog</p>\n<h2 id=\"linux-\">linux </h2>\n<p><code>LIBRARY_PATH</code>\n<code>LD_LIBRARY_PATH</code></p>\n<h2 id=\"\"></h2>\n<p>okular: error while loading shared libraries: libQt5Core.so.5: cannot open shared object file: No such file or directory\nstrip\nsudo strip --remove-section=.note.ABI-tag /usr/lib/x86_64-linux-gnu/libQt5Core.so.5</p>\n<h1>vim</h1>\n<p>aptvimvimlatex+clietservice\napt-cache search libc-dev\nln -s libXtst.so.6 <a href=\"http://libXtst.so\">libXtst.so</a>\n\n<a href=\"https://www.jianshu.com/p/aa5ea81bbc72\">https://www.jianshu.com/p/aa5ea81bbc72</a>\n<a href=\"https://toutiao.io/posts/runvgs/preview\">https://toutiao.io/posts/runvgs/preview</a>\nconfig </p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">./configure --<span class=\"keyword\">with</span>-features=huge \\</span><br><span class=\"line\">    --enable-multibyte \\</span><br><span class=\"line\">    --enable-rubyinterp=yes \\</span><br><span class=\"line\">    --enable-python3interp=yes \\</span><br><span class=\"line\">    --enable-perlinterp=yes \\</span><br><span class=\"line\">    --enable-cscope \\</span><br><span class=\"line\">    --enable-fontset \\</span><br><span class=\"line\">    --enable-largefile \\</span><br><span class=\"line\">    --enable-fail-<span class=\"keyword\">if</span>-missing \\</span><br><span class=\"line\">    --prefix=/path-to-install</span><br></pre></td></tr></table></figure>\n<p><code>--enable-fail-if-missing</code> </p>\n<h2 id=\"apt\">apt</h2>\n<p>feature hug+clientserver\nsrc/auto/cofig.log\n<code>sudo apt-get install vim-gtk</code>+clientservervim</p>\n"},{"title":"An Introduction to Git","date":"2021-12-10T13:55:33.000Z","description":"gitgit","summary":null,"_content":"\n\n\n\n\n\n\n![The Structure of Git](git.jpg)\n\ngit checkout\n\ngit ls-files\n\n--cached (-c) \n\n--midified (-m)\n\n--delete (-d)\n\n--other (-o)git\n\n","source":"_posts/An-Introduction-to-Git.md","raw":"---\ntitle: An Introduction to Git\ndate: 2021-12-10 21:55:33\ndescription: gitgit\nsummary:\ncategories:\n- Little Things\n- Git\ntags:\n- Git\n---\n\n\n\n\n\n\n\n![The Structure of Git](git.jpg)\n\ngit checkout\n\ngit ls-files\n\n--cached (-c) \n\n--midified (-m)\n\n--delete (-d)\n\n--other (-o)git\n\n","slug":"An-Introduction-to-Git","published":1,"updated":"2022-01-17T09:43:07.967Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckzhsa4g800034fvkhd0g7iv7","content":"<html><head></head><body><p><img src=\"git.jpg\" alt=\"The Structure of Git\"></p>\n<p>git checkout</p>\n<p>git ls-files</p>\n<p>cached (-c) </p>\n<p>midified (-m)</p>\n<p>delete (-d)</p>\n<p>other (-o)git</p>\n</body></html>","site":{"data":{}},"excerpt":"<html><head></head><body></body></html>","more":"<p><img src=\"git.jpg\" alt=\"The Structure of Git\"></p>\n<p>git checkout</p>\n<p>git ls-files</p>\n<p>cached (-c) </p>\n<p>midified (-m)</p>\n<p>delete (-d)</p>\n<p>other (-o)git</p>\n"},{"title":"Construct Your Blog with Hexo and Github","date":"2021-11-24T08:20:43.000Z","hidden":true,"description":"Hexo, Next","_content":"\n\n# \n\nhttps://segmentfault.com/a/1190000017986794\n\nhttps://godweiyang.com/2018/04/13/hexo-blog/\n\nhttps://blog.guaoxiaohei.com/posts/Hexo-Level/\n\nhttps://www.itfanr.cc/2021/04/16/hexo-blog-article-encryption/\n\nhttps://www.zhangxinxu.com/wordpress/2021/05/css-html-hr/\n\ntypora\n\nhttps://zhuanlan.zhihu.com/p/110257979\n\n# \n\n## hexo d GitHub\n\n_config.yml\n\n\n\nurl: github,  https://xyegithub.github.io/myBlog/\n\nroot: url/myBlog/\n\nhexo clean; hexo g; hexo d\n\n##  git\n\n\n\nhttps://juejin.cn/post/6844904193170341896\n\ndnscmd ipconfig /flushdns\n\n\n\n### \n\nhexo _config.ymlgit`https://github.com/xxx`ssh `git@github.com:xxx/xxx`\n\n## github page \n\n\n\nhttps://mizeri.github.io/2021/04/18/hexo-sitemap-google/\n\n## \n\n1. freenomyexiang.ml\n2. DNSpodAgithub page\n\n","source":"_posts/Construct-Your-Blog-with-Hexo-and-Github.md","raw":"---\ntitle: Construct Your Blog with Hexo and Github\ndate: 2021-11-24 16:20:43\nhidden: true\ndescription:  Hexo, Next\ntags: \n- Hexo\ncategories:\n- Little Things\n- Hexo\n---\n\n\n# \n\nhttps://segmentfault.com/a/1190000017986794\n\nhttps://godweiyang.com/2018/04/13/hexo-blog/\n\nhttps://blog.guaoxiaohei.com/posts/Hexo-Level/\n\nhttps://www.itfanr.cc/2021/04/16/hexo-blog-article-encryption/\n\nhttps://www.zhangxinxu.com/wordpress/2021/05/css-html-hr/\n\ntypora\n\nhttps://zhuanlan.zhihu.com/p/110257979\n\n# \n\n## hexo d GitHub\n\n_config.yml\n\n\n\nurl: github,  https://xyegithub.github.io/myBlog/\n\nroot: url/myBlog/\n\nhexo clean; hexo g; hexo d\n\n##  git\n\n\n\nhttps://juejin.cn/post/6844904193170341896\n\ndnscmd ipconfig /flushdns\n\n\n\n### \n\nhexo _config.ymlgit`https://github.com/xxx`ssh `git@github.com:xxx/xxx`\n\n## github page \n\n\n\nhttps://mizeri.github.io/2021/04/18/hexo-sitemap-google/\n\n## \n\n1. freenomyexiang.ml\n2. DNSpodAgithub page\n\n","slug":"Construct-Your-Blog-with-Hexo-and-Github","published":1,"updated":"2022-01-17T09:43:07.971Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckzhsa4ge00074fvkaqq79sef","content":"<html><head></head><body><h1><span class=\"post-title-index\">1. </span></h1>\n<p><a href=\"https://segmentfault.com/a/1190000017986794\">https://segmentfault.com/a/1190000017986794</a></p>\n<p><a href=\"https://godweiyang.com/2018/04/13/hexo-blog/\">https://godweiyang.com/2018/04/13/hexo-blog/</a></p>\n<p><a href=\"https://blog.guaoxiaohei.com/posts/Hexo-Level/\">https://blog.guaoxiaohei.com/posts/Hexo-Level/</a></p>\n<p><a href=\"https://www.itfanr.cc/2021/04/16/hexo-blog-article-encryption/\">https://www.itfanr.cc/2021/04/16/hexo-blog-article-encryption/</a></p>\n<p><a href=\"https://www.zhangxinxu.com/wordpress/2021/05/css-html-hr/\">https://www.zhangxinxu.com/wordpress/2021/05/css-html-hr/</a></p>\n<p>typora</p>\n<p><a href=\"https://zhuanlan.zhihu.com/p/110257979\">https://zhuanlan.zhihu.com/p/110257979</a></p>\n<h1><span class=\"post-title-index\">2. </span></h1>\n<h2 id=\"hexo-d-GitHub\"><span class=\"post-title-index\">2.1. </span>hexo d GitHub</h2>\n<p>_config.yml</p>\n<p>url: github,  <a href=\"https://xyegithub.github.io/myBlog/\">https://xyegithub.github.io/myBlog/</a></p>\n<p>root: url/myBlog/</p>\n<p>hexo clean; hexo g; hexo d</p>\n<h2 id=\"git\"><span class=\"post-title-index\">2.2. </span>git</h2>\n<p></p>\n<p><a href=\"https://juejin.cn/post/6844904193170341896\">https://juejin.cn/post/6844904193170341896</a></p>\n<p>dnscmd ipconfig /flushdns</p>\n<p></p>\n<h3 id=\"\"><span class=\"post-title-index\">2.2.1. </span></h3>\n<p>hexo _config.ymlgit<code>https://github.com/xxx</code>ssh <code>git@github.com:xxx/xxx</code></p>\n<h2 id=\"github-page-\"><span class=\"post-title-index\">2.3. </span>github page </h2>\n<p></p>\n<p><a href=\"https://mizeri.github.io/2021/04/18/hexo-sitemap-google/\">https://mizeri.github.io/2021/04/18/hexo-sitemap-google/</a></p>\n<h2 id=\"\"><span class=\"post-title-index\">2.4. </span></h2>\n<ol>\n<li>freenom<a href=\"http://xn--yexiang-i22m.ml\">yexiang.ml</a></li>\n<li>DNSpodAgithub page</li>\n</ol>\n<!-- flag of hidden posts --></body></html>","site":{"data":{}},"excerpt":"<html><head></head><body></body></html>","more":"<h1></h1>\n<p><a href=\"https://segmentfault.com/a/1190000017986794\">https://segmentfault.com/a/1190000017986794</a></p>\n<p><a href=\"https://godweiyang.com/2018/04/13/hexo-blog/\">https://godweiyang.com/2018/04/13/hexo-blog/</a></p>\n<p><a href=\"https://blog.guaoxiaohei.com/posts/Hexo-Level/\">https://blog.guaoxiaohei.com/posts/Hexo-Level/</a></p>\n<p><a href=\"https://www.itfanr.cc/2021/04/16/hexo-blog-article-encryption/\">https://www.itfanr.cc/2021/04/16/hexo-blog-article-encryption/</a></p>\n<p><a href=\"https://www.zhangxinxu.com/wordpress/2021/05/css-html-hr/\">https://www.zhangxinxu.com/wordpress/2021/05/css-html-hr/</a></p>\n<p>typora</p>\n<p><a href=\"https://zhuanlan.zhihu.com/p/110257979\">https://zhuanlan.zhihu.com/p/110257979</a></p>\n<h1></h1>\n<h2 id=\"hexo-d-GitHub\">hexo d GitHub</h2>\n<p>_config.yml</p>\n<p>url: github,  <a href=\"https://xyegithub.github.io/myBlog/\">https://xyegithub.github.io/myBlog/</a></p>\n<p>root: url/myBlog/</p>\n<p>hexo clean; hexo g; hexo d</p>\n<h2 id=\"git\">git</h2>\n<p></p>\n<p><a href=\"https://juejin.cn/post/6844904193170341896\">https://juejin.cn/post/6844904193170341896</a></p>\n<p>dnscmd ipconfig /flushdns</p>\n<p></p>\n<h3 id=\"\"></h3>\n<p>hexo _config.ymlgit<code>https://github.com/xxx</code>ssh <code>git@github.com:xxx/xxx</code></p>\n<h2 id=\"github-page-\">github page </h2>\n<p></p>\n<p><a href=\"https://mizeri.github.io/2021/04/18/hexo-sitemap-google/\">https://mizeri.github.io/2021/04/18/hexo-sitemap-google/</a></p>\n<h2 id=\"\"></h2>\n<ol>\n<li>freenom<a href=\"http://xn--yexiang-i22m.ml\">yexiang.ml</a></li>\n<li>DNSpodAgithub page</li>\n</ol>\n"},{"title":"Experiments","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-12-17T02:00:56.000Z","password":null,"summary":null,"description":"diy","_content":"\n\n\n# Deep Learning\n\n## Feature Map Multiplication\n\n### dataset: Caltech101\n\n[source code](https://github.com/xyegithub/Featrue-map-multiplication)\n\n3\n\n/media/new_2t/yexiang/image_classification/multiply/from_#1/ffmnst/Caltech101\n\n#### bnsig\n\n|                                                          | accuracy |\n| ------------------------------------------------------------ | -------- |\n| `out = self.bn(out) + self.shortcut(x) `                     | 87.62    |\n| `out = (out.sigmoid() + 1)* self.bn_s(self.shortcut(x))`     | 78.23    |\n| `out = (self.bn(out).sigmoid() + 1) * self.bn_s(self.shortcut(x))` | 78.69    |\n| `(self.bn(out).sigmoid() + 0.5) * self.bn_s(self.shortcut(x)) ` | 78.57    |\n| `self.bn_s.bias.data[:]=1`<br>`out = (self.bn(out).sigmoid() + 1) * self.bn_s(self.shortcut(x))    ` | 82.26    |\n| `self.bn_s.bias.data[:]=1`  <br>`out = (self.bn(out).sigmoid() + 0.5) * self.bn_s(self.shortcut(x)) ` | 84.10    |\n| ` self.bn.bias.data[:]=0`<br>`self.bn_s.bias.data[:]=1`<br>` out = (self.bn(out).sigmoid() + 0.5) * self.bn_s(self.shortcut(x))             ` | 84.85    |\n| `self.bn.bias.data[:]=0`<br>`self.bn_s.bias.data[:]=1`<br>`out = (self.bn(out).sigmoid()) * self.bn_s(self.shortcut(x))` | 85.83    |\n| `self.bn.bias.data[:]=0`<br>`self.bn.weight.data[:]=1`<br>`self.bn_s.bias.data[:]=1`<br>`out = (self.bn(out).sigmoid()) * self.bn_s(self.shortcut(x))` | 81.57    |\n\n1. shortcut1\n2. Ressigmoid0.51sigmoidsigmoid0sigmoid0.5\n3. Ressigmoidoutbn0bn\n\n#### sig, bn\n\n|                                                          | accuracy |\n| ------------------------------------------------------------ | -------- |\n| `out = self.bn(out) + self.shortcut(x) `                     | 87.62    |\n| `out = (self.shortcut(x).sigmoid() + 1)* self.bn_s(out)`     | 83.93    |\n| `out = (self.bn(self.shortcut(x)).sigmoid() + 1) * self.bn_s(out)` | 85.54    |\n| `(self.bn(self.shortcut(x)).sigmoid() + 0.5) * self.bn_s(out) ` | 85.14    |\n| `self.bn_s.bias.data[:]=1`<br>`out = (self.bn(self.shortcut(x)).sigmoid() + 1) * self.bn_s(out)    ` | 85.43    |\n| `self.bn_s.bias.data[:]=1`  <br>`out = (self.bn(self.shortcut(x)).sigmoid() + 0.5) * self.bn_s(out) ` | 87.44    |\n| ` self.bn.bias.data[:]=0`<br>`self.bn_s.bias.data[:]=1`<br>` out = (self.bn(self.shortcut(x)).sigmoid() + 0.5) * self.bn_s(out)             ` | 84.39    |\n| `self.bn.bias.data[:]=0`<br>`self.bn_s.bias.data[:]=1`<br>`out = (self.bn(self.shortcut(x)).sigmoid()) * self.bn_s(out)` | 84.39    |\n| `self.bn.bias.data[:]=0`<br>`self.bn.weight.data[:]=1`<br>`self.bn_s.bias.data[:]=1`<br>`out = (self.bn(self.shortcut(x)).sigmoid()) * self.bn_s(out)` | 84.91    |\n\n**sig, bnbn, sigsigshortcutsigmoidshortcut**\n\n#### bn, bn\n\n|                                                          | Accuracy |\n| ------------------------------------------------------------ | -------- |\n| `out = self.bn(out)* self.bn_s(self.shortcut(x))`            | 77.13    |\n| `self.bn_s.bias.data[:]=1`<br>`out = self.bn(out)* self.bn_s(self.shortcut(x)) ` | 75.75    |\n| `self.bn.bias.data[:] = 1`<br>`out = self.bn(out)* self.bn_s(self.shortcut(x))` | 79.55    |\n| `self.bn.bias.data[:]=1`<br>`self.bn_s.bias.data[:]=1`<br>`out = self.bn(out)* self.bn_s(self.shortcut(x))` | 81.39    |\n| `self.bn.bias.data[:]=1`<br>`self.bn.weight.data[:]=1`<br>`self.bn_s.bias.data[:]=1`<br>`out = self.bn(out)* self.bn_s(self.shortcut(x))` | 81.05    |\n| `self.bn.bias.data[:]=1`<br>`self.bn_s.bias.data[:]=1`<br>`self.bn_s.weight.data[:]=1`<br>`out = self.bn(out)* self.bn_s(self.shortcut(x))` | 80.24    |\n| `self.bn.bias.data[:]=1`<br>`self.bn.weight.data[:]=1`<br>`self.bn_s.bias.data[:]=1`<br>`self.bn_s.weight.data[:]=1`<br>`out = self.bn(out)* self.bn_s(self.shortcut(x))` | 81.22    |\n\n1bn\n\n#### sig, sig\n\n|                                                          | Accuracy |\n| ------------------------------------------------------------ | -------- |\n| `out = (self.shortcut(x).sigmoid()) * out.sigmoid())`        | 79.44    |\n| `out = (self.shortcut(x).sigmoid()) * (out.sigmoid() + 0.5)` | 70.05    |\n| `out = (self.shortcut(x).sigmoid() + 0.5) * (out.sigmoid())` | 76.61    |\n| `out = (self.shortcut(x).sigmoid()) * (out.sigmoid() + 1)`   | 72.64    |\n| `out = (self.shortcut(x).sigmoid() + 1) * (out.sigmoid())`   | 71.77    |\n\nbnsigmoidbn\n\n|                                                          | Accuracy |\n| ------------------------------------------------------------ | -------- |\n| `out = (self.shortcut(x).sigmoid()) * self.bn(out).sigmoid()` | 86.69    |\n| `out = (self.bn_s(self.shortcut(x)).sigmoid()) * out.sigmoid()` | 79.90    |\n| `self.bn_s.bias.data[:]=0`<br>`out = (self.bn_s(self.shortcut(x)).sigmoid()) * out.sigmoid()` | 76.32    |\n| `self.bn.bias.data[:]=0`<br>`out = (self.shortcut(x).sigmoid()) * self.bn(out).sigmoid()` | 83.99    |\n| `self.bn.bias.data[:]=0 `<br>` out = (self.shortcut(x).sigmoid()) * (self.bn(out).sigmoid() + 0.5)` | 86.52    |\n| `self.bn.bias.data[:]=0 `<br>`out = (self.shortcut(x).sigmoid()) * (self.bn(out).sigmoid() + 1) ` | 82.83    |\n| `self.bn.weight.data[:]=1`<br>`out = (self.shortcut(x).sigmoid()) * self.bn(out).sigmoid()` | 78.74    |\n| `self.bn_s.bias.data[:]=0`<br>`out = (self.bn_s(self.shortcut(x)).sigmoid() + 0.5) * out.sigmoid()` | 73.39    |\n\nbn\n\n|                                                          | Accuracy |\n| ------------------------------------------------------------ | -------- |\n| ` out = (self.bn_s(self.shortcut(x)).sigmoid()) * self.bn(out).sigmoid()` | 86.23    |\n| `self.bn.bias.data[:]=0`<br>`out = (self.bn_s(self.shortcut(x)).sigmoid()) * self.bn(out).sigmoid()` | 86.41    |\n| `self.bn.bias.data[:]=0`<br>`out = (self.bn_s(self.shortcut(x)).sigmoid()) * (self.bn(out).sigmoid() + 1)` | 85.83    |\n| `self.bn.bias.data[:]=0`<br>`out = (self.bn_s(self.shortcut(x)).sigmoid()) * (self.bn(out).sigmoid() + 0.5)` | 86.23    |\n| `self.bn.bias.data[:]=0`<br>`self.bn_s.bias.data[:]=0`<br/>`out = (self.bn_s(self.shortcut(x)).sigmoid()) * self.bn(out).sigmoid()` | 86.52    |\n| `self.bn.bias.data[:]=0`<br/>`self.bn_s.bias.data[:]=0`<br/>`self.bn_s.weight.data[:]=1`<br>`out = (self.bn_s(self.shortcut(x)).sigmoid()) * self.bn(out).sigmoid()` | 82.49    |\n| `self.bn.bias.data[:]=0`<br/>`self.bn.weight.data[:]=1`<br/>`self.bn_s.bias.data[:]=0`<br>`out = (self.bn_s(self.shortcut(x)).sigmoid()) * self.bn(out).sigmoid()` | 83.47    |\n| `self.bn.bias.data[:]=0`<br>`self.bn_s.bias.data[:]=0`<br>`out = (self.bn_s(self.shortcut(x)).sigmoid()) * (self.bn(out).sigmoid() + 0.5)` | 84.91    |\n| `self.bn.bias.data[:]=0`<br/>`self.bn_s.bias.data[:]=0`<br/>`out = (self.bn_s(self.shortcut(x)).sigmoid() + 0.5) * self.bn(out).sigmoid())` | 86.92    |\n| `self.bn.bias.data[:]=0`<br/>`self.bn_s.bias.data[:]=0`<br/>`out = (self.bn_s(self.shortcut(x)).sigmoid() + 1) * self.bn(out).sigmoid())` | 86.75    |\n| `self.bn.bias.data[:]=0`<br/>`self.bn_s.bias.data[:]=0`<br/>`out = (self.bn_s(self.shortcut(x)).sigmoid() + 0.5) * (self.bn(out).sigmoid() + 0.5)` | 84.79    |\n| `self.bn.weight.data[:]=1`<br>`out = (self.bn_s(self.shortcut(x)).sigmoid()) * self.bn(out).sigmoid()` | 81.91    |\n| `self.bn_s.weight.data[:]=1`<br>`out = (self.bn_s(self.shortcut(x)).sigmoid()) * self.bn(out).sigmoid()` | 80.93    |\n\n#### Resdual \n\n|                                                          | Accuracy |\n| ------------------------------------------------------------ | -------- |\n| `out_1 = F.relu(self.bn2(out_1))`<br>`out *= self.adap(out_1)` | 86.06    |\n| `out_1 = F.relu(self.bn2(out_1))`<br>`out *= self.adap(out_1).sigmoid()` | 87.33    |\n| `out_1 = self.bn2(out_1)`<br>`out = self.conv2(out_1)`<br>`out *= self.adap(out_1).sigmoid()` | 85.71    |\n| `out_1 = self.bn2(out_1)`<br/>`out = self.conv2(out_1.relu())`<br/>`out *= self.adap(out_1).sigmoid()` | 87.85    |\n| `self.bn2.bias.data[:]=0`<br>`out_1 = self.bn2(out_1)`<br>`out = self.conv2(out_1)`<br>`out *= self.adap(out_1).sigmoid()` | 86.64    |\n| `self.bn2.bias.data[:]=0`<br/>`out_1 = self.bn2(out_1)`<br/>`out = self.conv2(out_1.relu())`<br/>`out *= self.adap(out_1).sigmoid()` | 81.51    |\n| `self.bn2.bias.data[:]=0`<br/>`out_1 = self.bn2(out_1)`<br/>`out = self.conv2(out_1.sigmoid())`<br/>`out *= self.adap(out_1).sigmoid()` | 82.66    |\n| `out_1 = F.relu(self.bn2(out_1))`<br>`out = self.conv2(out_1).sigmoid()`<br>`out = self.adap(out_1) * out` | 84.22    |\n|                                                              |          |\n\n#### NAM\n\n1. sigmoid\n2. sigmoidbn\n3. 1\n\n\n$$\n\\begin{align}\natt &= norm(x) \\\\\natt &= att \\times \\gamma + \\delta \\\\\natt &= att \\times \\frac\\gamma{sum(\\gamma)} \\\\\nout &= att.sigmoid() \\times x\n\\end{align}\n$$\n\n|                                  | Accuracy |\n| ------------------------------------ | -------- |\n| `out = self.nam(x) + self.bn_s(out)` | 86.41    |\n\n","source":"_posts/Experiments.md","raw":"---\ntitle: Experiments\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-12-17 10:00:56\npassword:\nsummary:\ndescription: diy\ncategories:\n- Experiments\ntags:\n- Personal Thought\n- Experiments\n- private\n---\n\n\n\n# Deep Learning\n\n## Feature Map Multiplication\n\n### dataset: Caltech101\n\n[source code](https://github.com/xyegithub/Featrue-map-multiplication)\n\n3\n\n/media/new_2t/yexiang/image_classification/multiply/from_#1/ffmnst/Caltech101\n\n#### bnsig\n\n|                                                          | accuracy |\n| ------------------------------------------------------------ | -------- |\n| `out = self.bn(out) + self.shortcut(x) `                     | 87.62    |\n| `out = (out.sigmoid() + 1)* self.bn_s(self.shortcut(x))`     | 78.23    |\n| `out = (self.bn(out).sigmoid() + 1) * self.bn_s(self.shortcut(x))` | 78.69    |\n| `(self.bn(out).sigmoid() + 0.5) * self.bn_s(self.shortcut(x)) ` | 78.57    |\n| `self.bn_s.bias.data[:]=1`<br>`out = (self.bn(out).sigmoid() + 1) * self.bn_s(self.shortcut(x))    ` | 82.26    |\n| `self.bn_s.bias.data[:]=1`  <br>`out = (self.bn(out).sigmoid() + 0.5) * self.bn_s(self.shortcut(x)) ` | 84.10    |\n| ` self.bn.bias.data[:]=0`<br>`self.bn_s.bias.data[:]=1`<br>` out = (self.bn(out).sigmoid() + 0.5) * self.bn_s(self.shortcut(x))             ` | 84.85    |\n| `self.bn.bias.data[:]=0`<br>`self.bn_s.bias.data[:]=1`<br>`out = (self.bn(out).sigmoid()) * self.bn_s(self.shortcut(x))` | 85.83    |\n| `self.bn.bias.data[:]=0`<br>`self.bn.weight.data[:]=1`<br>`self.bn_s.bias.data[:]=1`<br>`out = (self.bn(out).sigmoid()) * self.bn_s(self.shortcut(x))` | 81.57    |\n\n1. shortcut1\n2. Ressigmoid0.51sigmoidsigmoid0sigmoid0.5\n3. Ressigmoidoutbn0bn\n\n#### sig, bn\n\n|                                                          | accuracy |\n| ------------------------------------------------------------ | -------- |\n| `out = self.bn(out) + self.shortcut(x) `                     | 87.62    |\n| `out = (self.shortcut(x).sigmoid() + 1)* self.bn_s(out)`     | 83.93    |\n| `out = (self.bn(self.shortcut(x)).sigmoid() + 1) * self.bn_s(out)` | 85.54    |\n| `(self.bn(self.shortcut(x)).sigmoid() + 0.5) * self.bn_s(out) ` | 85.14    |\n| `self.bn_s.bias.data[:]=1`<br>`out = (self.bn(self.shortcut(x)).sigmoid() + 1) * self.bn_s(out)    ` | 85.43    |\n| `self.bn_s.bias.data[:]=1`  <br>`out = (self.bn(self.shortcut(x)).sigmoid() + 0.5) * self.bn_s(out) ` | 87.44    |\n| ` self.bn.bias.data[:]=0`<br>`self.bn_s.bias.data[:]=1`<br>` out = (self.bn(self.shortcut(x)).sigmoid() + 0.5) * self.bn_s(out)             ` | 84.39    |\n| `self.bn.bias.data[:]=0`<br>`self.bn_s.bias.data[:]=1`<br>`out = (self.bn(self.shortcut(x)).sigmoid()) * self.bn_s(out)` | 84.39    |\n| `self.bn.bias.data[:]=0`<br>`self.bn.weight.data[:]=1`<br>`self.bn_s.bias.data[:]=1`<br>`out = (self.bn(self.shortcut(x)).sigmoid()) * self.bn_s(out)` | 84.91    |\n\n**sig, bnbn, sigsigshortcutsigmoidshortcut**\n\n#### bn, bn\n\n|                                                          | Accuracy |\n| ------------------------------------------------------------ | -------- |\n| `out = self.bn(out)* self.bn_s(self.shortcut(x))`            | 77.13    |\n| `self.bn_s.bias.data[:]=1`<br>`out = self.bn(out)* self.bn_s(self.shortcut(x)) ` | 75.75    |\n| `self.bn.bias.data[:] = 1`<br>`out = self.bn(out)* self.bn_s(self.shortcut(x))` | 79.55    |\n| `self.bn.bias.data[:]=1`<br>`self.bn_s.bias.data[:]=1`<br>`out = self.bn(out)* self.bn_s(self.shortcut(x))` | 81.39    |\n| `self.bn.bias.data[:]=1`<br>`self.bn.weight.data[:]=1`<br>`self.bn_s.bias.data[:]=1`<br>`out = self.bn(out)* self.bn_s(self.shortcut(x))` | 81.05    |\n| `self.bn.bias.data[:]=1`<br>`self.bn_s.bias.data[:]=1`<br>`self.bn_s.weight.data[:]=1`<br>`out = self.bn(out)* self.bn_s(self.shortcut(x))` | 80.24    |\n| `self.bn.bias.data[:]=1`<br>`self.bn.weight.data[:]=1`<br>`self.bn_s.bias.data[:]=1`<br>`self.bn_s.weight.data[:]=1`<br>`out = self.bn(out)* self.bn_s(self.shortcut(x))` | 81.22    |\n\n1bn\n\n#### sig, sig\n\n|                                                          | Accuracy |\n| ------------------------------------------------------------ | -------- |\n| `out = (self.shortcut(x).sigmoid()) * out.sigmoid())`        | 79.44    |\n| `out = (self.shortcut(x).sigmoid()) * (out.sigmoid() + 0.5)` | 70.05    |\n| `out = (self.shortcut(x).sigmoid() + 0.5) * (out.sigmoid())` | 76.61    |\n| `out = (self.shortcut(x).sigmoid()) * (out.sigmoid() + 1)`   | 72.64    |\n| `out = (self.shortcut(x).sigmoid() + 1) * (out.sigmoid())`   | 71.77    |\n\nbnsigmoidbn\n\n|                                                          | Accuracy |\n| ------------------------------------------------------------ | -------- |\n| `out = (self.shortcut(x).sigmoid()) * self.bn(out).sigmoid()` | 86.69    |\n| `out = (self.bn_s(self.shortcut(x)).sigmoid()) * out.sigmoid()` | 79.90    |\n| `self.bn_s.bias.data[:]=0`<br>`out = (self.bn_s(self.shortcut(x)).sigmoid()) * out.sigmoid()` | 76.32    |\n| `self.bn.bias.data[:]=0`<br>`out = (self.shortcut(x).sigmoid()) * self.bn(out).sigmoid()` | 83.99    |\n| `self.bn.bias.data[:]=0 `<br>` out = (self.shortcut(x).sigmoid()) * (self.bn(out).sigmoid() + 0.5)` | 86.52    |\n| `self.bn.bias.data[:]=0 `<br>`out = (self.shortcut(x).sigmoid()) * (self.bn(out).sigmoid() + 1) ` | 82.83    |\n| `self.bn.weight.data[:]=1`<br>`out = (self.shortcut(x).sigmoid()) * self.bn(out).sigmoid()` | 78.74    |\n| `self.bn_s.bias.data[:]=0`<br>`out = (self.bn_s(self.shortcut(x)).sigmoid() + 0.5) * out.sigmoid()` | 73.39    |\n\nbn\n\n|                                                          | Accuracy |\n| ------------------------------------------------------------ | -------- |\n| ` out = (self.bn_s(self.shortcut(x)).sigmoid()) * self.bn(out).sigmoid()` | 86.23    |\n| `self.bn.bias.data[:]=0`<br>`out = (self.bn_s(self.shortcut(x)).sigmoid()) * self.bn(out).sigmoid()` | 86.41    |\n| `self.bn.bias.data[:]=0`<br>`out = (self.bn_s(self.shortcut(x)).sigmoid()) * (self.bn(out).sigmoid() + 1)` | 85.83    |\n| `self.bn.bias.data[:]=0`<br>`out = (self.bn_s(self.shortcut(x)).sigmoid()) * (self.bn(out).sigmoid() + 0.5)` | 86.23    |\n| `self.bn.bias.data[:]=0`<br>`self.bn_s.bias.data[:]=0`<br/>`out = (self.bn_s(self.shortcut(x)).sigmoid()) * self.bn(out).sigmoid()` | 86.52    |\n| `self.bn.bias.data[:]=0`<br/>`self.bn_s.bias.data[:]=0`<br/>`self.bn_s.weight.data[:]=1`<br>`out = (self.bn_s(self.shortcut(x)).sigmoid()) * self.bn(out).sigmoid()` | 82.49    |\n| `self.bn.bias.data[:]=0`<br/>`self.bn.weight.data[:]=1`<br/>`self.bn_s.bias.data[:]=0`<br>`out = (self.bn_s(self.shortcut(x)).sigmoid()) * self.bn(out).sigmoid()` | 83.47    |\n| `self.bn.bias.data[:]=0`<br>`self.bn_s.bias.data[:]=0`<br>`out = (self.bn_s(self.shortcut(x)).sigmoid()) * (self.bn(out).sigmoid() + 0.5)` | 84.91    |\n| `self.bn.bias.data[:]=0`<br/>`self.bn_s.bias.data[:]=0`<br/>`out = (self.bn_s(self.shortcut(x)).sigmoid() + 0.5) * self.bn(out).sigmoid())` | 86.92    |\n| `self.bn.bias.data[:]=0`<br/>`self.bn_s.bias.data[:]=0`<br/>`out = (self.bn_s(self.shortcut(x)).sigmoid() + 1) * self.bn(out).sigmoid())` | 86.75    |\n| `self.bn.bias.data[:]=0`<br/>`self.bn_s.bias.data[:]=0`<br/>`out = (self.bn_s(self.shortcut(x)).sigmoid() + 0.5) * (self.bn(out).sigmoid() + 0.5)` | 84.79    |\n| `self.bn.weight.data[:]=1`<br>`out = (self.bn_s(self.shortcut(x)).sigmoid()) * self.bn(out).sigmoid()` | 81.91    |\n| `self.bn_s.weight.data[:]=1`<br>`out = (self.bn_s(self.shortcut(x)).sigmoid()) * self.bn(out).sigmoid()` | 80.93    |\n\n#### Resdual \n\n|                                                          | Accuracy |\n| ------------------------------------------------------------ | -------- |\n| `out_1 = F.relu(self.bn2(out_1))`<br>`out *= self.adap(out_1)` | 86.06    |\n| `out_1 = F.relu(self.bn2(out_1))`<br>`out *= self.adap(out_1).sigmoid()` | 87.33    |\n| `out_1 = self.bn2(out_1)`<br>`out = self.conv2(out_1)`<br>`out *= self.adap(out_1).sigmoid()` | 85.71    |\n| `out_1 = self.bn2(out_1)`<br/>`out = self.conv2(out_1.relu())`<br/>`out *= self.adap(out_1).sigmoid()` | 87.85    |\n| `self.bn2.bias.data[:]=0`<br>`out_1 = self.bn2(out_1)`<br>`out = self.conv2(out_1)`<br>`out *= self.adap(out_1).sigmoid()` | 86.64    |\n| `self.bn2.bias.data[:]=0`<br/>`out_1 = self.bn2(out_1)`<br/>`out = self.conv2(out_1.relu())`<br/>`out *= self.adap(out_1).sigmoid()` | 81.51    |\n| `self.bn2.bias.data[:]=0`<br/>`out_1 = self.bn2(out_1)`<br/>`out = self.conv2(out_1.sigmoid())`<br/>`out *= self.adap(out_1).sigmoid()` | 82.66    |\n| `out_1 = F.relu(self.bn2(out_1))`<br>`out = self.conv2(out_1).sigmoid()`<br>`out = self.adap(out_1) * out` | 84.22    |\n|                                                              |          |\n\n#### NAM\n\n1. sigmoid\n2. sigmoidbn\n3. 1\n\n\n$$\n\\begin{align}\natt &= norm(x) \\\\\natt &= att \\times \\gamma + \\delta \\\\\natt &= att \\times \\frac\\gamma{sum(\\gamma)} \\\\\nout &= att.sigmoid() \\times x\n\\end{align}\n$$\n\n|                                  | Accuracy |\n| ------------------------------------ | -------- |\n| `out = self.nam(x) + self.bn_s(out)` | 86.41    |\n\n","slug":"Experiments","published":1,"updated":"2022-01-17T09:43:07.972Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckzhsa4gf00084fvkal9fhgcp","content":"<div class=\"hbe hbe-container\" id=\"hexo-blog-encrypt\" data-wpm=\"Oh, this is an invalid password. Check and try again, please.\" data-whm=\"OOPS, these decrypted content may changed, but you can still have a look.\">\n  <script id=\"hbeData\" type=\"hbeData\" data-hmacdigest=\"9c27cc54855c76790d00a7f922a52ec375489f017946203bd53e36a96d09df90\">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</script>\n  <div class=\"hbe hbe-content\">\n    <div class=\"hbe hbe-input hbe-input-default\">\n      <input class=\"hbe hbe-input-field hbe-input-field-default\" type=\"password\" id=\"hbePass\">\n      <label class=\"hbe hbe-input-label hbe-input-label-default\" for=\"hbePass\">\n        <span class=\"hbe hbe-input-label-content hbe-input-label-content-default\">Hey, password is required here.</span>\n      </label>\n    </div>\n  </div>\n</div>\n<script data-pjax src=\"/lib/hbe.js\"></script><link href=\"/css/hbe.style.css\" rel=\"stylesheet\" type=\"text/css\">","site":{"data":{}},"excerpt":"","more":"","origin":"<html><head></head><body><h1><span class=\"post-title-index\">1. </span>Deep Learning</h1>\n<h2 id=\"Feature-Map-Multiplication\"><span class=\"post-title-index\">1.1. </span>Feature Map Multiplication</h2>\n<h3 id=\"dataset-Caltech101\"><span class=\"post-title-index\">1.1.1. </span>dataset: Caltech101</h3>\n<p><a href=\"https://github.com/xyegithub/Featrue-map-multiplication\">source code</a></p>\n<p>3</p>\n<p>/media/new_2t/yexiang/image_classification/multiply/from_#1/ffmnst/Caltech101</p>\n<h4 id=\"bnsig\"><span class=\"post-title-index\">1.1.1.1. </span>bnsig</h4>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>accuracy</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>out = self.bn(out) + self.shortcut(x) </code></td>\n<td>87.62</td>\n</tr>\n<tr>\n<td><code>out = (out.sigmoid() + 1)* self.bn_s(self.shortcut(x))</code></td>\n<td>78.23</td>\n</tr>\n<tr>\n<td><code>out = (self.bn(out).sigmoid() + 1) * self.bn_s(self.shortcut(x))</code></td>\n<td>78.69</td>\n</tr>\n<tr>\n<td><code>(self.bn(out).sigmoid() + 0.5) * self.bn_s(self.shortcut(x)) </code></td>\n<td>78.57</td>\n</tr>\n<tr>\n<td><code>self.bn_s.bias.data[:]=1</code><br><code>out = (self.bn(out).sigmoid() + 1) * self.bn_s(self.shortcut(x))    </code></td>\n<td>82.26</td>\n</tr>\n<tr>\n<td><code>self.bn_s.bias.data[:]=1</code>  <br><code>out = (self.bn(out).sigmoid() + 0.5) * self.bn_s(self.shortcut(x)) </code></td>\n<td>84.10</td>\n</tr>\n<tr>\n<td><code> self.bn.bias.data[:]=0</code><br><code>self.bn_s.bias.data[:]=1</code><br><code>out = (self.bn(out).sigmoid() + 0.5) * self.bn_s(self.shortcut(x))            </code></td>\n<td>84.85</td>\n</tr>\n<tr>\n<td><code>self.bn.bias.data[:]=0</code><br><code>self.bn_s.bias.data[:]=1</code><br><code>out = (self.bn(out).sigmoid()) * self.bn_s(self.shortcut(x))</code></td>\n<td>85.83</td>\n</tr>\n<tr>\n<td><code>self.bn.bias.data[:]=0</code><br><code>self.bn.weight.data[:]=1</code><br><code>self.bn_s.bias.data[:]=1</code><br><code>out = (self.bn(out).sigmoid()) * self.bn_s(self.shortcut(x))</code></td>\n<td>81.57</td>\n</tr>\n</tbody>\n</table>\n<ol>\n<li>shortcut1</li>\n<li>Ressigmoid0.51sigmoidsigmoid0sigmoid0.5</li>\n<li>Ressigmoidoutbn0bn</li>\n</ol>\n<h4 id=\"sig-bn\"><span class=\"post-title-index\">1.1.1.2. </span>sig, bn</h4>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>accuracy</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>out = self.bn(out) + self.shortcut(x) </code></td>\n<td>87.62</td>\n</tr>\n<tr>\n<td><code>out = (self.shortcut(x).sigmoid() + 1)* self.bn_s(out)</code></td>\n<td>83.93</td>\n</tr>\n<tr>\n<td><code>out = (self.bn(self.shortcut(x)).sigmoid() + 1) * self.bn_s(out)</code></td>\n<td>85.54</td>\n</tr>\n<tr>\n<td><code>(self.bn(self.shortcut(x)).sigmoid() + 0.5) * self.bn_s(out) </code></td>\n<td>85.14</td>\n</tr>\n<tr>\n<td><code>self.bn_s.bias.data[:]=1</code><br><code>out = (self.bn(self.shortcut(x)).sigmoid() + 1) * self.bn_s(out)    </code></td>\n<td>85.43</td>\n</tr>\n<tr>\n<td><code>self.bn_s.bias.data[:]=1</code>  <br><code>out = (self.bn(self.shortcut(x)).sigmoid() + 0.5) * self.bn_s(out) </code></td>\n<td>87.44</td>\n</tr>\n<tr>\n<td><code> self.bn.bias.data[:]=0</code><br><code>self.bn_s.bias.data[:]=1</code><br><code>out = (self.bn(self.shortcut(x)).sigmoid() + 0.5) * self.bn_s(out)            </code></td>\n<td>84.39</td>\n</tr>\n<tr>\n<td><code>self.bn.bias.data[:]=0</code><br><code>self.bn_s.bias.data[:]=1</code><br><code>out = (self.bn(self.shortcut(x)).sigmoid()) * self.bn_s(out)</code></td>\n<td>84.39</td>\n</tr>\n<tr>\n<td><code>self.bn.bias.data[:]=0</code><br><code>self.bn.weight.data[:]=1</code><br><code>self.bn_s.bias.data[:]=1</code><br><code>out = (self.bn(self.shortcut(x)).sigmoid()) * self.bn_s(out)</code></td>\n<td>84.91</td>\n</tr>\n</tbody>\n</table>\n<p><strong>sig, bnbn, sigsigshortcutsigmoidshortcut</strong></p>\n<h4 id=\"bn-bn\"><span class=\"post-title-index\">1.1.1.3. </span>bn, bn</h4>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>Accuracy</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>out = self.bn(out)* self.bn_s(self.shortcut(x))</code></td>\n<td>77.13</td>\n</tr>\n<tr>\n<td><code>self.bn_s.bias.data[:]=1</code><br><code>out = self.bn(out)* self.bn_s(self.shortcut(x)) </code></td>\n<td>75.75</td>\n</tr>\n<tr>\n<td><code>self.bn.bias.data[:] = 1</code><br><code>out = self.bn(out)* self.bn_s(self.shortcut(x))</code></td>\n<td>79.55</td>\n</tr>\n<tr>\n<td><code>self.bn.bias.data[:]=1</code><br><code>self.bn_s.bias.data[:]=1</code><br><code>out = self.bn(out)* self.bn_s(self.shortcut(x))</code></td>\n<td>81.39</td>\n</tr>\n<tr>\n<td><code>self.bn.bias.data[:]=1</code><br><code>self.bn.weight.data[:]=1</code><br><code>self.bn_s.bias.data[:]=1</code><br><code>out = self.bn(out)* self.bn_s(self.shortcut(x))</code></td>\n<td>81.05</td>\n</tr>\n<tr>\n<td><code>self.bn.bias.data[:]=1</code><br><code>self.bn_s.bias.data[:]=1</code><br><code>self.bn_s.weight.data[:]=1</code><br><code>out = self.bn(out)* self.bn_s(self.shortcut(x))</code></td>\n<td>80.24</td>\n</tr>\n<tr>\n<td><code>self.bn.bias.data[:]=1</code><br><code>self.bn.weight.data[:]=1</code><br><code>self.bn_s.bias.data[:]=1</code><br><code>self.bn_s.weight.data[:]=1</code><br><code>out = self.bn(out)* self.bn_s(self.shortcut(x))</code></td>\n<td>81.22</td>\n</tr>\n</tbody>\n</table>\n<p>1bn</p>\n<h4 id=\"sig-sig\"><span class=\"post-title-index\">1.1.1.4. </span>sig, sig</h4>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>Accuracy</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>out = (self.shortcut(x).sigmoid()) * out.sigmoid())</code></td>\n<td>79.44</td>\n</tr>\n<tr>\n<td><code>out = (self.shortcut(x).sigmoid()) * (out.sigmoid() + 0.5)</code></td>\n<td>70.05</td>\n</tr>\n<tr>\n<td><code>out = (self.shortcut(x).sigmoid() + 0.5) * (out.sigmoid())</code></td>\n<td>76.61</td>\n</tr>\n<tr>\n<td><code>out = (self.shortcut(x).sigmoid()) * (out.sigmoid() + 1)</code></td>\n<td>72.64</td>\n</tr>\n<tr>\n<td><code>out = (self.shortcut(x).sigmoid() + 1) * (out.sigmoid())</code></td>\n<td>71.77</td>\n</tr>\n</tbody>\n</table>\n<p>bnsigmoidbn</p>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>Accuracy</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>out = (self.shortcut(x).sigmoid()) * self.bn(out).sigmoid()</code></td>\n<td>86.69</td>\n</tr>\n<tr>\n<td><code>out = (self.bn_s(self.shortcut(x)).sigmoid()) * out.sigmoid()</code></td>\n<td>79.90</td>\n</tr>\n<tr>\n<td><code>self.bn_s.bias.data[:]=0</code><br><code>out = (self.bn_s(self.shortcut(x)).sigmoid()) * out.sigmoid()</code></td>\n<td>76.32</td>\n</tr>\n<tr>\n<td><code>self.bn.bias.data[:]=0</code><br><code>out = (self.shortcut(x).sigmoid()) * self.bn(out).sigmoid()</code></td>\n<td>83.99</td>\n</tr>\n<tr>\n<td><code>self.bn.bias.data[:]=0 </code><br><code> out = (self.shortcut(x).sigmoid()) * (self.bn(out).sigmoid() + 0.5)</code></td>\n<td>86.52</td>\n</tr>\n<tr>\n<td><code>self.bn.bias.data[:]=0 </code><br><code>out = (self.shortcut(x).sigmoid()) * (self.bn(out).sigmoid() + 1) </code></td>\n<td>82.83</td>\n</tr>\n<tr>\n<td><code>self.bn.weight.data[:]=1</code><br><code>out = (self.shortcut(x).sigmoid()) * self.bn(out).sigmoid()</code></td>\n<td>78.74</td>\n</tr>\n<tr>\n<td><code>self.bn_s.bias.data[:]=0</code><br><code>out = (self.bn_s(self.shortcut(x)).sigmoid() + 0.5) * out.sigmoid()</code></td>\n<td>73.39</td>\n</tr>\n</tbody>\n</table>\n<p>bn</p>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>Accuracy</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code> out = (self.bn_s(self.shortcut(x)).sigmoid()) * self.bn(out).sigmoid()</code></td>\n<td>86.23</td>\n</tr>\n<tr>\n<td><code>self.bn.bias.data[:]=0</code><br><code>out = (self.bn_s(self.shortcut(x)).sigmoid()) * self.bn(out).sigmoid()</code></td>\n<td>86.41</td>\n</tr>\n<tr>\n<td><code>self.bn.bias.data[:]=0</code><br><code>out = (self.bn_s(self.shortcut(x)).sigmoid()) * (self.bn(out).sigmoid() + 1)</code></td>\n<td>85.83</td>\n</tr>\n<tr>\n<td><code>self.bn.bias.data[:]=0</code><br><code>out = (self.bn_s(self.shortcut(x)).sigmoid()) * (self.bn(out).sigmoid() + 0.5)</code></td>\n<td>86.23</td>\n</tr>\n<tr>\n<td><code>self.bn.bias.data[:]=0</code><br><code>self.bn_s.bias.data[:]=0</code><br><code>out = (self.bn_s(self.shortcut(x)).sigmoid()) * self.bn(out).sigmoid()</code></td>\n<td>86.52</td>\n</tr>\n<tr>\n<td><code>self.bn.bias.data[:]=0</code><br><code>self.bn_s.bias.data[:]=0</code><br><code>self.bn_s.weight.data[:]=1</code><br><code>out = (self.bn_s(self.shortcut(x)).sigmoid()) * self.bn(out).sigmoid()</code></td>\n<td>82.49</td>\n</tr>\n<tr>\n<td><code>self.bn.bias.data[:]=0</code><br><code>self.bn.weight.data[:]=1</code><br><code>self.bn_s.bias.data[:]=0</code><br><code>out = (self.bn_s(self.shortcut(x)).sigmoid()) * self.bn(out).sigmoid()</code></td>\n<td>83.47</td>\n</tr>\n<tr>\n<td><code>self.bn.bias.data[:]=0</code><br><code>self.bn_s.bias.data[:]=0</code><br><code>out = (self.bn_s(self.shortcut(x)).sigmoid()) * (self.bn(out).sigmoid() + 0.5)</code></td>\n<td>84.91</td>\n</tr>\n<tr>\n<td><code>self.bn.bias.data[:]=0</code><br><code>self.bn_s.bias.data[:]=0</code><br><code>out = (self.bn_s(self.shortcut(x)).sigmoid() + 0.5) * self.bn(out).sigmoid())</code></td>\n<td>86.92</td>\n</tr>\n<tr>\n<td><code>self.bn.bias.data[:]=0</code><br><code>self.bn_s.bias.data[:]=0</code><br><code>out = (self.bn_s(self.shortcut(x)).sigmoid() + 1) * self.bn(out).sigmoid())</code></td>\n<td>86.75</td>\n</tr>\n<tr>\n<td><code>self.bn.bias.data[:]=0</code><br><code>self.bn_s.bias.data[:]=0</code><br><code>out = (self.bn_s(self.shortcut(x)).sigmoid() + 0.5) * (self.bn(out).sigmoid() + 0.5)</code></td>\n<td>84.79</td>\n</tr>\n<tr>\n<td><code>self.bn.weight.data[:]=1</code><br><code>out = (self.bn_s(self.shortcut(x)).sigmoid()) * self.bn(out).sigmoid()</code></td>\n<td>81.91</td>\n</tr>\n<tr>\n<td><code>self.bn_s.weight.data[:]=1</code><br><code>out = (self.bn_s(self.shortcut(x)).sigmoid()) * self.bn(out).sigmoid()</code></td>\n<td>80.93</td>\n</tr>\n</tbody>\n</table>\n<h4 id=\"Resdual-\"><span class=\"post-title-index\">1.1.1.5. </span>Resdual </h4>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>Accuracy</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>out_1 = F.relu(self.bn2(out_1))</code><br><code>out *= self.adap(out_1)</code></td>\n<td>86.06</td>\n</tr>\n<tr>\n<td><code>out_1 = F.relu(self.bn2(out_1))</code><br><code>out *= self.adap(out_1).sigmoid()</code></td>\n<td>87.33</td>\n</tr>\n<tr>\n<td><code>out_1 = self.bn2(out_1)</code><br><code>out = self.conv2(out_1)</code><br><code>out *= self.adap(out_1).sigmoid()</code></td>\n<td>85.71</td>\n</tr>\n<tr>\n<td><code>out_1 = self.bn2(out_1)</code><br><code>out = self.conv2(out_1.relu())</code><br><code>out *= self.adap(out_1).sigmoid()</code></td>\n<td>87.85</td>\n</tr>\n<tr>\n<td><code>self.bn2.bias.data[:]=0</code><br><code>out_1 = self.bn2(out_1)</code><br><code>out = self.conv2(out_1)</code><br><code>out *= self.adap(out_1).sigmoid()</code></td>\n<td>86.64</td>\n</tr>\n<tr>\n<td><code>self.bn2.bias.data[:]=0</code><br><code>out_1 = self.bn2(out_1)</code><br><code>out = self.conv2(out_1.relu())</code><br><code>out *= self.adap(out_1).sigmoid()</code></td>\n<td>81.51</td>\n</tr>\n<tr>\n<td><code>self.bn2.bias.data[:]=0</code><br><code>out_1 = self.bn2(out_1)</code><br><code>out = self.conv2(out_1.sigmoid())</code><br><code>out *= self.adap(out_1).sigmoid()</code></td>\n<td>82.66</td>\n</tr>\n<tr>\n<td><code>out_1 = F.relu(self.bn2(out_1))</code><br><code>out = self.conv2(out_1).sigmoid()</code><br><code>out = self.adap(out_1) * out</code></td>\n<td>84.22</td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n</tr>\n</tbody>\n</table>\n<h4 id=\"NAM\"><span class=\"post-title-index\">1.1.1.6. </span>NAM</h4>\n<ol>\n<li>sigmoid</li>\n<li>sigmoidbn</li>\n<li>1</li>\n</ol>\n<p>$$\n\\begin{align}\natt &amp;= norm(x) \\\natt &amp;= att \\times \\gamma + \\delta \\\natt &amp;= att \\times \\frac\\gamma{sum(\\gamma)} \\\nout &amp;= att.sigmoid() \\times x\n\\end{align}\n$$</p>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>Accuracy</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>out = self.nam(x) + self.bn_s(out)</code></td>\n<td>86.41</td>\n</tr>\n</tbody>\n</table>\n</body></html>","encrypt":true},{"title":"Foundation for Topological Data Analysis","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-12-30T01:07:39.000Z","password":null,"summary":null,"description":"","_content":"\n# \n\n## \n\n33\n\n1. qq\n2. qq, i.e., qq-1\n3. \n\n23\n\n## \n\n\n\n## \n\n\n\n4. 34\n\n4\n\n## \n\n03\n\n\n\n3qq+1\n\nqq+1q+1\n\nqq+1\n","source":"_posts/Foundation-for-Topological-Data-Analysis.md","raw":"---\ntitle: Foundation for Topological Data Analysis\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-12-30 09:07:39\npassword:\nsummary:\ndescription: \ncategories:\n- Topological Data Analysis\ntags:\n- Topological Data Analysis \n---\n\n# \n\n## \n\n33\n\n1. qq\n2. qq, i.e., qq-1\n3. \n\n23\n\n## \n\n\n\n## \n\n\n\n4. 34\n\n4\n\n## \n\n03\n\n\n\n3qq+1\n\nqq+1q+1\n\nqq+1\n","slug":"Foundation-for-Topological-Data-Analysis","published":1,"updated":"2022-01-17T09:43:07.975Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckzhsa4gl00094fvkb7e035ce","content":"<html><head></head><body><h1><span class=\"post-title-index\">1. </span></h1>\n<h2 id=\"\"><span class=\"post-title-index\">1.1. </span></h2>\n<p>33</p>\n<ol>\n<li>qq</li>\n<li>qq, i.e., qq-1</li>\n<li></li>\n</ol>\n<p>23</p>\n<h2 id=\"\"><span class=\"post-title-index\">1.2. </span></h2>\n<p></p>\n<h2 id=\"\"><span class=\"post-title-index\">1.3. </span></h2>\n<p></p>\n<ol start=\"4\">\n<li>34</li>\n</ol>\n<p>4</p>\n<h2 id=\"\"><span class=\"post-title-index\">1.4. </span></h2>\n<p>03</p>\n<p></p>\n<p>3qq+1</p>\n<p>qq+1q+1</p>\n<p>qq+1</p>\n</body></html>","site":{"data":{}},"excerpt":"<html><head></head><body></body></html>","more":"<h1></h1>\n<h2 id=\"\"></h2>\n<p>33</p>\n<ol>\n<li>qq</li>\n<li>qq, i.e., qq-1</li>\n<li></li>\n</ol>\n<p>23</p>\n<h2 id=\"\"></h2>\n<p></p>\n<h2 id=\"\"></h2>\n<p></p>\n<ol start=\"4\">\n<li>34</li>\n</ol>\n<p>4</p>\n<h2 id=\"\"></h2>\n<p>03</p>\n<p></p>\n<p>3qq+1</p>\n<p>qq+1q+1</p>\n<p>qq+1</p>\n"},{"title":"How to Blance Losses in Multi Task Training","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2022-01-10T06:34:19.000Z","password":null,"summary":null,"description":"loss","_content":"\n# \n\nTask Learning Using Uncertainty to Weigh Losses for Scene Geometry and Semantics\n\nMulti-Task Learning as Multi-Objective Optimization\n\nMulti-Task Learning Using Uncertainty to Weigh Losses for Scene Geometry and Semantics\n\nBounding Box Regression with Uncertainty for Accurate Object Detection\n\nBayesianloss\n\n# Focal loss\n\nDynamic Task Prioritization for Multitask Learning\n\nfocal loss\n\ntasklossKPI (key performance indicator)KPIkpi\n\n batchTask_i  loss_iTask i  KPI: k_i Focal loss FL(k_i, gamma_i) = -((1 - k_i)^gamma_i) * log(k_i)gamma  2\n\nloss = sum(FL(k_i, gamma_i) * loss_i)lossFLloss \n","source":"_posts/How-to-Blance-Losses-in-Multi-Task-Training.md","raw":"---\ntitle: How to Blance Losses in Multi Task Training\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2022-01-10 14:34:19\npassword:\nsummary:\ndescription: loss\ncategories:\n- Little Things\ntags:\n- Multi Task Training\n---\n\n# \n\nTask Learning Using Uncertainty to Weigh Losses for Scene Geometry and Semantics\n\nMulti-Task Learning as Multi-Objective Optimization\n\nMulti-Task Learning Using Uncertainty to Weigh Losses for Scene Geometry and Semantics\n\nBounding Box Regression with Uncertainty for Accurate Object Detection\n\nBayesianloss\n\n# Focal loss\n\nDynamic Task Prioritization for Multitask Learning\n\nfocal loss\n\ntasklossKPI (key performance indicator)KPIkpi\n\n batchTask_i  loss_iTask i  KPI: k_i Focal loss FL(k_i, gamma_i) = -((1 - k_i)^gamma_i) * log(k_i)gamma  2\n\nloss = sum(FL(k_i, gamma_i) * loss_i)lossFLloss \n","slug":"How-to-Blance-Losses-in-Multi-Task-Training","published":1,"updated":"2022-01-17T09:43:07.977Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckzhsa4gp000c4fvk6aascpoc","content":"<html><head></head><body><h1><span class=\"post-title-index\">1. </span></h1>\n<p>Task Learning Using Uncertainty to Weigh Losses for Scene Geometry and Semantics</p>\n<p>Multi-Task Learning as Multi-Objective Optimization</p>\n<p>Multi-Task Learning Using Uncertainty to Weigh Losses for Scene Geometry and Semantics</p>\n<p>Bounding Box Regression with Uncertainty for Accurate Object Detection</p>\n<p>Bayesianloss</p>\n<h1><span class=\"post-title-index\">2. </span>Focal loss</h1>\n<p>Dynamic Task Prioritization for Multitask Learning</p>\n<p>focal loss</p>\n<p>tasklossKPI (key performance indicator)KPIkpi</p>\n<p> batchTask_i  loss_iTask i  KPI: k_i Focal loss FL(k_i, gamma_i) = -((1 - k_i)^gamma_i) * log(k_i)gamma  2</p>\n<p>loss = sum(FL(k_i, gamma_i) * loss_i)lossFLloss</p>\n</body></html>","site":{"data":{}},"excerpt":"<html><head></head><body></body></html>","more":"<h1></h1>\n<p>Task Learning Using Uncertainty to Weigh Losses for Scene Geometry and Semantics</p>\n<p>Multi-Task Learning as Multi-Objective Optimization</p>\n<p>Multi-Task Learning Using Uncertainty to Weigh Losses for Scene Geometry and Semantics</p>\n<p>Bounding Box Regression with Uncertainty for Accurate Object Detection</p>\n<p>Bayesianloss</p>\n<h1>Focal loss</h1>\n<p>Dynamic Task Prioritization for Multitask Learning</p>\n<p>focal loss</p>\n<p>tasklossKPI (key performance indicator)KPIkpi</p>\n<p> batchTask_i  loss_iTask i  KPI: k_i Focal loss FL(k_i, gamma_i) = -((1 - k_i)^gamma_i) * log(k_i)gamma  2</p>\n<p>loss = sum(FL(k_i, gamma_i) * loss_i)lossFLloss</p>\n"},{"title":"Algorithm","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-12-17T08:26:10.000Z","password":null,"summary":null,"description":"","_content":"","source":"_posts/Algorithm.md","raw":"---\ntitle: Algorithm\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-12-17 16:26:10\npassword:\nsummary:\ndescription: \ncategories:\n- Programming\ntags:\n- Algorithm\n- Programming\n---\n","slug":"Algorithm","published":1,"updated":"2022-01-17T09:43:07.967Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckzhsa4gq000d4fvkhzz97how","content":"<html><head></head><body></body></html>","site":{"data":{}},"excerpt":"<html><head></head><body></body></html>","more":""},{"title":"First Step to Reinforcement Learning","date":"2021-12-03T08:48:41.000Z","description":"(Policy Network)(Value Network)","_content":"\n\n\n# \n\n<font color=green size=3></font>\n\n<font color=green size=3></font>\n\n<font color=green size=3></font>\n\n\n\n* S\n* A\n* \n* \n* \n* /\n\n## \n\n****\n\n1\n\n2 agent\n\n<font color=deeppink> agent</font>\n\n\n\n\n\n<font color=deeppink>label</font>\n\n\n\n \n\n## \n\n\n\n## \n\n\n\n\n\n\n\n## \n\n\n\n\n\n\n\n<font color=green></font>\n\n## \n\n1. targetActionPS. targetAction\n\n2. lossloss\n\n   0.1\n\n3. 2\n\n4. ActionActionrewardreward\n\n   ActionrewardActionreward\n\n   <font color=green>Actionrewardreward</font>\n\n5. \n\n   \n\n\n\n\n\n**<font color=green>Actionadvatagereward</font>**\n\n## \n\n\n\nActionscore = 0.1 score\n\n\n\nreward\n\n**<font color=green>actionaction ActionrewardActionactionrewardActionActionAction(reward)</font>**\n\nrewardrewardActionrewardAction\n\n\n\n**<font color=green>  rewardAction</font>**\n\n**<font color=green>rewardrewardrewardAction</font>**\n\n\n\n**<font color=green></font>**\n\n# (Policy Network)(Value Network)\n\nAlphaGo \n\n<font color=green></font>ActionActionAction.\n\n\n\n**Policy-based,Value-based**Actionq\n\n\n\n<font color=deeppink>Action+Action</font>ActionActionAction\n\n<font color=green></font>\n\n<font color=green>Value BasedActionPolicy BasedActionActionPolicy BasedValue Based</font>\n\n## (Policy Network)\n\n[Policy_Network.py](https://github.com/xyegithub/myBlog/blob/main/2021/12/03/First-Step-to-RL/policy_network.py) [Policy_Network.py](policy_network.py)\n\n\n\n ```python\n score = tf.matmul(layer1,W2)\n probability = tf.nn.sigmoid(score)#Action 1\n input_y = tf.placeholder(tf.float32,[None,1], \\\\\n                          name=\"input_y\")# \n advantages = tf.placeholder(tf.float32,name=\"reward_signal\") \n # \n loglik = tf.log(input_y*(input_y - probability) + \\\\\n                 (1 - input_y)*(input_y + probability)) \n # 1\n \n # 00\n #\n loss = -tf.reduce_mean(loglik * advantages) # \n #advantages\n #advantages \n #\n \n #\n #\n \n ##  \n #Policy_Network.py ,\n #0.501\n #\n \n ## action\n # + \n \n ## n\n #actionadvantages\n \n ## \n #\n #\n ```\n\n---\n\n\n\n0.5Action\n\n### \n\n\n\n```python\n#xAction 1\ntfprob = sess.run(probability,feed_dict={observations: x})\n# \naction = 1 if np.random.uniform() < tfprob else 0\n```\n\n\n\n```python\n# \n# tfprob = sess.run(probability,feed_dict={observations: x})\n# 0.5\ntfprob = 0.5\naction = 1 if np.random.uniform() < tfprob else 0\n```\n\n\n\n\n\n actionactionaction\n\n\n\n\n\n## (Value NetworkQ-learning)\n\nQ-Learing\n\n[Value_Network.py](https://github.com/xyegithub/myBlog/blob/main/2021/12/03/First-Step-to-RL/policy_network.py)\n\nActionreward\n\n\n\n```python\n#Save the experience to our episode buffer.\nepisodeBuffer.add(np.reshape(np.array([s,a,r,s1,d]),[1,5]))\n# saActionrActionreward\n# s1Actiond  \n```\n\n1. Q(s<sub>t</sub>, a<sub>t</sub>)areward\n\n2. Q<sub>desird</sub>rewardQ<sub>desired</sub>(s<sub>t</sub>, a<sub>t</sub>) = r + $\\lambda$ Max<sub>a</sub> Q<sub>desired</sub>(s<sub>t+1</sub>, a)\n\n3.   Q<sub>desired</sub>\n\n   \n\n\n\n```python\n#Choose an action by greedily (with e chance of random action)\n# from the Q-network\nif np.random.rand(1) < e or total_steps < pre_train_steps:\n    a = np.random.randint(0,4)\nelse:\n    a = sess.run(mainQN.predict,feed_dict={mainQN.scalarInput:[s]})[0]\n# total_steps < pre_train_steps\n# total_steps >= pre_train_steps\n# e1-eAction \n# \n# epre_train_steps\n# Action\n# \n# Action\n# \n```\n\n**\"by greedily (with e chance of random action) from the Q-network\"**\n\n**<font color=green></font>**\n\n\n\n```python\nif total_steps > pre_train_steps:\n    if e > endE:\n        e -= stepDrop\n# \n# \n# \n# pass\n# endE=0.1 \n#\n```\n\n\n\n\n\n```python \nif total_steps % (update_freq) == 0:\n    trainBatch = myBuffer.sample(batch_size) #Get a random batch of experiences.\n    #Below we perform the Double-DQN update to the target Q-values\n    # ActiontrainBatch[:,3]\n    # Q(st, at) = r + $\\lambda$ Max Q(s_t+1, a)\n    # Actiont+1Action\n    Q1 = sess.run(mainQN.predict,feed_dict={mainQN.scalarInput:np.vstack(trainBatch[:,3])})\n    # targetreward\n    Q2 = sess.run(targetQN.Qout,feed_dict={targetQN.scalarInput:np.vstack(trainBatch[:,3])})\n    end_multiplier = -(trainBatch[:,4] - 1)\n    # Actiontargetreward\n    # reward, Max Q(s_t+1, a)\n    doubleQ = Q2[range(batch_size),Q1]\n    # Q(st, at) = r + $\\lambda$ Max Q(s_t+1, a)\n    # rewardreward\n    targetQ = trainBatch[:,2] + (y*doubleQ * end_multiplier)\n    #Update the network with our target values.\n    # \n    # \n    _ = sess.run(mainQN.updateModel, \\\n                 feed_dict={mainQN.scalarInput:np.vstack(trainBatch[:,0]),mainQN.targetQ:targetQ, mainQN.actions:trainBatch[:,1]})\n    # target\n    updateTarget(targetOps,sess) #Update the target network toward the primary network.\n```\n\n\n\n\ntarget\n\n```python \ndef updateTargetGraph(tfVars,tau):\n    total_vars = len(tfVars)\n    op_holder = [] \n    # target\n    for idx,var in enumerate(tfVars[0:total_vars//2]):\n        # idx+total_varstarget\n        # target =  * tau + 1- tau*target\n        # target\n        # target\n        # target\n        # targetActionrewardAction\n        # target\n        # target\n        # \n        op_holder.append(tfVars[idx+total_vars//2].assign\\\\\n                         ((var.value()*tau) \\\\\n                      + ((1-tau)*tfVars[idx+total_vars//2].value())))\n        return op_holder\n\n    def updateTarget(op_holder,sess):\n        for op in op_holder:\n            sess.run(op)\n\n```\n\nstate of the arttrick\n\n1. CNN\n2. Experience replayNN batchsizeN=1\n3. target**targetQ-Learing********DQNQQ**targettargettargetQ\n4. Double DQNtricktargetActionactiontargetreward\n5. Dueling DQN\n\n```python \nself.AW = tf.Variable(xavier_init([h_size//2,env.actions]))\nself.VW = tf.Variable(xavier_init([h_size//2,1]))\nself.Advantage = tf.matmul(self.streamA,self.AW)\nself.Value = tf.matmul(self.streamV,self.VW)\n\n#Then combine them together to get our final Q-values.\n# QoutActionrewardValueAdvantage\n# Valueadvantage#action\n# Dueling DQNrewardValue\n# ActionAction\n# \n#out\n# Action\n# \nself.Qout = self.Value + tf.subtract(self.Advantage,tf.reduce_mean(self.Advantage,axis=1,keep_dims=True))\n\n```\n\n## \n\nreward\n\n1. Action\n2. Actionreward\n3. \n4. ActionAction1ActionrewardAction**rewardreward**\n\n\n\n# \n\n\n\n\n\nsgd\n\n\n\n\n\n\n\n\n\nreward \n\nQ<sub>desired</sub>(s<sub>t</sub>, a<sub>t</sub>) = r + $\\lambda$ Max<sub>a</sub> Q<sub>desired</sub>(s<sub>t+1</sub>, a)\n\n\n\n\n\n```python \nif done:\n    episode_number += 1\n    epx = np.vstack(xs)\n    epy = np.vstack(ys)\n    epr = np.vstack(drs)\n    tfp = tfps\n    xs,hs,dlogps,drs,ys,tfps = [],[],[],[],[],[]\n\n    discounted_epr = discount_rewards(epr)\n    discounted_epr -= np.mean(discounted_epr)\n    discounted_epr //= np.std(discounted_epr)\n\n    tGrad = sess.run(newGrads,feed_dict={observations: epx, input_y: epy, advantages: discounted_epr})\n    for ix,grad in enumerate(tGrad):\n        gradBuffer[ix] += grad\n\n        if episode_number % batch_size == 0:\n            sess.run(updateGrads,feed_dict={W1Grad: gradBuffer[0],W1_1Grad:gradBuffer[1],W2Grad:gradBuffer[2]})\n```\n\n\n\n\n\n","source":"_posts/First-Step-to-RL.md","raw":"---\ntitle: First Step to Reinforcement Learning\ndate: 2021-12-03 16:48:41\ndescription: (Policy Network)(Value Network)\ntags:\n- Reinforcement Learning\ncategories:\n- Reinforcement Learning\n\n\n---\n\n\n\n# \n\n<font color=green size=3></font>\n\n<font color=green size=3></font>\n\n<font color=green size=3></font>\n\n\n\n* S\n* A\n* \n* \n* \n* /\n\n## \n\n****\n\n1\n\n2 agent\n\n<font color=deeppink> agent</font>\n\n\n\n\n\n<font color=deeppink>label</font>\n\n\n\n \n\n## \n\n\n\n## \n\n\n\n\n\n\n\n## \n\n\n\n\n\n\n\n<font color=green></font>\n\n## \n\n1. targetActionPS. targetAction\n\n2. lossloss\n\n   0.1\n\n3. 2\n\n4. ActionActionrewardreward\n\n   ActionrewardActionreward\n\n   <font color=green>Actionrewardreward</font>\n\n5. \n\n   \n\n\n\n\n\n**<font color=green>Actionadvatagereward</font>**\n\n## \n\n\n\nActionscore = 0.1 score\n\n\n\nreward\n\n**<font color=green>actionaction ActionrewardActionactionrewardActionActionAction(reward)</font>**\n\nrewardrewardActionrewardAction\n\n\n\n**<font color=green>  rewardAction</font>**\n\n**<font color=green>rewardrewardrewardAction</font>**\n\n\n\n**<font color=green></font>**\n\n# (Policy Network)(Value Network)\n\nAlphaGo \n\n<font color=green></font>ActionActionAction.\n\n\n\n**Policy-based,Value-based**Actionq\n\n\n\n<font color=deeppink>Action+Action</font>ActionActionAction\n\n<font color=green></font>\n\n<font color=green>Value BasedActionPolicy BasedActionActionPolicy BasedValue Based</font>\n\n## (Policy Network)\n\n[Policy_Network.py](https://github.com/xyegithub/myBlog/blob/main/2021/12/03/First-Step-to-RL/policy_network.py) [Policy_Network.py](policy_network.py)\n\n\n\n ```python\n score = tf.matmul(layer1,W2)\n probability = tf.nn.sigmoid(score)#Action 1\n input_y = tf.placeholder(tf.float32,[None,1], \\\\\n                          name=\"input_y\")# \n advantages = tf.placeholder(tf.float32,name=\"reward_signal\") \n # \n loglik = tf.log(input_y*(input_y - probability) + \\\\\n                 (1 - input_y)*(input_y + probability)) \n # 1\n \n # 00\n #\n loss = -tf.reduce_mean(loglik * advantages) # \n #advantages\n #advantages \n #\n \n #\n #\n \n ##  \n #Policy_Network.py ,\n #0.501\n #\n \n ## action\n # + \n \n ## n\n #actionadvantages\n \n ## \n #\n #\n ```\n\n---\n\n\n\n0.5Action\n\n### \n\n\n\n```python\n#xAction 1\ntfprob = sess.run(probability,feed_dict={observations: x})\n# \naction = 1 if np.random.uniform() < tfprob else 0\n```\n\n\n\n```python\n# \n# tfprob = sess.run(probability,feed_dict={observations: x})\n# 0.5\ntfprob = 0.5\naction = 1 if np.random.uniform() < tfprob else 0\n```\n\n\n\n\n\n actionactionaction\n\n\n\n\n\n## (Value NetworkQ-learning)\n\nQ-Learing\n\n[Value_Network.py](https://github.com/xyegithub/myBlog/blob/main/2021/12/03/First-Step-to-RL/policy_network.py)\n\nActionreward\n\n\n\n```python\n#Save the experience to our episode buffer.\nepisodeBuffer.add(np.reshape(np.array([s,a,r,s1,d]),[1,5]))\n# saActionrActionreward\n# s1Actiond  \n```\n\n1. Q(s<sub>t</sub>, a<sub>t</sub>)areward\n\n2. Q<sub>desird</sub>rewardQ<sub>desired</sub>(s<sub>t</sub>, a<sub>t</sub>) = r + $\\lambda$ Max<sub>a</sub> Q<sub>desired</sub>(s<sub>t+1</sub>, a)\n\n3.   Q<sub>desired</sub>\n\n   \n\n\n\n```python\n#Choose an action by greedily (with e chance of random action)\n# from the Q-network\nif np.random.rand(1) < e or total_steps < pre_train_steps:\n    a = np.random.randint(0,4)\nelse:\n    a = sess.run(mainQN.predict,feed_dict={mainQN.scalarInput:[s]})[0]\n# total_steps < pre_train_steps\n# total_steps >= pre_train_steps\n# e1-eAction \n# \n# epre_train_steps\n# Action\n# \n# Action\n# \n```\n\n**\"by greedily (with e chance of random action) from the Q-network\"**\n\n**<font color=green></font>**\n\n\n\n```python\nif total_steps > pre_train_steps:\n    if e > endE:\n        e -= stepDrop\n# \n# \n# \n# pass\n# endE=0.1 \n#\n```\n\n\n\n\n\n```python \nif total_steps % (update_freq) == 0:\n    trainBatch = myBuffer.sample(batch_size) #Get a random batch of experiences.\n    #Below we perform the Double-DQN update to the target Q-values\n    # ActiontrainBatch[:,3]\n    # Q(st, at) = r + $\\lambda$ Max Q(s_t+1, a)\n    # Actiont+1Action\n    Q1 = sess.run(mainQN.predict,feed_dict={mainQN.scalarInput:np.vstack(trainBatch[:,3])})\n    # targetreward\n    Q2 = sess.run(targetQN.Qout,feed_dict={targetQN.scalarInput:np.vstack(trainBatch[:,3])})\n    end_multiplier = -(trainBatch[:,4] - 1)\n    # Actiontargetreward\n    # reward, Max Q(s_t+1, a)\n    doubleQ = Q2[range(batch_size),Q1]\n    # Q(st, at) = r + $\\lambda$ Max Q(s_t+1, a)\n    # rewardreward\n    targetQ = trainBatch[:,2] + (y*doubleQ * end_multiplier)\n    #Update the network with our target values.\n    # \n    # \n    _ = sess.run(mainQN.updateModel, \\\n                 feed_dict={mainQN.scalarInput:np.vstack(trainBatch[:,0]),mainQN.targetQ:targetQ, mainQN.actions:trainBatch[:,1]})\n    # target\n    updateTarget(targetOps,sess) #Update the target network toward the primary network.\n```\n\n\n\n\ntarget\n\n```python \ndef updateTargetGraph(tfVars,tau):\n    total_vars = len(tfVars)\n    op_holder = [] \n    # target\n    for idx,var in enumerate(tfVars[0:total_vars//2]):\n        # idx+total_varstarget\n        # target =  * tau + 1- tau*target\n        # target\n        # target\n        # target\n        # targetActionrewardAction\n        # target\n        # target\n        # \n        op_holder.append(tfVars[idx+total_vars//2].assign\\\\\n                         ((var.value()*tau) \\\\\n                      + ((1-tau)*tfVars[idx+total_vars//2].value())))\n        return op_holder\n\n    def updateTarget(op_holder,sess):\n        for op in op_holder:\n            sess.run(op)\n\n```\n\nstate of the arttrick\n\n1. CNN\n2. Experience replayNN batchsizeN=1\n3. target**targetQ-Learing********DQNQQ**targettargettargetQ\n4. Double DQNtricktargetActionactiontargetreward\n5. Dueling DQN\n\n```python \nself.AW = tf.Variable(xavier_init([h_size//2,env.actions]))\nself.VW = tf.Variable(xavier_init([h_size//2,1]))\nself.Advantage = tf.matmul(self.streamA,self.AW)\nself.Value = tf.matmul(self.streamV,self.VW)\n\n#Then combine them together to get our final Q-values.\n# QoutActionrewardValueAdvantage\n# Valueadvantage#action\n# Dueling DQNrewardValue\n# ActionAction\n# \n#out\n# Action\n# \nself.Qout = self.Value + tf.subtract(self.Advantage,tf.reduce_mean(self.Advantage,axis=1,keep_dims=True))\n\n```\n\n## \n\nreward\n\n1. Action\n2. Actionreward\n3. \n4. ActionAction1ActionrewardAction**rewardreward**\n\n\n\n# \n\n\n\n\n\nsgd\n\n\n\n\n\n\n\n\n\nreward \n\nQ<sub>desired</sub>(s<sub>t</sub>, a<sub>t</sub>) = r + $\\lambda$ Max<sub>a</sub> Q<sub>desired</sub>(s<sub>t+1</sub>, a)\n\n\n\n\n\n```python \nif done:\n    episode_number += 1\n    epx = np.vstack(xs)\n    epy = np.vstack(ys)\n    epr = np.vstack(drs)\n    tfp = tfps\n    xs,hs,dlogps,drs,ys,tfps = [],[],[],[],[],[]\n\n    discounted_epr = discount_rewards(epr)\n    discounted_epr -= np.mean(discounted_epr)\n    discounted_epr //= np.std(discounted_epr)\n\n    tGrad = sess.run(newGrads,feed_dict={observations: epx, input_y: epy, advantages: discounted_epr})\n    for ix,grad in enumerate(tGrad):\n        gradBuffer[ix] += grad\n\n        if episode_number % batch_size == 0:\n            sess.run(updateGrads,feed_dict={W1Grad: gradBuffer[0],W1_1Grad:gradBuffer[1],W2Grad:gradBuffer[2]})\n```\n\n\n\n\n\n","slug":"First-Step-to-RL","published":1,"updated":"2022-01-17T09:43:07.972Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckzhsa4gs000h4fvkhboa5qsd","content":"<html><head></head><body><h1><span class=\"post-title-index\">1. </span></h1>\n<p><font color=\"green\" size=\"3\"></font></p>\n<p><font color=\"green\" size=\"3\"></font></p>\n<p><font color=\"green\" size=\"3\"></font></p>\n<p></p>\n<ul>\n<li>S</li>\n<li>A</li>\n<li></li>\n<li></li>\n<li></li>\n<li>/</li>\n</ul>\n<h2 id=\"\"><span class=\"post-title-index\">1.1. </span></h2>\n<p><strong></strong></p>\n<p>1</p>\n<p>2 agent</p>\n<p><font color=\"deeppink\"> agent</font></p>\n<p></p>\n<p></p>\n<p><font color=\"deeppink\">label</font></p>\n<p></p>\n<p></p>\n<h2 id=\"\"><span class=\"post-title-index\">1.2. </span></h2>\n<p></p>\n<h2 id=\"\"><span class=\"post-title-index\">1.3. </span></h2>\n<p></p>\n<p></p>\n<p></p>\n<h2 id=\"\"><span class=\"post-title-index\">1.4. </span></h2>\n<p></p>\n<p></p>\n<p></p>\n<p><font color=\"green\"></font></p>\n<h2 id=\"\"><span class=\"post-title-index\">1.5. </span></h2>\n<ol>\n<li>\n<p>targetActionPS. targetAction</p>\n</li>\n<li>\n<p>lossloss</p>\n<p>0.1</p>\n</li>\n<li>\n<p>2</p>\n</li>\n<li>\n<p>ActionActionrewardreward</p>\n<p>ActionrewardActionreward</p>\n<p><font color=\"green\">Actionrewardreward</font></p>\n</li>\n<li>\n<p></p>\n</li>\n</ol>\n<p></p>\n<p></p>\n<p><strong><font color=\"green\">Actionadvatagereward</font></strong></p>\n<h2 id=\"\"><span class=\"post-title-index\">1.6. </span></h2>\n<p></p>\n<p>Actionscore = 0.1 score</p>\n<p></p>\n<p>reward</p>\n<p><strong><font color=\"green\">actionaction ActionrewardActionactionrewardActionActionAction(reward)</font></strong></p>\n<p>rewardrewardActionrewardAction</p>\n<p></p>\n<p><strong><font color=\"green\">  rewardAction</font></strong></p>\n<p><strong><font color=\"green\">rewardrewardrewardAction</font></strong></p>\n<p></p>\n<p><strong><font color=\"green\"></font></strong></p>\n<h1><span class=\"post-title-index\">2. </span>(Policy Network)(Value Network)</h1>\n<p>AlphaGo </p>\n<p><font color=\"green\"></font>ActionActionAction.</p>\n<p></p>\n<p><strong>Policy-based,Value-based</strong>Actionq</p>\n<p></p>\n<p><font color=\"deeppink\">Action+Action</font>ActionActionAction</p>\n<p><font color=\"green\"></font></p>\n<p><font color=\"green\">Value BasedActionPolicy BasedActionActionPolicy BasedValue Based</font></p>\n<h2 id=\"-Policy-Network\"><span class=\"post-title-index\">2.1. </span>(Policy Network)</h2>\n<p><a href=\"https://github.com/xyegithub/myBlog/blob/main/2021/12/03/First-Step-to-RL/policy_network.py\">Policy_Network.py</a> <a href=\"policy_network.py\">Policy_Network.py</a></p>\n<p></p>\n <figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">score = tf.matmul(layer1,W2)</span><br><span class=\"line\">probability = tf.nn.sigmoid(score)<span class=\"comment\">#Action 1</span></span><br><span class=\"line\">input_y = tf.placeholder(tf.float32,[<span class=\"literal\">None</span>,<span class=\"number\">1</span>], \\\\</span><br><span class=\"line\">                         name=<span class=\"string\">\"input_y\"</span>)<span class=\"comment\"># </span></span><br><span class=\"line\">advantages = tf.placeholder(tf.float32,name=<span class=\"string\">\"reward_signal\"</span>) </span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\">loglik = tf.log(input_y*(input_y - probability) + \\\\</span><br><span class=\"line\">                (<span class=\"number\">1</span> - input_y)*(input_y + probability)) </span><br><span class=\"line\"><span class=\"comment\"># 1</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 00</span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\">loss = -tf.reduce_mean(loglik * advantages) <span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"comment\">#advantages</span></span><br><span class=\"line\"><span class=\"comment\">#advantages </span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">##  </span></span><br><span class=\"line\"><span class=\"comment\">#Policy_Network.py ,</span></span><br><span class=\"line\"><span class=\"comment\">#0.501</span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## action</span></span><br><span class=\"line\"><span class=\"comment\"># + </span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## n</span></span><br><span class=\"line\"><span class=\"comment\">#actionadvantages</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## </span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br></pre></td></tr></tbody></table></figure>\n<p></p>\n<p></p>\n<p>0.5Action</p>\n<h3 id=\"\"><span class=\"post-title-index\">2.1.1. </span></h3>\n<p></p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#xAction 1</span></span><br><span class=\"line\">tfprob = sess.run(probability,feed_dict={observations: x})</span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\">action = <span class=\"number\">1</span> <span class=\"keyword\">if</span> np.random.uniform() &lt; tfprob <span class=\"keyword\">else</span> <span class=\"number\">0</span></span><br></pre></td></tr></tbody></table></figure>\n<p></p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"comment\"># tfprob = sess.run(probability,feed_dict={observations: x})</span></span><br><span class=\"line\"><span class=\"comment\"># 0.5</span></span><br><span class=\"line\">tfprob = <span class=\"number\">0.5</span></span><br><span class=\"line\">action = <span class=\"number\">1</span> <span class=\"keyword\">if</span> np.random.uniform() &lt; tfprob <span class=\"keyword\">else</span> <span class=\"number\">0</span></span><br></pre></td></tr></tbody></table></figure>\n<p></p>\n<p></p>\n<p> actionactionaction</p>\n<p></p>\n<p></p>\n<h2 id=\"-Value-NetworkQ-learning\"><span class=\"post-title-index\">2.2. </span>(Value NetworkQ-learning)</h2>\n<p>Q-Learing</p>\n<p><a href=\"https://github.com/xyegithub/myBlog/blob/main/2021/12/03/First-Step-to-RL/policy_network.py\">Value_Network.py</a></p>\n<p>Actionreward</p>\n<p></p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#Save the experience to our episode buffer.</span></span><br><span class=\"line\">episodeBuffer.add(np.reshape(np.array([s,a,r,s1,d]),[<span class=\"number\">1</span>,<span class=\"number\">5</span>]))</span><br><span class=\"line\"><span class=\"comment\"># saActionrActionreward</span></span><br><span class=\"line\"><span class=\"comment\"># s1Actiond  </span></span><br></pre></td></tr></tbody></table></figure>\n<ol>\n<li>\n<p>Q(s<sub>t</sub>, a<sub>t</sub>)areward</p>\n</li>\n<li>\n<p>Q<sub>desird</sub>rewardQ<sub>desired</sub>(s<sub>t</sub>, a<sub>t</sub>) = r + $\\lambda$ Max<sub>a</sub> Q<sub>desired</sub>(s<sub>t+1</sub>, a)</p>\n</li>\n<li>\n<p>  Q<sub>desired</sub></p>\n</li>\n</ol>\n<p></p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#Choose an action by greedily (with e chance of random action)</span></span><br><span class=\"line\"><span class=\"comment\"># from the Q-network</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> np.random.rand(<span class=\"number\">1</span>) &lt; e <span class=\"keyword\">or</span> total_steps &lt; pre_train_steps:</span><br><span class=\"line\">    a = np.random.randint(<span class=\"number\">0</span>,<span class=\"number\">4</span>)</span><br><span class=\"line\"><span class=\"keyword\">else</span>:</span><br><span class=\"line\">    a = sess.run(mainQN.predict,feed_dict={mainQN.scalarInput:[s]})[<span class=\"number\">0</span>]</span><br><span class=\"line\"><span class=\"comment\"># total_steps &lt; pre_train_steps</span></span><br><span class=\"line\"><span class=\"comment\"># total_steps &gt;= pre_train_steps</span></span><br><span class=\"line\"><span class=\"comment\"># e1-eAction </span></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"comment\"># epre_train_steps</span></span><br><span class=\"line\"><span class=\"comment\"># Action</span></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"comment\"># Action</span></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br></pre></td></tr></tbody></table></figure>\n<p><strong>\"by greedily (with e chance of random action) from the Q-network\"</strong></p>\n<p><strong><font color=\"green\"></font></strong></p>\n<p></p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> total_steps &gt; pre_train_steps:</span><br><span class=\"line\">    <span class=\"keyword\">if</span> e &gt; endE:</span><br><span class=\"line\">        e -= stepDrop</span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"comment\"># pass</span></span><br><span class=\"line\"><span class=\"comment\"># endE=0.1 </span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br></pre></td></tr></tbody></table></figure>\n<p></p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> total_steps % (update_freq) == <span class=\"number\">0</span>:</span><br><span class=\"line\">    trainBatch = myBuffer.sample(batch_size) <span class=\"comment\">#Get a random batch of experiences.</span></span><br><span class=\"line\">    <span class=\"comment\">#Below we perform the Double-DQN update to the target Q-values</span></span><br><span class=\"line\">    <span class=\"comment\"># ActiontrainBatch[:,3]</span></span><br><span class=\"line\">    <span class=\"comment\"># Q(st, at) = r + $\\lambda$ Max Q(s_t+1, a)</span></span><br><span class=\"line\">    <span class=\"comment\"># Actiont+1Action</span></span><br><span class=\"line\">    Q1 = sess.run(mainQN.predict,feed_dict={mainQN.scalarInput:np.vstack(trainBatch[:,<span class=\"number\">3</span>])})</span><br><span class=\"line\">    <span class=\"comment\"># targetreward</span></span><br><span class=\"line\">    Q2 = sess.run(targetQN.Qout,feed_dict={targetQN.scalarInput:np.vstack(trainBatch[:,<span class=\"number\">3</span>])})</span><br><span class=\"line\">    end_multiplier = -(trainBatch[:,<span class=\"number\">4</span>] - <span class=\"number\">1</span>)</span><br><span class=\"line\">    <span class=\"comment\"># Actiontargetreward</span></span><br><span class=\"line\">    <span class=\"comment\"># reward, Max Q(s_t+1, a)</span></span><br><span class=\"line\">    doubleQ = Q2[<span class=\"built_in\">range</span>(batch_size),Q1]</span><br><span class=\"line\">    <span class=\"comment\"># Q(st, at) = r + $\\lambda$ Max Q(s_t+1, a)</span></span><br><span class=\"line\">    <span class=\"comment\"># rewardreward</span></span><br><span class=\"line\">    targetQ = trainBatch[:,<span class=\"number\">2</span>] + (y*doubleQ * end_multiplier)</span><br><span class=\"line\">    <span class=\"comment\">#Update the network with our target values.</span></span><br><span class=\"line\">    <span class=\"comment\"># </span></span><br><span class=\"line\">    <span class=\"comment\"># </span></span><br><span class=\"line\">    _ = sess.run(mainQN.updateModel, \\</span><br><span class=\"line\">                 feed_dict={mainQN.scalarInput:np.vstack(trainBatch[:,<span class=\"number\">0</span>]),mainQN.targetQ:targetQ, mainQN.actions:trainBatch[:,<span class=\"number\">1</span>]})</span><br><span class=\"line\">    <span class=\"comment\"># target</span></span><br><span class=\"line\">    updateTarget(targetOps,sess) <span class=\"comment\">#Update the target network toward the primary network.</span></span><br></pre></td></tr></tbody></table></figure>\n<p>target</p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">updateTargetGraph</span>(<span class=\"params\">tfVars,tau</span>):</span></span><br><span class=\"line\">    total_vars = <span class=\"built_in\">len</span>(tfVars)</span><br><span class=\"line\">    op_holder = [] </span><br><span class=\"line\">    <span class=\"comment\"># target</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> idx,var <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(tfVars[<span class=\"number\">0</span>:total_vars//<span class=\"number\">2</span>]):</span><br><span class=\"line\">        <span class=\"comment\"># idx+total_varstarget</span></span><br><span class=\"line\">        <span class=\"comment\"># target =  * tau + 1- tau*target</span></span><br><span class=\"line\">        <span class=\"comment\"># target</span></span><br><span class=\"line\">        <span class=\"comment\"># target</span></span><br><span class=\"line\">        <span class=\"comment\"># target</span></span><br><span class=\"line\">        <span class=\"comment\"># targetActionrewardAction</span></span><br><span class=\"line\">        <span class=\"comment\"># target</span></span><br><span class=\"line\">        <span class=\"comment\"># target</span></span><br><span class=\"line\">        <span class=\"comment\"># </span></span><br><span class=\"line\">        op_holder.append(tfVars[idx+total_vars//<span class=\"number\">2</span>].assign\\\\</span><br><span class=\"line\">                         ((var.value()*tau) \\\\</span><br><span class=\"line\">                      + ((<span class=\"number\">1</span>-tau)*tfVars[idx+total_vars//<span class=\"number\">2</span>].value())))</span><br><span class=\"line\">        <span class=\"keyword\">return</span> op_holder</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">updateTarget</span>(<span class=\"params\">op_holder,sess</span>):</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> op <span class=\"keyword\">in</span> op_holder:</span><br><span class=\"line\">            sess.run(op)</span><br><span class=\"line\"></span><br></pre></td></tr></tbody></table></figure>\n<p>state of the arttrick</p>\n<ol>\n<li>CNN</li>\n<li>Experience replayNN batchsizeN=1</li>\n<li>target**targetQ-Learing********DQNQQ**targettargettargetQ</li>\n<li>Double DQNtricktargetActionactiontargetreward</li>\n<li>Dueling DQN</li>\n</ol>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">self.AW = tf.Variable(xavier_init([h_size//<span class=\"number\">2</span>,env.actions]))</span><br><span class=\"line\">self.VW = tf.Variable(xavier_init([h_size//<span class=\"number\">2</span>,<span class=\"number\">1</span>]))</span><br><span class=\"line\">self.Advantage = tf.matmul(self.streamA,self.AW)</span><br><span class=\"line\">self.Value = tf.matmul(self.streamV,self.VW)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#Then combine them together to get our final Q-values.</span></span><br><span class=\"line\"><span class=\"comment\"># QoutActionrewardValueAdvantage</span></span><br><span class=\"line\"><span class=\"comment\"># Valueadvantage#action</span></span><br><span class=\"line\"><span class=\"comment\"># Dueling DQNrewardValue</span></span><br><span class=\"line\"><span class=\"comment\"># ActionAction</span></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"comment\">#out</span></span><br><span class=\"line\"><span class=\"comment\"># Action</span></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\">self.Qout = self.Value + tf.subtract(self.Advantage,tf.reduce_mean(self.Advantage,axis=<span class=\"number\">1</span>,keep_dims=<span class=\"literal\">True</span>))</span><br><span class=\"line\"></span><br></pre></td></tr></tbody></table></figure>\n<h2 id=\"\"><span class=\"post-title-index\">2.3. </span></h2>\n<p>reward</p>\n<ol>\n<li>Action</li>\n<li>Actionreward</li>\n<li></li>\n<li>ActionAction1ActionrewardAction<strong>rewardreward</strong></li>\n</ol>\n<h1><span class=\"post-title-index\">3. </span></h1>\n<p></p>\n<p></p>\n<p>sgd</p>\n<p></p>\n<p></p>\n<p>reward </p>\n<p>Q<sub>desired</sub>(s<sub>t</sub>, a<sub>t</sub>) = r + $\\lambda$ Max<sub>a</sub> Q<sub>desired</sub>(s<sub>t+1</sub>, a)</p>\n<p></p>\n<p></p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> done:</span><br><span class=\"line\">    episode_number += <span class=\"number\">1</span></span><br><span class=\"line\">    epx = np.vstack(xs)</span><br><span class=\"line\">    epy = np.vstack(ys)</span><br><span class=\"line\">    epr = np.vstack(drs)</span><br><span class=\"line\">    tfp = tfps</span><br><span class=\"line\">    xs,hs,dlogps,drs,ys,tfps = [],[],[],[],[],[]</span><br><span class=\"line\"></span><br><span class=\"line\">    discounted_epr = discount_rewards(epr)</span><br><span class=\"line\">    discounted_epr -= np.mean(discounted_epr)</span><br><span class=\"line\">    discounted_epr //= np.std(discounted_epr)</span><br><span class=\"line\"></span><br><span class=\"line\">    tGrad = sess.run(newGrads,feed_dict={observations: epx, input_y: epy, advantages: discounted_epr})</span><br><span class=\"line\">    <span class=\"keyword\">for</span> ix,grad <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(tGrad):</span><br><span class=\"line\">        gradBuffer[ix] += grad</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> episode_number % batch_size == <span class=\"number\">0</span>:</span><br><span class=\"line\">            sess.run(updateGrads,feed_dict={W1Grad: gradBuffer[<span class=\"number\">0</span>],W1_1Grad:gradBuffer[<span class=\"number\">1</span>],W2Grad:gradBuffer[<span class=\"number\">2</span>]})</span><br></pre></td></tr></tbody></table></figure>\n<p></p>\n</body></html>","site":{"data":{}},"excerpt":"<html><head></head><body></body></html>","more":"<h1></h1>\n<p><font color=green size=3></font></p>\n<p><font color=green size=3></font></p>\n<p><font color=green size=3></font></p>\n<p></p>\n<ul>\n<li>S</li>\n<li>A</li>\n<li></li>\n<li></li>\n<li></li>\n<li>/</li>\n</ul>\n<h2 id=\"\"></h2>\n<p><strong></strong></p>\n<p>1</p>\n<p>2 agent</p>\n<p><font color=deeppink> agent</font></p>\n<p></p>\n<p></p>\n<p><font color=deeppink>label</font></p>\n<p></p>\n<p></p>\n<h2 id=\"\"></h2>\n<p></p>\n<h2 id=\"\"></h2>\n<p></p>\n<p></p>\n<p></p>\n<h2 id=\"\"></h2>\n<p></p>\n<p></p>\n<p></p>\n<p><font color=green></font></p>\n<h2 id=\"\"></h2>\n<ol>\n<li>\n<p>targetActionPS. targetAction</p>\n</li>\n<li>\n<p>lossloss</p>\n<p>0.1</p>\n</li>\n<li>\n<p>2</p>\n</li>\n<li>\n<p>ActionActionrewardreward</p>\n<p>ActionrewardActionreward</p>\n<p><font color=green>Actionrewardreward</font></p>\n</li>\n<li>\n<p></p>\n</li>\n</ol>\n<p></p>\n<p></p>\n<p><strong><font color=green>Actionadvatagereward</font></strong></p>\n<h2 id=\"\"></h2>\n<p></p>\n<p>Actionscore = 0.1 score</p>\n<p></p>\n<p>reward</p>\n<p><strong><font color=green>actionaction ActionrewardActionactionrewardActionActionAction(reward)</font></strong></p>\n<p>rewardrewardActionrewardAction</p>\n<p></p>\n<p><strong><font color=green>  rewardAction</font></strong></p>\n<p><strong><font color=green>rewardrewardrewardAction</font></strong></p>\n<p></p>\n<p><strong><font color=green></font></strong></p>\n<h1>(Policy Network)(Value Network)</h1>\n<p>AlphaGo </p>\n<p><font color=green></font>ActionActionAction.</p>\n<p></p>\n<p><strong>Policy-based,Value-based</strong>Actionq</p>\n<p></p>\n<p><font color=deeppink>Action+Action</font>ActionActionAction</p>\n<p><font color=green></font></p>\n<p><font color=green>Value BasedActionPolicy BasedActionActionPolicy BasedValue Based</font></p>\n<h2 id=\"-Policy-Network\">(Policy Network)</h2>\n<p><a href=\"https://github.com/xyegithub/myBlog/blob/main/2021/12/03/First-Step-to-RL/policy_network.py\">Policy_Network.py</a> <a href=\"policy_network.py\">Policy_Network.py</a></p>\n<p></p>\n <figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">score = tf.matmul(layer1,W2)</span><br><span class=\"line\">probability = tf.nn.sigmoid(score)<span class=\"comment\">#Action 1</span></span><br><span class=\"line\">input_y = tf.placeholder(tf.float32,[<span class=\"literal\">None</span>,<span class=\"number\">1</span>], \\\\</span><br><span class=\"line\">                         name=<span class=\"string\">&quot;input_y&quot;</span>)<span class=\"comment\"># </span></span><br><span class=\"line\">advantages = tf.placeholder(tf.float32,name=<span class=\"string\">&quot;reward_signal&quot;</span>) </span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\">loglik = tf.log(input_y*(input_y - probability) + \\\\</span><br><span class=\"line\">                (<span class=\"number\">1</span> - input_y)*(input_y + probability)) </span><br><span class=\"line\"><span class=\"comment\"># 1</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 00</span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\">loss = -tf.reduce_mean(loglik * advantages) <span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"comment\">#advantages</span></span><br><span class=\"line\"><span class=\"comment\">#advantages </span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">##  </span></span><br><span class=\"line\"><span class=\"comment\">#Policy_Network.py ,</span></span><br><span class=\"line\"><span class=\"comment\">#0.501</span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## action</span></span><br><span class=\"line\"><span class=\"comment\"># + </span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## n</span></span><br><span class=\"line\"><span class=\"comment\">#actionadvantages</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## </span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br></pre></td></tr></table></figure>\n<p></p>\n<p></p>\n<p>0.5Action</p>\n<h3 id=\"\"></h3>\n<p></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#xAction 1</span></span><br><span class=\"line\">tfprob = sess.run(probability,feed_dict=&#123;observations: x&#125;)</span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\">action = <span class=\"number\">1</span> <span class=\"keyword\">if</span> np.random.uniform() &lt; tfprob <span class=\"keyword\">else</span> <span class=\"number\">0</span></span><br></pre></td></tr></table></figure>\n<p></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"comment\"># tfprob = sess.run(probability,feed_dict=&#123;observations: x&#125;)</span></span><br><span class=\"line\"><span class=\"comment\"># 0.5</span></span><br><span class=\"line\">tfprob = <span class=\"number\">0.5</span></span><br><span class=\"line\">action = <span class=\"number\">1</span> <span class=\"keyword\">if</span> np.random.uniform() &lt; tfprob <span class=\"keyword\">else</span> <span class=\"number\">0</span></span><br></pre></td></tr></table></figure>\n<p></p>\n<p></p>\n<p> actionactionaction</p>\n<p></p>\n<p></p>\n<h2 id=\"-Value-NetworkQ-learning\">(Value NetworkQ-learning)</h2>\n<p>Q-Learing</p>\n<p><a href=\"https://github.com/xyegithub/myBlog/blob/main/2021/12/03/First-Step-to-RL/policy_network.py\">Value_Network.py</a></p>\n<p>Actionreward</p>\n<p></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#Save the experience to our episode buffer.</span></span><br><span class=\"line\">episodeBuffer.add(np.reshape(np.array([s,a,r,s1,d]),[<span class=\"number\">1</span>,<span class=\"number\">5</span>]))</span><br><span class=\"line\"><span class=\"comment\"># saActionrActionreward</span></span><br><span class=\"line\"><span class=\"comment\"># s1Actiond  </span></span><br></pre></td></tr></table></figure>\n<ol>\n<li>\n<p>Q(s<sub>t</sub>, a<sub>t</sub>)areward</p>\n</li>\n<li>\n<p>Q<sub>desird</sub>rewardQ<sub>desired</sub>(s<sub>t</sub>, a<sub>t</sub>) = r + $\\lambda$ Max<sub>a</sub> Q<sub>desired</sub>(s<sub>t+1</sub>, a)</p>\n</li>\n<li>\n<p>  Q<sub>desired</sub></p>\n</li>\n</ol>\n<p></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#Choose an action by greedily (with e chance of random action)</span></span><br><span class=\"line\"><span class=\"comment\"># from the Q-network</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> np.random.rand(<span class=\"number\">1</span>) &lt; e <span class=\"keyword\">or</span> total_steps &lt; pre_train_steps:</span><br><span class=\"line\">    a = np.random.randint(<span class=\"number\">0</span>,<span class=\"number\">4</span>)</span><br><span class=\"line\"><span class=\"keyword\">else</span>:</span><br><span class=\"line\">    a = sess.run(mainQN.predict,feed_dict=&#123;mainQN.scalarInput:[s]&#125;)[<span class=\"number\">0</span>]</span><br><span class=\"line\"><span class=\"comment\"># total_steps &lt; pre_train_steps</span></span><br><span class=\"line\"><span class=\"comment\"># total_steps &gt;= pre_train_steps</span></span><br><span class=\"line\"><span class=\"comment\"># e1-eAction </span></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"comment\"># epre_train_steps</span></span><br><span class=\"line\"><span class=\"comment\"># Action</span></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"comment\"># Action</span></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br></pre></td></tr></table></figure>\n<p><strong>&quot;by greedily (with e chance of random action) from the Q-network&quot;</strong></p>\n<p><strong><font color=green></font></strong></p>\n<p></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> total_steps &gt; pre_train_steps:</span><br><span class=\"line\">    <span class=\"keyword\">if</span> e &gt; endE:</span><br><span class=\"line\">        e -= stepDrop</span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"comment\"># pass</span></span><br><span class=\"line\"><span class=\"comment\"># endE=0.1 </span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br></pre></td></tr></table></figure>\n<p></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> total_steps % (update_freq) == <span class=\"number\">0</span>:</span><br><span class=\"line\">    trainBatch = myBuffer.sample(batch_size) <span class=\"comment\">#Get a random batch of experiences.</span></span><br><span class=\"line\">    <span class=\"comment\">#Below we perform the Double-DQN update to the target Q-values</span></span><br><span class=\"line\">    <span class=\"comment\"># ActiontrainBatch[:,3]</span></span><br><span class=\"line\">    <span class=\"comment\"># Q(st, at) = r + $\\lambda$ Max Q(s_t+1, a)</span></span><br><span class=\"line\">    <span class=\"comment\"># Actiont+1Action</span></span><br><span class=\"line\">    Q1 = sess.run(mainQN.predict,feed_dict=&#123;mainQN.scalarInput:np.vstack(trainBatch[:,<span class=\"number\">3</span>])&#125;)</span><br><span class=\"line\">    <span class=\"comment\"># targetreward</span></span><br><span class=\"line\">    Q2 = sess.run(targetQN.Qout,feed_dict=&#123;targetQN.scalarInput:np.vstack(trainBatch[:,<span class=\"number\">3</span>])&#125;)</span><br><span class=\"line\">    end_multiplier = -(trainBatch[:,<span class=\"number\">4</span>] - <span class=\"number\">1</span>)</span><br><span class=\"line\">    <span class=\"comment\"># Actiontargetreward</span></span><br><span class=\"line\">    <span class=\"comment\"># reward, Max Q(s_t+1, a)</span></span><br><span class=\"line\">    doubleQ = Q2[<span class=\"built_in\">range</span>(batch_size),Q1]</span><br><span class=\"line\">    <span class=\"comment\"># Q(st, at) = r + $\\lambda$ Max Q(s_t+1, a)</span></span><br><span class=\"line\">    <span class=\"comment\"># rewardreward</span></span><br><span class=\"line\">    targetQ = trainBatch[:,<span class=\"number\">2</span>] + (y*doubleQ * end_multiplier)</span><br><span class=\"line\">    <span class=\"comment\">#Update the network with our target values.</span></span><br><span class=\"line\">    <span class=\"comment\"># </span></span><br><span class=\"line\">    <span class=\"comment\"># </span></span><br><span class=\"line\">    _ = sess.run(mainQN.updateModel, \\</span><br><span class=\"line\">                 feed_dict=&#123;mainQN.scalarInput:np.vstack(trainBatch[:,<span class=\"number\">0</span>]),mainQN.targetQ:targetQ, mainQN.actions:trainBatch[:,<span class=\"number\">1</span>]&#125;)</span><br><span class=\"line\">    <span class=\"comment\"># target</span></span><br><span class=\"line\">    updateTarget(targetOps,sess) <span class=\"comment\">#Update the target network toward the primary network.</span></span><br></pre></td></tr></table></figure>\n<p>target</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">updateTargetGraph</span>(<span class=\"params\">tfVars,tau</span>):</span></span><br><span class=\"line\">    total_vars = <span class=\"built_in\">len</span>(tfVars)</span><br><span class=\"line\">    op_holder = [] </span><br><span class=\"line\">    <span class=\"comment\"># target</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> idx,var <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(tfVars[<span class=\"number\">0</span>:total_vars//<span class=\"number\">2</span>]):</span><br><span class=\"line\">        <span class=\"comment\"># idx+total_varstarget</span></span><br><span class=\"line\">        <span class=\"comment\"># target =  * tau + 1- tau*target</span></span><br><span class=\"line\">        <span class=\"comment\"># target</span></span><br><span class=\"line\">        <span class=\"comment\"># target</span></span><br><span class=\"line\">        <span class=\"comment\"># target</span></span><br><span class=\"line\">        <span class=\"comment\"># targetActionrewardAction</span></span><br><span class=\"line\">        <span class=\"comment\"># target</span></span><br><span class=\"line\">        <span class=\"comment\"># target</span></span><br><span class=\"line\">        <span class=\"comment\"># </span></span><br><span class=\"line\">        op_holder.append(tfVars[idx+total_vars//<span class=\"number\">2</span>].assign\\\\</span><br><span class=\"line\">                         ((var.value()*tau) \\\\</span><br><span class=\"line\">                      + ((<span class=\"number\">1</span>-tau)*tfVars[idx+total_vars//<span class=\"number\">2</span>].value())))</span><br><span class=\"line\">        <span class=\"keyword\">return</span> op_holder</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">updateTarget</span>(<span class=\"params\">op_holder,sess</span>):</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> op <span class=\"keyword\">in</span> op_holder:</span><br><span class=\"line\">            sess.run(op)</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<p>state of the arttrick</p>\n<ol>\n<li>CNN</li>\n<li>Experience replayNN batchsizeN=1</li>\n<li>target**targetQ-Learing********DQNQQ**targettargettargetQ</li>\n<li>Double DQNtricktargetActionactiontargetreward</li>\n<li>Dueling DQN</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">self.AW = tf.Variable(xavier_init([h_size//<span class=\"number\">2</span>,env.actions]))</span><br><span class=\"line\">self.VW = tf.Variable(xavier_init([h_size//<span class=\"number\">2</span>,<span class=\"number\">1</span>]))</span><br><span class=\"line\">self.Advantage = tf.matmul(self.streamA,self.AW)</span><br><span class=\"line\">self.Value = tf.matmul(self.streamV,self.VW)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#Then combine them together to get our final Q-values.</span></span><br><span class=\"line\"><span class=\"comment\"># QoutActionrewardValueAdvantage</span></span><br><span class=\"line\"><span class=\"comment\"># Valueadvantage#action</span></span><br><span class=\"line\"><span class=\"comment\"># Dueling DQNrewardValue</span></span><br><span class=\"line\"><span class=\"comment\"># ActionAction</span></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"comment\">#out</span></span><br><span class=\"line\"><span class=\"comment\"># Action</span></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\">self.Qout = self.Value + tf.subtract(self.Advantage,tf.reduce_mean(self.Advantage,axis=<span class=\"number\">1</span>,keep_dims=<span class=\"literal\">True</span>))</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<h2 id=\"\"></h2>\n<p>reward</p>\n<ol>\n<li>Action</li>\n<li>Actionreward</li>\n<li></li>\n<li>ActionAction1ActionrewardAction<strong>rewardreward</strong></li>\n</ol>\n<h1></h1>\n<p></p>\n<p></p>\n<p>sgd</p>\n<p></p>\n<p></p>\n<p>reward </p>\n<p>Q<sub>desired</sub>(s<sub>t</sub>, a<sub>t</sub>) = r + $\\lambda$ Max<sub>a</sub> Q<sub>desired</sub>(s<sub>t+1</sub>, a)</p>\n<p></p>\n<p></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> done:</span><br><span class=\"line\">    episode_number += <span class=\"number\">1</span></span><br><span class=\"line\">    epx = np.vstack(xs)</span><br><span class=\"line\">    epy = np.vstack(ys)</span><br><span class=\"line\">    epr = np.vstack(drs)</span><br><span class=\"line\">    tfp = tfps</span><br><span class=\"line\">    xs,hs,dlogps,drs,ys,tfps = [],[],[],[],[],[]</span><br><span class=\"line\"></span><br><span class=\"line\">    discounted_epr = discount_rewards(epr)</span><br><span class=\"line\">    discounted_epr -= np.mean(discounted_epr)</span><br><span class=\"line\">    discounted_epr //= np.std(discounted_epr)</span><br><span class=\"line\"></span><br><span class=\"line\">    tGrad = sess.run(newGrads,feed_dict=&#123;observations: epx, input_y: epy, advantages: discounted_epr&#125;)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> ix,grad <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(tGrad):</span><br><span class=\"line\">        gradBuffer[ix] += grad</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> episode_number % batch_size == <span class=\"number\">0</span>:</span><br><span class=\"line\">            sess.run(updateGrads,feed_dict=&#123;W1Grad: gradBuffer[<span class=\"number\">0</span>],W1_1Grad:gradBuffer[<span class=\"number\">1</span>],W2Grad:gradBuffer[<span class=\"number\">2</span>]&#125;)</span><br></pre></td></tr></table></figure>\n<p></p>\n"},{"title":"Shorcut on Linux","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2022-02-10T01:22:15.000Z","password":null,"summary":null,"description":"Describe the shortcuts of linux and how to set them","_content":"\n*Root in: I want to find out where the \"kill shortcut\", ctrl C, defined.\nI use `bind \n-P` to check the shortcuts. However, do not find ctrl C. Thus, I learned\nsomething about the shortcuts on linux.*\n*ctrl C is a shortcut of stty. However, `bind -P` lists the shortcuts\nof readline.*\n\nThere may be two kinds of shortcuts, in practice,\n* stty shortcuts\n* readline shortcuts\n\n# stty (set tty, set teletypewriter) #\n\n## The difference between shell, terminal and tty ##\n\ntty: Print the file name of the terminal connected to standard input.\n\nstty: change or print terminal characteristics, change and print terminal line settings.\n\nThey are related to terminal.\n\n* terminal = tty = text input/output environment\n* console = physical terminal\n* shell = command line interpreter\n\nThe input of terminal or tty will used by readline, but not always\nreadline.\n\n# gun readline - get a line from a user with editing #\n\n## Synopsis ##\n\n\n```c\n#include <stdio.h>\n#include <readline/readline.h>\n#include <readline/history.h>\n\nchar *\nreadline (const char *prompt)\n\n```\n\n\n## Description ##\n\n**readline will read a line from the terminal and return it, using\n*prompt* as a prompt.**\n\nIf prompt is NULL or the empty string, no prompt is issued.\nThe line returned is allocated with `malloc`; the caller must\nfree it when finished. The line returned has the final newline removed,\nso only the text of the line remains.\n\n## Return Value ##\n\nreadline returns the text of the line read. A black line returns the empty\nstring. If EOF is encountered while reading a line, and the line is empty,\nNULL is returned. If an EOF is read with a non-empty line, it is treated\nas a newline.\n\n## Initialization file ##\n\nReadline is customized by putting commands in an initialization file\n(the `inputrc` file). The name of this file is taken from the value of \nthe INPUTRC environment variable. If that variable is unset, the default\nis `~/.inputrc`. If that file does not exist or cannot be read, the\nultimate default is `/etc/inputrc`. \n\nWhen a program which uses the readline library starts up, the init\nfile is read, and the key bindings and variables are set. \n\nThere are only a few basic constructs allowed in the readline init file.\n\n1. Black lines are ignored.\n2. Lines beginning with a `#` are comments.\n3. Lines beginning with a `$` indicate conditional constructs.\n4. Other lines denote key bindings and variable settings.\n\n\n\nEach program using this library may add its own commands and bindings.\n\n\nFor example, placing\n```bash\nM-Control-u: universal-argment\n```\ninto the `inputrc` would make `M-C-u` execute the readline command\n`universal-argument`.\n\n# The difference of `help` and `man` on linux #\n\n`help` displays information about builtin shell commands.\n\n`man` is s system-wide documentation system that provides short\nreference manuals for individual commands, API functions, concepts,\nconfiguration file syntax, file formats. It is the traditional Unix\ndocumentation system.\n\nWe can get the information of `cd` by `help cd`, but not by `man cd`.\nWe can get the information of `git/nvim/stty` by `man git/nvim/stty`, but not by `help git/nvim/stty`.\n`cd` is a shell command and `git/nvim/stty` is linux projects. \n","source":"_posts/Shorcut-on-Linux.md","raw":"---\ntitle: Shorcut on Linux\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2022-02-10 09:22:15\npassword:\nsummary:\ndescription: Describe the shortcuts of linux and how to set them\ncategories:\n- Little Things\n- Linux\ntags:\n- Linux\n---\n\n*Root in: I want to find out where the \"kill shortcut\", ctrl C, defined.\nI use `bind \n-P` to check the shortcuts. However, do not find ctrl C. Thus, I learned\nsomething about the shortcuts on linux.*\n*ctrl C is a shortcut of stty. However, `bind -P` lists the shortcuts\nof readline.*\n\nThere may be two kinds of shortcuts, in practice,\n* stty shortcuts\n* readline shortcuts\n\n# stty (set tty, set teletypewriter) #\n\n## The difference between shell, terminal and tty ##\n\ntty: Print the file name of the terminal connected to standard input.\n\nstty: change or print terminal characteristics, change and print terminal line settings.\n\nThey are related to terminal.\n\n* terminal = tty = text input/output environment\n* console = physical terminal\n* shell = command line interpreter\n\nThe input of terminal or tty will used by readline, but not always\nreadline.\n\n# gun readline - get a line from a user with editing #\n\n## Synopsis ##\n\n\n```c\n#include <stdio.h>\n#include <readline/readline.h>\n#include <readline/history.h>\n\nchar *\nreadline (const char *prompt)\n\n```\n\n\n## Description ##\n\n**readline will read a line from the terminal and return it, using\n*prompt* as a prompt.**\n\nIf prompt is NULL or the empty string, no prompt is issued.\nThe line returned is allocated with `malloc`; the caller must\nfree it when finished. The line returned has the final newline removed,\nso only the text of the line remains.\n\n## Return Value ##\n\nreadline returns the text of the line read. A black line returns the empty\nstring. If EOF is encountered while reading a line, and the line is empty,\nNULL is returned. If an EOF is read with a non-empty line, it is treated\nas a newline.\n\n## Initialization file ##\n\nReadline is customized by putting commands in an initialization file\n(the `inputrc` file). The name of this file is taken from the value of \nthe INPUTRC environment variable. If that variable is unset, the default\nis `~/.inputrc`. If that file does not exist or cannot be read, the\nultimate default is `/etc/inputrc`. \n\nWhen a program which uses the readline library starts up, the init\nfile is read, and the key bindings and variables are set. \n\nThere are only a few basic constructs allowed in the readline init file.\n\n1. Black lines are ignored.\n2. Lines beginning with a `#` are comments.\n3. Lines beginning with a `$` indicate conditional constructs.\n4. Other lines denote key bindings and variable settings.\n\n\n\nEach program using this library may add its own commands and bindings.\n\n\nFor example, placing\n```bash\nM-Control-u: universal-argment\n```\ninto the `inputrc` would make `M-C-u` execute the readline command\n`universal-argument`.\n\n# The difference of `help` and `man` on linux #\n\n`help` displays information about builtin shell commands.\n\n`man` is s system-wide documentation system that provides short\nreference manuals for individual commands, API functions, concepts,\nconfiguration file syntax, file formats. It is the traditional Unix\ndocumentation system.\n\nWe can get the information of `cd` by `help cd`, but not by `man cd`.\nWe can get the information of `git/nvim/stty` by `man git/nvim/stty`, but not by `help git/nvim/stty`.\n`cd` is a shell command and `git/nvim/stty` is linux projects. \n","slug":"Shorcut-on-Linux","published":1,"updated":"2022-02-11T02:26:01.098Z","_id":"ckzhsa4gu000i4fvk8sj248al","comments":1,"layout":"post","photos":[],"link":"","content":"<html><head></head><body><p><em>Root in: I want to find out where the \"kill shortcut\", ctrl C, defined.<br>\nI use <code>bind  -P</code> to check the shortcuts. However, do not find ctrl C. Thus, I learned<br>\nsomething about the shortcuts on linux.</em><br>\n<em>ctrl C is a shortcut of stty. However, <code>bind -P</code> lists the shortcuts<br>\nof readline.</em></p>\n<p>There may be two kinds of shortcuts, in practice,<br>\n* stty shortcuts<br>\n* readline shortcuts</p>\n<h1 id=\"stty-set-tty-set-teletypewriter\"><span class=\"post-title-index\">1. </span>stty (set tty, set teletypewriter)</h1>\n<h2 id=\"the-difference-between-shell-terminal-and-tty\"><span class=\"post-title-index\">1.1. </span>The difference between shell, terminal and tty</h2>\n<p>tty: Print the file name of the terminal connected to standard input.</p>\n<p>stty: change or print terminal characteristics, change and print terminal line settings.</p>\n<p>They are related to terminal.</p>\n<ul>\n<li>terminal = tty = text input/output environment</li>\n<li>console = physical terminal</li>\n<li>shell = command line interpreter</li>\n</ul>\n<p>The input of terminal or tty will used by readline, but not always<br>\nreadline.</p>\n<h1 id=\"gun-readline---get-a-line-from-a-user-with-editing\"><span class=\"post-title-index\">2. </span>gun readline - get a line from a user with editing</h1>\n<h2 id=\"synopsis\"><span class=\"post-title-index\">2.1. </span>Synopsis</h2>\n<figure class=\"highlight c\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;readline/readline.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;readline/history.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">char</span> *</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">readline</span> <span class=\"params\">(<span class=\"keyword\">const</span> <span class=\"keyword\">char</span> *prompt)</span></span></span><br><span class=\"line\"><span class=\"function\"></span></span><br></pre></td></tr></tbody></table></figure>\n<h2 id=\"description\"><span class=\"post-title-index\">2.2. </span>Description</h2>\n<p><strong>readline will read a line from the terminal and return it, using<br>\n<em>prompt</em> as a prompt.</strong></p>\n<p>If prompt is NULL or the empty string, no prompt is issued.<br>\nThe line returned is allocated with <code>malloc</code>; the caller must<br>\nfree it when finished. The line returned has the final newline removed,<br>\nso only the text of the line remains.</p>\n<h2 id=\"return-value\"><span class=\"post-title-index\">2.3. </span>Return Value</h2>\n<p>readline returns the text of the line read. A black line returns the empty<br>\nstring. If EOF is encountered while reading a line, and the line is empty,<br>\nNULL is returned. If an EOF is read with a non-empty line, it is treated<br>\nas a newline.</p>\n<h2 id=\"initialization-file\"><span class=\"post-title-index\">2.4. </span>Initialization file</h2>\n<p>Readline is customized by putting commands in an initialization file<br>\n(the <code>inputrc</code> file). The name of this file is taken from the value of<br>\nthe INPUTRC environment variable. If that variable is unset, the default<br>\nis <code>~/.inputrc</code>. If that file does not exist or cannot be read, the<br>\nultimate default is <code>/etc/inputrc</code>.</p>\n<p>When a program which uses the readline library starts up, the init<br>\nfile is read, and the key bindings and variables are set.</p>\n<p>There are only a few basic constructs allowed in the readline init file.</p>\n<ol type=\"1\">\n<li>Black lines are ignored.</li>\n<li>Lines beginning with a <code>#</code> are comments.</li>\n<li>Lines beginning with a <code>$</code> indicate conditional constructs.</li>\n<li>Other lines denote key bindings and variable settings.</li>\n</ol>\n<p>Each program using this library may add its own commands and bindings.</p>\n<p>For example, placing<br>\n</p><figure class=\"highlight bash\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">M-Control-u: universal-argment</span><br></pre></td></tr></tbody></table></figure><br>\ninto the <code>inputrc</code> would make <code>M-C-u</code> execute the readline command<br>\n<code>universal-argument</code>.<p></p>\n<h1 id=\"the-difference-of-help-and-man-on-linux\"><span class=\"post-title-index\">3. </span>The difference of <code>help</code> and <code>man</code> on linux</h1>\n<p><code>help</code> displays information about builtin shell commands.</p>\n<p><code>man</code> is s system-wide documentation system that provides short<br>\nreference manuals for individual commands, API functions, concepts,<br>\nconfiguration file syntax, file formats. It is the traditional Unix<br>\ndocumentation system.</p>\n<p>We can get the information of <code>cd</code> by <code>help cd</code>, but not by <code>man cd</code>.<br>\nWe can get the information of <code>git/nvim/stty</code> by <code>man git/nvim/stty</code>, but not by <code>help git/nvim/stty</code>.<br>\n<code>cd</code> is a shell command and <code>git/nvim/stty</code> is linux projects.</p>\n</body></html>","site":{"data":{}},"excerpt":"<html><head></head><body></body></html>","more":"<p><em>Root in: I want to find out where the \"kill shortcut\", ctrl C, defined.<br />\nI use <code>bind  -P</code> to check the shortcuts. However, do not find ctrl C. Thus, I learned<br />\nsomething about the shortcuts on linux.</em><br />\n<em>ctrl C is a shortcut of stty. However, <code>bind -P</code> lists the shortcuts<br />\nof readline.</em></p>\n<p>There may be two kinds of shortcuts, in practice,<br />\n* stty shortcuts<br />\n* readline shortcuts</p>\n<h1 id=\"stty-set-tty-set-teletypewriter\">stty (set tty, set teletypewriter)</h1>\n<h2 id=\"the-difference-between-shell-terminal-and-tty\">The difference between shell, terminal and tty</h2>\n<p>tty: Print the file name of the terminal connected to standard input.</p>\n<p>stty: change or print terminal characteristics, change and print terminal line settings.</p>\n<p>They are related to terminal.</p>\n<ul>\n<li>terminal = tty = text input/output environment</li>\n<li>console = physical terminal</li>\n<li>shell = command line interpreter</li>\n</ul>\n<p>The input of terminal or tty will used by readline, but not always<br />\nreadline.</p>\n<h1 id=\"gun-readline---get-a-line-from-a-user-with-editing\">gun readline - get a line from a user with editing</h1>\n<h2 id=\"synopsis\">Synopsis</h2>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;readline/readline.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;readline/history.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">char</span> *</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">readline</span> <span class=\"params\">(<span class=\"keyword\">const</span> <span class=\"keyword\">char</span> *prompt)</span></span></span><br><span class=\"line\"><span class=\"function\"></span></span><br></pre></td></tr></table></figure>\n<h2 id=\"description\">Description</h2>\n<p><strong>readline will read a line from the terminal and return it, using<br />\n<em>prompt</em> as a prompt.</strong></p>\n<p>If prompt is NULL or the empty string, no prompt is issued.<br />\nThe line returned is allocated with <code>malloc</code>; the caller must<br />\nfree it when finished. The line returned has the final newline removed,<br />\nso only the text of the line remains.</p>\n<h2 id=\"return-value\">Return Value</h2>\n<p>readline returns the text of the line read. A black line returns the empty<br />\nstring. If EOF is encountered while reading a line, and the line is empty,<br />\nNULL is returned. If an EOF is read with a non-empty line, it is treated<br />\nas a newline.</p>\n<h2 id=\"initialization-file\">Initialization file</h2>\n<p>Readline is customized by putting commands in an initialization file<br />\n(the <code>inputrc</code> file). The name of this file is taken from the value of<br />\nthe INPUTRC environment variable. If that variable is unset, the default<br />\nis <code>~/.inputrc</code>. If that file does not exist or cannot be read, the<br />\nultimate default is <code>/etc/inputrc</code>.</p>\n<p>When a program which uses the readline library starts up, the init<br />\nfile is read, and the key bindings and variables are set.</p>\n<p>There are only a few basic constructs allowed in the readline init file.</p>\n<ol type=\"1\">\n<li>Black lines are ignored.</li>\n<li>Lines beginning with a <code>#</code> are comments.</li>\n<li>Lines beginning with a <code>$</code> indicate conditional constructs.</li>\n<li>Other lines denote key bindings and variable settings.</li>\n</ol>\n<p>Each program using this library may add its own commands and bindings.</p>\n<p>For example, placing<br />\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">M-Control-u: universal-argment</span><br></pre></td></tr></table></figure><br />\ninto the <code>inputrc</code> would make <code>M-C-u</code> execute the readline command<br />\n<code>universal-argument</code>.</p>\n<h1 id=\"the-difference-of-help-and-man-on-linux\">The difference of <code>help</code> and <code>man</code> on linux</h1>\n<p><code>help</code> displays information about builtin shell commands.</p>\n<p><code>man</code> is s system-wide documentation system that provides short<br />\nreference manuals for individual commands, API functions, concepts,<br />\nconfiguration file syntax, file formats. It is the traditional Unix<br />\ndocumentation system.</p>\n<p>We can get the information of <code>cd</code> by <code>help cd</code>, but not by <code>man cd</code>.<br />\nWe can get the information of <code>git/nvim/stty</code> by <code>man git/nvim/stty</code>, but not by <code>help git/nvim/stty</code>.<br />\n<code>cd</code> is a shell command and <code>git/nvim/stty</code> is linux projects.</p>\n"},{"title":"Personal Thought","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-12-15T08:01:28.000Z","password":null,"summary":null,"description":"","_content":"\n\n\n# Deep Learning\n\n## \n\n### \n\n\n\ni.e.\n\n\n\nA1A1\n\nmixup\n\n\n\n\n\n**MNIST, CIFAR-10100%**\n\n\n\n### neural tangent kernel\n\n**[^1]**\n\n[^1]:NEURAL TANGENT KERNEL EIGENVALUES ACCURATELY PREDICT GENERALIZATION\n\n\n\n## \n\n### \n\nResNet\n\n```python\nshortcut(x) + out\n# \nshortcut(x) * out\n```\n\n****\n\n1.  CNN\n2. ResNet3Dmaskattention module\n\n### \n\nCifar-100Cifar-10\n\n### \n\n\n\n1. \n2. \n\n\n\n\n\n1. bn``bn(shortcut(x)) * bn(out)``\n\n2. bnbias1bn(shortcut(x))bn(out)1 \n\n    **1. shortcut(x) + outshortcut(x)1out1**\n\n   **2. out 0shorcut**\n\n### sigmoid\n\n3. attentionsigmoid``bn(shortcut(x)) * out.sigmoid()``sigmoid sigmoid\n4. soft attentionsigmoid1.  2. 2d1dSE-Netattentionattention\n\n\n\n","source":"_posts/Personal-Thought.md","raw":"---\ntitle: Personal Thought\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-12-15 16:01:28\npassword:\nsummary:\ndescription: \ncategories:\n- About Papers\ntags:\n- Personal Thought\n- Papers\n- private\n---\n\n\n\n# Deep Learning\n\n## \n\n### \n\n\n\ni.e.\n\n\n\nA1A1\n\nmixup\n\n\n\n\n\n**MNIST, CIFAR-10100%**\n\n\n\n### neural tangent kernel\n\n**[^1]**\n\n[^1]:NEURAL TANGENT KERNEL EIGENVALUES ACCURATELY PREDICT GENERALIZATION\n\n\n\n## \n\n### \n\nResNet\n\n```python\nshortcut(x) + out\n# \nshortcut(x) * out\n```\n\n****\n\n1.  CNN\n2. ResNet3Dmaskattention module\n\n### \n\nCifar-100Cifar-10\n\n### \n\n\n\n1. \n2. \n\n\n\n\n\n1. bn``bn(shortcut(x)) * bn(out)``\n\n2. bnbias1bn(shortcut(x))bn(out)1 \n\n    **1. shortcut(x) + outshortcut(x)1out1**\n\n   **2. out 0shorcut**\n\n### sigmoid\n\n3. attentionsigmoid``bn(shortcut(x)) * out.sigmoid()``sigmoid sigmoid\n4. soft attentionsigmoid1.  2. 2d1dSE-Netattentionattention\n\n\n\n","slug":"Personal-Thought","published":1,"updated":"2022-01-17T09:43:07.977Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckzhsa4gw000m4fvk1bd30rfr","content":"<div class=\"hbe hbe-container\" id=\"hexo-blog-encrypt\" data-wpm=\"Oh, this is an invalid password. Check and try again, please.\" data-whm=\"OOPS, these decrypted content may changed, but you can still have a look.\">\n  <script id=\"hbeData\" type=\"hbeData\" data-hmacdigest=\"1f2471b7a24eed971cb44583c4098fbf6e85565be3f6d375ee3de45625c112c3\">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</script>\n  <div class=\"hbe hbe-content\">\n    <div class=\"hbe hbe-input hbe-input-default\">\n      <input class=\"hbe hbe-input-field hbe-input-field-default\" type=\"password\" id=\"hbePass\">\n      <label class=\"hbe hbe-input-label hbe-input-label-default\" for=\"hbePass\">\n        <span class=\"hbe hbe-input-label-content hbe-input-label-content-default\">Hey, password is required here.</span>\n      </label>\n    </div>\n  </div>\n</div>\n<script data-pjax src=\"/lib/hbe.js\"></script><link href=\"/css/hbe.style.css\" rel=\"stylesheet\" type=\"text/css\">","site":{"data":{}},"excerpt":"","more":"","origin":"<html><head></head><body><h1><span class=\"post-title-index\">1. </span>Deep Learning</h1>\n<h2 id=\"\"><span class=\"post-title-index\">1.1. </span></h2>\n<h3 id=\"\"><span class=\"post-title-index\">1.1.1. </span></h3>\n<p></p>\n<p>i.e.</p>\n<p></p>\n<p>A1A1</p>\n<p>mixup</p>\n<p></p>\n<p></p>\n<p><strong>MNIST, CIFAR-10100%</strong></p>\n<p></p>\n<h3 id=\"neural-tangent-kernel\"><span class=\"post-title-index\">1.1.2. </span>neural tangent kernel</h3>\n<p><strong><sup id=\"fnref:1\"><a href=\"#fn:1\" rel=\"footnote\">1</a></sup></strong></p>\n<h2 id=\"\"><span class=\"post-title-index\">1.2. </span></h2>\n<h3 id=\"\"><span class=\"post-title-index\">1.2.1. </span></h3>\n<p>ResNet</p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">shortcut(x) + out</span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\">shortcut(x) * out</span><br></pre></td></tr></tbody></table></figure>\n<p><strong></strong></p>\n<ol>\n<li> CNN</li>\n<li>ResNet3Dmaskattention module</li>\n</ol>\n<h3 id=\"\"><span class=\"post-title-index\">1.2.2. </span></h3>\n<p>Cifar-100Cifar-10</p>\n<h3 id=\"\"><span class=\"post-title-index\">1.2.3. </span></h3>\n<p></p>\n<ol>\n<li></li>\n<li></li>\n</ol>\n<p></p>\n<p></p>\n<ol>\n<li>\n<p>bn<code>bn(shortcut(x)) * bn(out)</code></p>\n</li>\n<li>\n<p>bnbias1bn(shortcut(x))bn(out)1</p>\n<p><strong>1. shortcut(x) + outshortcut(x)1out1</strong></p>\n<p><strong>2. out 0shorcut</strong></p>\n</li>\n</ol>\n<h3 id=\"sigmoid\"><span class=\"post-title-index\">1.2.4. </span>sigmoid</h3>\n<ol start=\"3\">\n<li>attentionsigmoid<code>bn(shortcut(x)) * out.sigmoid()</code>sigmoid sigmoid</li>\n<li>soft attentionsigmoid1.  2. 2d1dSE-Netattentionattention</li>\n</ol>\n<div id=\"footnotes\"><hr><div id=\"footnotelist\"><ol><li id=\"fn:1\">NEURAL TANGENT KERNEL EIGENVALUES ACCURATELY PREDICT GENERALIZATION<a href=\"#fnref:1\" rev=\"footnote\"> </a></li></ol></div></div></body></html>","encrypt":true},{"title":"Tips in Papers","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-12-14T08:33:03.000Z","password":null,"summary":null,"description":"","_content":"\n# Attention\n\n## Hard and Soft Attention\n\n### Attention Mechanisms in CV: A Survey\n\n## Gumbel-Softmax Hard Attention\n\n### Categorical Reparameterization with Gumbel-Softmax\n\n#### Stochastic Neural Networks with discrete random variables\n\n\n\n#### Stochastic Gradient Estimation\n\ndumbel-softmax, score function estimator, biased path derivative estimator\n\n> However, no existing gradient estimator has been formulated specifically for categorical variables.\n\n## Reinforce Learnning Hard Attention\n\n### 2019 Scacader: Improving Accuracy of Hard Attention Models for Vision\n\n#### Hard Attention\n\nhard attentionSoft Attention<div id=\"ap\"></div> \n\n> Our best models narrow the gap to common ImageNet baselines, achieving 75% top-1 and 91% top-5 while attending to less than one-third of the image.We further demonstrate that occluding the image patches prposed by the Saccader model highly impairs classification, thus confirming these patches strong relevance to the classification task.\n\n> Typical soft attention mechanisms rescale features at one or more stages of the network. The soft mask used for rescaling often to provide some insight into the model's decision-making process, but the model's final decision may nonetheless rely on information provided by features with small weights [^1]\n\n[^1]:2018,Learn to pay attention.\n\n#### glimpsepatchglimpse\n\n> Models that employ hard attention make decisions based on only a subset of pixel in the input image, typically in the form of a series of glimpses.\n\n#### Hard AttentionHard Attention\n\n> Altough our aim in this work is to perform classification with only image-level class labels, out approach bears some resembalance to two-stage object detection models. \n\n> These models operate by generating many region proposals and then applying a classification model to each proposal. \n\n> Unlike our work, these approaches use ground-truth bounding boxes to train the classification model, and modern architectures also use bounding boxes to supervise the proposal generator.\n\n**Hard AttentionHard Attention, i.e., **\n\n#### \n\n<img src=Saccader_Over.jpg width=80% height = 80%>\n\nrep. netlogits per locationrepresentation networkBagNet[^2]\n\natten. netattentionSacadder cellwhatwhereconcatmixed\n\nSaccader cell\n\n**coordinate at time tslicetprediction**\n\n[^2]:2019, Approximating CNNs with bag-of-local-features models works surprisingly well on ImageNet.  \n\n#### Saccader cell\n\n<img src=Saccader_Cell.jpg width=80% height = 80%>\n\n\n\n1. Cell statestatestate2d softmaxlogitlogitstate\n\n   > This cell produces a sequence of locations. Elements in the sequence correctpond to target locations.\n\n2. cell state$C^t$t1$C^{t - 1}$$C^t$$-10^5$ 2d softmax\n\n   > The cell includes a 2D state ($C^t$) that keeps memory of the visited locations until time t by placing 1 in the corresponding location in the cell state. We use this state to prevent the network from returning to previously seen locations.\n\n   **statesequencestatestate011sequencelogicstatelogic**\n\n3. $C^t$mixed feature$C^{t - 1}$$C^t$1mixed featurechannel attentionchannel attentionSE-Netmask mask$C^{t - 1}$\n\n4. > At test time, the model extracts the logits at time $t$ from the representation network at location $argmax_{i,j}(\\hat{R}^t_{i,j})$.The final prediction is obtained by averaging the extracted logits across all times.\n\n**Saccader Cellsequencesequencefeature**\n\n#### \n\n> The goal of our training is to learn a policy that predicts a sequence of visual attentnion locations that is useful to the downsteam task (here image classification) in absence of location labels.\n>\n> We performed a three step training procedure using only the training class lables as supervision.\n\n![](Saccader_eq1.jpg)\n\n1. representation network\n\n   $y_{target}$$y_{target}$region of interestposition\n\n   > Key to Saccader is a pretraining step that require only class lables and provides initial attention locations for policy gradient optimization.\n\n   > Our pretraining procedure overcomes the sparse-reward problem that makes hard attention models difficult to optimize. It requires access to only class lables and prvides initial attention locations.These initial locations provide better rewards for the policy gradient learning.\n\n![](Saccader_eq2.jpg)\n\n2. location network (attention network, $1 \\times 1$ mixing convolution and Sacader cell)\n\n   T = 12\n\n   <font color =deeppink> </font>\n\n![](Saccader_eq3.jpg)\n\n3. > we trained the whole model to maximize the expected reward, where the reward ($r \\in \\{0, 1\\}$) represents whether the model final prediction after 6 glimpses (T = 6) is correct. \n\n<font color=deeppink></font>\n\n\n$l^t_s$saccader cellrT$y_{target}$<div id=\"\"></div> \n\n**13loss$y_{target}$**\n\nsaccader cellsaccader cellpatch \n\n**[](#ap)**\n\n#### ordered logits policySaccader\n\n> An ordered logits policy uses the BagNet model to pick the top K locations based on the largest class logits.\n\nOrdered logits policy\n\n> The ordered logits policy strats off with accuracy much higher than a random policy, suggesting that the patches it initially picks are meaningful to classification.\n>\n> However, accuracy is still lower than the learned Saccader model, and **performacne improves only slowly with additional glimpese. The ordered logits policy is able to capture some of the features relevant to classification, but it is a greedy policy that produces glimpses that cluster around a few top features (i.e., with low image coverage)**\n\nordered logits policyglimpeseperformanceSaccader\n\n#### \n\n[](#)Sccaderglimplese\n\n> In fact, increasing the number of glimpses beyond the number used for DRAM policy training leads to drop in performane, ulike the Saccader model that generalizes to greater umbers of glimpses.\n\n<img src=Saccader_gl.jpg width=50% height = 50%>\n\nglimpsesSaccader[](#)<font color=deeppink></font>\n\n### Hard Attention for Scalable Image Classification\n\n#### \n\n<img src=Tnet_over.jpg width=50% height = 50%>\n\n> Muti-scale processing in the proposed TNet architecture. Starting from level 1, the image is processed in low resolution to get a coarse description of its content (red cube). Extracted features are used for (hard) selection of image regions worth processing in higher resolution. The process is repeated recursively (here to 2 additional levels). Features from all levels are combined (arrows on the right) to create the final image representation used for classificaiton (blue cube).\n\nSaccader\n\n## Soft Attention\n\n### NAM, Normalization-based Attention Module\n\n#### \n\n> Those methods successfully exploit the mutual information from different dimensions of feawture. However, they lack consideration on the contributing factors of weights, which is capable of furthr suppressing the insignificant channels or pixels.\n\n****\n\nbnbnattentionattentionbn**bn**\n$$\n\\begin{align}\natt &= norm(x) \\\\\natt &= att \\times \\gamma + \\delta \\\\\natt &= att \\times \\frac\\gamma{sum(\\gamma)} \\\\\nout &= att.sigmoid() \\times x\n\\end{align}\n$$\n\n```python\nclass Channel_Att(nn.Module):\n    def __init__(self, channels, t=16):\n        super(Channel_Att, self).__init__()\n        self.channels = channels   \n        self.bn2 = nn.BatchNorm2d(self.channels, affine=True)\n    def forward(self, x):\n        residual = x\n        x = self.bn2(x)\n        weight_bn = self.bn2.weight.data.abs() / torch.sum(self.bn2.weight.data.abs())\n        x = x.permute(0, 2, 3, 1).contiguous()\n        x = torch.mul(weight_bn, x)\n        x = x.permute(0, 3, 1, 2).contiguous()\n        x = torch.sigmoid(x) * residual  \n        return x\n```\n\n#### \n\n> It applies a weightsparsity penalty to the attention modules, thus, making them more computational efficient while retaining similar performance.\n>\n> To suppress the less salient weights, we add a regularization term into the loss function.\n\n$$\nLoss = \\sum_{(x,y)}l(f(x, W), y) + p\\sum g(\\gamma) + p \\sum g(\\lambda)\n$$\n\n$g$$\\gamma$bn$\\lambda$pix normalization\n\n<font color=deeppink>loss attentioncomputational efficient? computational efficientparameterFLOPS</font>\n\n#### \n\n<font color=deeppink></font>\n\n<font color=deeppink></font>\n\n\n\n# Regularization \n\n## ADCM: Attentnion Dropout Convolutional Module\n\n![ADCM](ADCM.jpg)\n\nCBAMCBAMattention weightsDropfeature mapdropattentionhard attention\n","source":"_posts/Tips-in-Papers.md","raw":"---\ntitle: Tips in Papers\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-12-14 16:33:03\npassword:\nsummary:\ndescription: \ncategories:\n- About Papers\ntags:\n- Papers\n- Personal Thought\n---\n\n# Attention\n\n## Hard and Soft Attention\n\n### Attention Mechanisms in CV: A Survey\n\n## Gumbel-Softmax Hard Attention\n\n### Categorical Reparameterization with Gumbel-Softmax\n\n#### Stochastic Neural Networks with discrete random variables\n\n\n\n#### Stochastic Gradient Estimation\n\ndumbel-softmax, score function estimator, biased path derivative estimator\n\n> However, no existing gradient estimator has been formulated specifically for categorical variables.\n\n## Reinforce Learnning Hard Attention\n\n### 2019 Scacader: Improving Accuracy of Hard Attention Models for Vision\n\n#### Hard Attention\n\nhard attentionSoft Attention<div id=\"ap\"></div> \n\n> Our best models narrow the gap to common ImageNet baselines, achieving 75% top-1 and 91% top-5 while attending to less than one-third of the image.We further demonstrate that occluding the image patches prposed by the Saccader model highly impairs classification, thus confirming these patches strong relevance to the classification task.\n\n> Typical soft attention mechanisms rescale features at one or more stages of the network. The soft mask used for rescaling often to provide some insight into the model's decision-making process, but the model's final decision may nonetheless rely on information provided by features with small weights [^1]\n\n[^1]:2018,Learn to pay attention.\n\n#### glimpsepatchglimpse\n\n> Models that employ hard attention make decisions based on only a subset of pixel in the input image, typically in the form of a series of glimpses.\n\n#### Hard AttentionHard Attention\n\n> Altough our aim in this work is to perform classification with only image-level class labels, out approach bears some resembalance to two-stage object detection models. \n\n> These models operate by generating many region proposals and then applying a classification model to each proposal. \n\n> Unlike our work, these approaches use ground-truth bounding boxes to train the classification model, and modern architectures also use bounding boxes to supervise the proposal generator.\n\n**Hard AttentionHard Attention, i.e., **\n\n#### \n\n<img src=Saccader_Over.jpg width=80% height = 80%>\n\nrep. netlogits per locationrepresentation networkBagNet[^2]\n\natten. netattentionSacadder cellwhatwhereconcatmixed\n\nSaccader cell\n\n**coordinate at time tslicetprediction**\n\n[^2]:2019, Approximating CNNs with bag-of-local-features models works surprisingly well on ImageNet.  \n\n#### Saccader cell\n\n<img src=Saccader_Cell.jpg width=80% height = 80%>\n\n\n\n1. Cell statestatestate2d softmaxlogitlogitstate\n\n   > This cell produces a sequence of locations. Elements in the sequence correctpond to target locations.\n\n2. cell state$C^t$t1$C^{t - 1}$$C^t$$-10^5$ 2d softmax\n\n   > The cell includes a 2D state ($C^t$) that keeps memory of the visited locations until time t by placing 1 in the corresponding location in the cell state. We use this state to prevent the network from returning to previously seen locations.\n\n   **statesequencestatestate011sequencelogicstatelogic**\n\n3. $C^t$mixed feature$C^{t - 1}$$C^t$1mixed featurechannel attentionchannel attentionSE-Netmask mask$C^{t - 1}$\n\n4. > At test time, the model extracts the logits at time $t$ from the representation network at location $argmax_{i,j}(\\hat{R}^t_{i,j})$.The final prediction is obtained by averaging the extracted logits across all times.\n\n**Saccader Cellsequencesequencefeature**\n\n#### \n\n> The goal of our training is to learn a policy that predicts a sequence of visual attentnion locations that is useful to the downsteam task (here image classification) in absence of location labels.\n>\n> We performed a three step training procedure using only the training class lables as supervision.\n\n![](Saccader_eq1.jpg)\n\n1. representation network\n\n   $y_{target}$$y_{target}$region of interestposition\n\n   > Key to Saccader is a pretraining step that require only class lables and provides initial attention locations for policy gradient optimization.\n\n   > Our pretraining procedure overcomes the sparse-reward problem that makes hard attention models difficult to optimize. It requires access to only class lables and prvides initial attention locations.These initial locations provide better rewards for the policy gradient learning.\n\n![](Saccader_eq2.jpg)\n\n2. location network (attention network, $1 \\times 1$ mixing convolution and Sacader cell)\n\n   T = 12\n\n   <font color =deeppink> </font>\n\n![](Saccader_eq3.jpg)\n\n3. > we trained the whole model to maximize the expected reward, where the reward ($r \\in \\{0, 1\\}$) represents whether the model final prediction after 6 glimpses (T = 6) is correct. \n\n<font color=deeppink></font>\n\n\n$l^t_s$saccader cellrT$y_{target}$<div id=\"\"></div> \n\n**13loss$y_{target}$**\n\nsaccader cellsaccader cellpatch \n\n**[](#ap)**\n\n#### ordered logits policySaccader\n\n> An ordered logits policy uses the BagNet model to pick the top K locations based on the largest class logits.\n\nOrdered logits policy\n\n> The ordered logits policy strats off with accuracy much higher than a random policy, suggesting that the patches it initially picks are meaningful to classification.\n>\n> However, accuracy is still lower than the learned Saccader model, and **performacne improves only slowly with additional glimpese. The ordered logits policy is able to capture some of the features relevant to classification, but it is a greedy policy that produces glimpses that cluster around a few top features (i.e., with low image coverage)**\n\nordered logits policyglimpeseperformanceSaccader\n\n#### \n\n[](#)Sccaderglimplese\n\n> In fact, increasing the number of glimpses beyond the number used for DRAM policy training leads to drop in performane, ulike the Saccader model that generalizes to greater umbers of glimpses.\n\n<img src=Saccader_gl.jpg width=50% height = 50%>\n\nglimpsesSaccader[](#)<font color=deeppink></font>\n\n### Hard Attention for Scalable Image Classification\n\n#### \n\n<img src=Tnet_over.jpg width=50% height = 50%>\n\n> Muti-scale processing in the proposed TNet architecture. Starting from level 1, the image is processed in low resolution to get a coarse description of its content (red cube). Extracted features are used for (hard) selection of image regions worth processing in higher resolution. The process is repeated recursively (here to 2 additional levels). Features from all levels are combined (arrows on the right) to create the final image representation used for classificaiton (blue cube).\n\nSaccader\n\n## Soft Attention\n\n### NAM, Normalization-based Attention Module\n\n#### \n\n> Those methods successfully exploit the mutual information from different dimensions of feawture. However, they lack consideration on the contributing factors of weights, which is capable of furthr suppressing the insignificant channels or pixels.\n\n****\n\nbnbnattentionattentionbn**bn**\n$$\n\\begin{align}\natt &= norm(x) \\\\\natt &= att \\times \\gamma + \\delta \\\\\natt &= att \\times \\frac\\gamma{sum(\\gamma)} \\\\\nout &= att.sigmoid() \\times x\n\\end{align}\n$$\n\n```python\nclass Channel_Att(nn.Module):\n    def __init__(self, channels, t=16):\n        super(Channel_Att, self).__init__()\n        self.channels = channels   \n        self.bn2 = nn.BatchNorm2d(self.channels, affine=True)\n    def forward(self, x):\n        residual = x\n        x = self.bn2(x)\n        weight_bn = self.bn2.weight.data.abs() / torch.sum(self.bn2.weight.data.abs())\n        x = x.permute(0, 2, 3, 1).contiguous()\n        x = torch.mul(weight_bn, x)\n        x = x.permute(0, 3, 1, 2).contiguous()\n        x = torch.sigmoid(x) * residual  \n        return x\n```\n\n#### \n\n> It applies a weightsparsity penalty to the attention modules, thus, making them more computational efficient while retaining similar performance.\n>\n> To suppress the less salient weights, we add a regularization term into the loss function.\n\n$$\nLoss = \\sum_{(x,y)}l(f(x, W), y) + p\\sum g(\\gamma) + p \\sum g(\\lambda)\n$$\n\n$g$$\\gamma$bn$\\lambda$pix normalization\n\n<font color=deeppink>loss attentioncomputational efficient? computational efficientparameterFLOPS</font>\n\n#### \n\n<font color=deeppink></font>\n\n<font color=deeppink></font>\n\n\n\n# Regularization \n\n## ADCM: Attentnion Dropout Convolutional Module\n\n![ADCM](ADCM.jpg)\n\nCBAMCBAMattention weightsDropfeature mapdropattentionhard attention\n","slug":"Tips-in-Papers","published":1,"updated":"2022-01-17T09:43:07.978Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckzhsa4h0000o4fvkg3e2dr33","content":"<html><head></head><body><h1><span class=\"post-title-index\">1. </span>Attention</h1>\n<h2 id=\"Hard-and-Soft-Attention\"><span class=\"post-title-index\">1.1. </span>Hard and Soft Attention</h2>\n<h3 id=\"Attention-Mechanisms-in-CV-A-Survey\"><span class=\"post-title-index\">1.1.1. </span>Attention Mechanisms in CV: A Survey</h3>\n<h2 id=\"Gumbel-Softmax-Hard-Attention\"><span class=\"post-title-index\">1.2. </span>Gumbel-Softmax Hard Attention</h2>\n<h3 id=\"Categorical-Reparameterization-with-Gumbel-Softmax\"><span class=\"post-title-index\">1.2.1. </span>Categorical Reparameterization with Gumbel-Softmax</h3>\n<h4 id=\"Stochastic-Neural-Networks-with-discrete-random-variables\"><span class=\"post-title-index\">1.2.1.1. </span>Stochastic Neural Networks with discrete random variables</h4>\n<p></p>\n<h4 id=\"Stochastic-Gradient-Estimation\"><span class=\"post-title-index\">1.2.1.2. </span>Stochastic Gradient Estimation</h4>\n<p>dumbel-softmax, score function estimator, biased path derivative estimator</p>\n<blockquote>\n<p>However, no existing gradient estimator has been formulated specifically for categorical variables.</p>\n</blockquote>\n<h2 id=\"Reinforce-Learnning-Hard-Attention\"><span class=\"post-title-index\">1.3. </span>Reinforce Learnning Hard Attention</h2>\n<h3 id=\"2019-Scacader-Improving-Accuracy-of-Hard-Attention-Models-for-Vision\"><span class=\"post-title-index\">1.3.1. </span>2019 Scacader: Improving Accuracy of Hard Attention Models for Vision</h3>\n<h4 id=\"Hard-Attention\"><span class=\"post-title-index\">1.3.1.1. </span>Hard Attention</h4>\n<p>hard attentionSoft Attention</p><div id=\"ap\"></div><p></p>\n<blockquote>\n<p>Our best models narrow the gap to common ImageNet baselines, achieving 75% top-1 and 91% top-5 while attending to less than one-third of the image.We further demonstrate that occluding the image patches prposed by the Saccader model highly impairs classification, thus confirming these patches strong relevance to the classification task.</p>\n</blockquote>\n<blockquote>\n<p>Typical soft attention mechanisms rescale features at one or more stages of the network. The soft mask used for rescaling often to provide some insight into the models decision-making process, but the models final decision may nonetheless rely on information provided by features with small weights <sup id=\"fnref:1\"><a href=\"#fn:1\" rel=\"footnote\">1</a></sup></p>\n</blockquote>\n<h4 id=\"glimpsepatchglimpse\"><span class=\"post-title-index\">1.3.1.2. </span>glimpsepatchglimpse</h4>\n<blockquote>\n<p>Models that employ hard attention make decisions based on only a subset of pixel in the input image, typically in the form of a series of glimpses.</p>\n</blockquote>\n<h4 id=\"Hard-AttentionHard-Attention\"><span class=\"post-title-index\">1.3.1.3. </span>Hard AttentionHard Attention</h4>\n<blockquote>\n<p>Altough our aim in this work is to perform classification with only image-level class labels, out approach bears some resembalance to two-stage object detection models.</p>\n</blockquote>\n<blockquote>\n<p>These models operate by generating many region proposals and then applying a classification model to each proposal.</p>\n</blockquote>\n<blockquote>\n<p>Unlike our work, these approaches use ground-truth bounding boxes to train the classification model, and modern architectures also use bounding boxes to supervise the proposal generator.</p>\n</blockquote>\n<p><strong>Hard AttentionHard Attention, i.e., </strong></p>\n<h4 id=\"\"><span class=\"post-title-index\">1.3.1.4. </span></h4>\n<img src=\"Saccader_Over.jpg\" width=\"80%\" height=\"80%\">\n<p>rep. netlogits per locationrepresentation networkBagNet<sup id=\"fnref:2\"><a href=\"#fn:2\" rel=\"footnote\">2</a></sup></p>\n<p>atten. netattentionSacadder cellwhatwhereconcatmixed</p>\n<p>Saccader cell</p>\n<p><strong>coordinate at time tslicetprediction</strong></p>\n<h4 id=\"Saccader-cell\"><span class=\"post-title-index\">1.3.1.5. </span>Saccader cell</h4>\n<img src=\"Saccader_Cell.jpg\" width=\"80%\" height=\"80%\">\n<p></p>\n<ol>\n<li>\n<p>Cell statestatestate2d softmaxlogitlogitstate</p>\n<blockquote>\n<p>This cell produces a sequence of locations. Elements in the sequence correctpond to target locations.</p>\n</blockquote>\n</li>\n<li>\n<p>cell state$C^t$t1$C^{t - 1}$$C^t$$-10^5$ 2d softmax</p>\n<blockquote>\n<p>The cell includes a 2D state ($C^t$) that keeps memory of the visited locations until time t by placing 1 in the corresponding location in the cell state. We use this state to prevent the network from returning to previously seen locations.</p>\n</blockquote>\n<p><strong>statesequencestatestate011sequencelogicstatelogic</strong></p>\n</li>\n<li>\n<p>$C^t$mixed feature$C^{t - 1}$$C^t$1mixed featurechannel attentionchannel attentionSE-Netmask mask$C^{t - 1}$</p>\n</li>\n<li>\n<blockquote>\n<p>At test time, the model extracts the logits at time $t$ from the representation network at location $argmax_{i,j}(\\hat{R}^t_{i,j})$.The final prediction is obtained by averaging the extracted logits across all times.</p>\n</blockquote>\n</li>\n</ol>\n<p><strong>Saccader Cellsequencesequencefeature</strong></p>\n<h4 id=\"\"><span class=\"post-title-index\">1.3.1.6. </span></h4>\n<blockquote>\n<p>The goal of our training is to learn a policy that predicts a sequence of visual attentnion locations that is useful to the downsteam task (here image classification) in absence of location labels.</p>\n<p>We performed a three step training procedure using only the training class lables as supervision.</p>\n</blockquote>\n<p><img src=\"Saccader_eq1.jpg\" alt=\"\"></p>\n<ol>\n<li>\n<p>representation network</p>\n<p>$y_{target}$$y_{target}$region of interestposition</p>\n<blockquote>\n<p>Key to Saccader is a pretraining step that require only class lables and provides initial attention locations for policy gradient optimization.</p>\n</blockquote>\n<blockquote>\n<p>Our pretraining procedure overcomes the sparse-reward problem that makes hard attention models difficult to optimize. It requires access to only class lables and prvides initial attention locations.These initial locations provide better rewards for the policy gradient learning.</p>\n</blockquote>\n</li>\n</ol>\n<p><img src=\"Saccader_eq2.jpg\" alt=\"\"></p>\n<ol start=\"2\">\n<li>\n<p>location network (attention network, $1 \\times 1$ mixing convolution and Sacader cell)</p>\n<p>T = 12</p>\n<p><font color=\"deeppink\"> </font></p>\n</li>\n</ol>\n<p><img src=\"Saccader_eq3.jpg\" alt=\"\"></p>\n<ol start=\"3\">\n<li>\n<blockquote>\n<p>we trained the whole model to maximize the expected reward, where the reward ($r \\in {0, 1}$) represents whether the model final prediction after 6 glimpses (T = 6) is correct.</p>\n</blockquote>\n</li>\n</ol>\n<p><font color=\"deeppink\"></font></p>\n<p>$l^t_s$saccader cellrT$y_{target}$</p><div id=\"\"></div><p></p>\n<p><strong>13loss$y_{target}$</strong></p>\n<p>saccader cellsaccader cellpatch</p>\n<p><strong><a href=\"#ap\"></a></strong></p>\n<h4 id=\"ordered-logits-policySaccader\"><span class=\"post-title-index\">1.3.1.7. </span>ordered logits policySaccader</h4>\n<blockquote>\n<p>An ordered logits policy uses the BagNet model to pick the top K locations based on the largest class logits.</p>\n</blockquote>\n<p>Ordered logits policy</p>\n<blockquote>\n<p>The ordered logits policy strats off with accuracy much higher than a random policy, suggesting that the patches it initially picks are meaningful to classification.</p>\n<p>However, accuracy is still lower than the learned Saccader model, and <strong>performacne improves only slowly with additional glimpese. The ordered logits policy is able to capture some of the features relevant to classification, but it is a greedy policy that produces glimpses that cluster around a few top features (i.e., with low image coverage)</strong></p>\n</blockquote>\n<p>ordered logits policyglimpeseperformanceSaccader</p>\n<h4 id=\"\"><span class=\"post-title-index\">1.3.1.8. </span></h4>\n<p><a href=\"#%E7%A9%BA%E9%97%B4\"></a>Sccaderglimplese</p>\n<blockquote>\n<p>In fact, increasing the number of glimpses beyond the number used for DRAM policy training leads to drop in performane, ulike the Saccader model that generalizes to greater umbers of glimpses.</p>\n</blockquote>\n<img src=\"Saccader_gl.jpg\" width=\"50%\" height=\"50%\">\n<p>glimpsesSaccader<a href=\"#%E7%A9%BA%E9%97%B4\"></a><font color=\"deeppink\"></font></p>\n<h3 id=\"Hard-Attention-for-Scalable-Image-Classification\"><span class=\"post-title-index\">1.3.2. </span>Hard Attention for Scalable Image Classification</h3>\n<h4 id=\"\"><span class=\"post-title-index\">1.3.2.1. </span></h4>\n<img src=\"Tnet_over.jpg\" width=\"50%\" height=\"50%\">\n<blockquote>\n<p>Muti-scale processing in the proposed TNet architecture. Starting from level 1, the image is processed in low resolution to get a coarse description of its content (red cube). Extracted features are used for (hard) selection of image regions worth processing in higher resolution. The process is repeated recursively (here to 2 additional levels). Features from all levels are combined (arrows on the right) to create the final image representation used for classificaiton (blue cube).</p>\n</blockquote>\n<p>Saccader</p>\n<h2 id=\"Soft-Attention\"><span class=\"post-title-index\">1.4. </span>Soft Attention</h2>\n<h3 id=\"NAM-Normalization-based-Attention-Module\"><span class=\"post-title-index\">1.4.1. </span>NAM, Normalization-based Attention Module</h3>\n<h4 id=\"\"><span class=\"post-title-index\">1.4.1.1. </span></h4>\n<blockquote>\n<p>Those methods successfully exploit the mutual information from different dimensions of feawture. However, they lack consideration on the contributing factors of weights, which is capable of furthr suppressing the insignificant channels or pixels.</p>\n</blockquote>\n<p><strong></strong></p>\n<p>bnbnattentionattentionbn<strong>bn</strong>\n$$\n\\begin{align}\natt &amp;= norm(x) \\\natt &amp;= att \\times \\gamma + \\delta \\\natt &amp;= att \\times \\frac\\gamma{sum(\\gamma)} \\\nout &amp;= att.sigmoid() \\times x\n\\end{align}\n$$</p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Channel_Att</span>(<span class=\"params\">nn.Module</span>):</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span>(<span class=\"params\">self, channels, t=<span class=\"number\">16</span></span>):</span></span><br><span class=\"line\">        <span class=\"built_in\">super</span>(Channel_Att, self).__init__()</span><br><span class=\"line\">        self.channels = channels   </span><br><span class=\"line\">        self.bn2 = nn.BatchNorm2d(self.channels, affine=<span class=\"literal\">True</span>)</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">forward</span>(<span class=\"params\">self, x</span>):</span></span><br><span class=\"line\">        residual = x</span><br><span class=\"line\">        x = self.bn2(x)</span><br><span class=\"line\">        weight_bn = self.bn2.weight.data.<span class=\"built_in\">abs</span>() / torch.<span class=\"built_in\">sum</span>(self.bn2.weight.data.<span class=\"built_in\">abs</span>())</span><br><span class=\"line\">        x = x.permute(<span class=\"number\">0</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">1</span>).contiguous()</span><br><span class=\"line\">        x = torch.mul(weight_bn, x)</span><br><span class=\"line\">        x = x.permute(<span class=\"number\">0</span>, <span class=\"number\">3</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>).contiguous()</span><br><span class=\"line\">        x = torch.sigmoid(x) * residual  </span><br><span class=\"line\">        <span class=\"keyword\">return</span> x</span><br></pre></td></tr></tbody></table></figure>\n<h4 id=\"\"><span class=\"post-title-index\">1.4.1.2. </span></h4>\n<blockquote>\n<p>It applies a weightsparsity penalty to the attention modules, thus, making them more computational efficient while retaining similar performance.</p>\n<p>To suppress the less salient weights, we add a regularization term into the loss function.</p>\n</blockquote>\n<p>$$\nLoss = \\sum_{(x,y)}l(f(x, W), y) + p\\sum g(\\gamma) + p \\sum g(\\lambda)\n$$</p>\n<p>$g$$\\gamma$bn$\\lambda$pix normalization</p>\n<p><font color=\"deeppink\">loss attentioncomputational efficient? computational efficientparameterFLOPS</font></p>\n<h4 id=\"\"><span class=\"post-title-index\">1.4.1.3. </span></h4>\n<p><font color=\"deeppink\"></font></p>\n<p><font color=\"deeppink\"></font></p>\n<h1><span class=\"post-title-index\">2. </span>Regularization</h1>\n<h2 id=\"ADCM-Attentnion-Dropout-Convolutional-Module\"><span class=\"post-title-index\">2.1. </span>ADCM: Attentnion Dropout Convolutional Module</h2>\n<p><img src=\"ADCM.jpg\" alt=\"ADCM\"></p>\n<p>CBAMCBAMattention weightsDropfeature mapdropattentionhard attention</p>\n<div id=\"footnotes\"><hr><div id=\"footnotelist\"><ol><li id=\"fn:1\">2018,Learn to pay attention.<a href=\"#fnref:1\" rev=\"footnote\"> </a></li><li id=\"fn:2\">2019, Approximating CNNs with bag-of-local-features models works surprisingly well on ImageNet.<a href=\"#fnref:2\" rev=\"footnote\"> </a></li></ol></div></div></body></html>","site":{"data":{}},"excerpt":"<html><head></head><body></body></html>","more":"<h1>Attention</h1>\n<h2 id=\"Hard-and-Soft-Attention\">Hard and Soft Attention</h2>\n<h3 id=\"Attention-Mechanisms-in-CV-A-Survey\">Attention Mechanisms in CV: A Survey</h3>\n<h2 id=\"Gumbel-Softmax-Hard-Attention\">Gumbel-Softmax Hard Attention</h2>\n<h3 id=\"Categorical-Reparameterization-with-Gumbel-Softmax\">Categorical Reparameterization with Gumbel-Softmax</h3>\n<h4 id=\"Stochastic-Neural-Networks-with-discrete-random-variables\">Stochastic Neural Networks with discrete random variables</h4>\n<p></p>\n<h4 id=\"Stochastic-Gradient-Estimation\">Stochastic Gradient Estimation</h4>\n<p>dumbel-softmax, score function estimator, biased path derivative estimator</p>\n<blockquote>\n<p>However, no existing gradient estimator has been formulated specifically for categorical variables.</p>\n</blockquote>\n<h2 id=\"Reinforce-Learnning-Hard-Attention\">Reinforce Learnning Hard Attention</h2>\n<h3 id=\"2019-Scacader-Improving-Accuracy-of-Hard-Attention-Models-for-Vision\">2019 Scacader: Improving Accuracy of Hard Attention Models for Vision</h3>\n<h4 id=\"Hard-Attention\">Hard Attention</h4>\n<p>hard attentionSoft Attention<div id=\"ap\"></div></p>\n<blockquote>\n<p>Our best models narrow the gap to common ImageNet baselines, achieving 75% top-1 and 91% top-5 while attending to less than one-third of the image.We further demonstrate that occluding the image patches prposed by the Saccader model highly impairs classification, thus confirming these patches strong relevance to the classification task.</p>\n</blockquote>\n<blockquote>\n<p>Typical soft attention mechanisms rescale features at one or more stages of the network. The soft mask used for rescaling often to provide some insight into the models decision-making process, but the models final decision may nonetheless rely on information provided by features with small weights <sup id=\"fnref:1\"><a href=\"#fn:1\" rel=\"footnote\">1</a></sup></p>\n</blockquote>\n<h4 id=\"glimpsepatchglimpse\">glimpsepatchglimpse</h4>\n<blockquote>\n<p>Models that employ hard attention make decisions based on only a subset of pixel in the input image, typically in the form of a series of glimpses.</p>\n</blockquote>\n<h4 id=\"Hard-AttentionHard-Attention\">Hard AttentionHard Attention</h4>\n<blockquote>\n<p>Altough our aim in this work is to perform classification with only image-level class labels, out approach bears some resembalance to two-stage object detection models.</p>\n</blockquote>\n<blockquote>\n<p>These models operate by generating many region proposals and then applying a classification model to each proposal.</p>\n</blockquote>\n<blockquote>\n<p>Unlike our work, these approaches use ground-truth bounding boxes to train the classification model, and modern architectures also use bounding boxes to supervise the proposal generator.</p>\n</blockquote>\n<p><strong>Hard AttentionHard Attention, i.e., </strong></p>\n<h4 id=\"\"></h4>\n<img src=Saccader_Over.jpg width=80% height = 80%>\n<p>rep. netlogits per locationrepresentation networkBagNet<sup id=\"fnref:2\"><a href=\"#fn:2\" rel=\"footnote\">2</a></sup></p>\n<p>atten. netattentionSacadder cellwhatwhereconcatmixed</p>\n<p>Saccader cell</p>\n<p><strong>coordinate at time tslicetprediction</strong></p>\n<h4 id=\"Saccader-cell\">Saccader cell</h4>\n<img src=Saccader_Cell.jpg width=80% height = 80%>\n<p></p>\n<ol>\n<li>\n<p>Cell statestatestate2d softmaxlogitlogitstate</p>\n<blockquote>\n<p>This cell produces a sequence of locations. Elements in the sequence correctpond to target locations.</p>\n</blockquote>\n</li>\n<li>\n<p>cell state$C^t$t1$C^{t - 1}$$C^t$$-10^5$ 2d softmax</p>\n<blockquote>\n<p>The cell includes a 2D state ($C^t$) that keeps memory of the visited locations until time t by placing 1 in the corresponding location in the cell state. We use this state to prevent the network from returning to previously seen locations.</p>\n</blockquote>\n<p><strong>statesequencestatestate011sequencelogicstatelogic</strong></p>\n</li>\n<li>\n<p>$C^t$mixed feature$C^{t - 1}$$C^t$1mixed featurechannel attentionchannel attentionSE-Netmask mask$C^{t - 1}$</p>\n</li>\n<li>\n<blockquote>\n<p>At test time, the model extracts the logits at time $t$ from the representation network at location $argmax_{i,j}(\\hat{R}^t_{i,j})$.The final prediction is obtained by averaging the extracted logits across all times.</p>\n</blockquote>\n</li>\n</ol>\n<p><strong>Saccader Cellsequencesequencefeature</strong></p>\n<h4 id=\"\"></h4>\n<blockquote>\n<p>The goal of our training is to learn a policy that predicts a sequence of visual attentnion locations that is useful to the downsteam task (here image classification) in absence of location labels.</p>\n<p>We performed a three step training procedure using only the training class lables as supervision.</p>\n</blockquote>\n<p><img src=\"Saccader_eq1.jpg\" alt=\"\"></p>\n<ol>\n<li>\n<p>representation network</p>\n<p>$y_{target}$$y_{target}$region of interestposition</p>\n<blockquote>\n<p>Key to Saccader is a pretraining step that require only class lables and provides initial attention locations for policy gradient optimization.</p>\n</blockquote>\n<blockquote>\n<p>Our pretraining procedure overcomes the sparse-reward problem that makes hard attention models difficult to optimize. It requires access to only class lables and prvides initial attention locations.These initial locations provide better rewards for the policy gradient learning.</p>\n</blockquote>\n</li>\n</ol>\n<p><img src=\"Saccader_eq2.jpg\" alt=\"\"></p>\n<ol start=\"2\">\n<li>\n<p>location network (attention network, $1 \\times 1$ mixing convolution and Sacader cell)</p>\n<p>T = 12</p>\n<p><font color =deeppink> </font></p>\n</li>\n</ol>\n<p><img src=\"Saccader_eq3.jpg\" alt=\"\"></p>\n<ol start=\"3\">\n<li>\n<blockquote>\n<p>we trained the whole model to maximize the expected reward, where the reward ($r \\in {0, 1}$) represents whether the model final prediction after 6 glimpses (T = 6) is correct.</p>\n</blockquote>\n</li>\n</ol>\n<p><font color=deeppink></font></p>\n<p>$l^t_s$saccader cellrT$y_{target}$<div id=\"\"></div></p>\n<p><strong>13loss$y_{target}$</strong></p>\n<p>saccader cellsaccader cellpatch</p>\n<p><strong><a href=\"#ap\"></a></strong></p>\n<h4 id=\"ordered-logits-policySaccader\">ordered logits policySaccader</h4>\n<blockquote>\n<p>An ordered logits policy uses the BagNet model to pick the top K locations based on the largest class logits.</p>\n</blockquote>\n<p>Ordered logits policy</p>\n<blockquote>\n<p>The ordered logits policy strats off with accuracy much higher than a random policy, suggesting that the patches it initially picks are meaningful to classification.</p>\n<p>However, accuracy is still lower than the learned Saccader model, and <strong>performacne improves only slowly with additional glimpese. The ordered logits policy is able to capture some of the features relevant to classification, but it is a greedy policy that produces glimpses that cluster around a few top features (i.e., with low image coverage)</strong></p>\n</blockquote>\n<p>ordered logits policyglimpeseperformanceSaccader</p>\n<h4 id=\"\"></h4>\n<p><a href=\"#%E7%A9%BA%E9%97%B4\"></a>Sccaderglimplese</p>\n<blockquote>\n<p>In fact, increasing the number of glimpses beyond the number used for DRAM policy training leads to drop in performane, ulike the Saccader model that generalizes to greater umbers of glimpses.</p>\n</blockquote>\n<img src=Saccader_gl.jpg width=50% height = 50%>\n<p>glimpsesSaccader<a href=\"#%E7%A9%BA%E9%97%B4\"></a><font color=deeppink></font></p>\n<h3 id=\"Hard-Attention-for-Scalable-Image-Classification\">Hard Attention for Scalable Image Classification</h3>\n<h4 id=\"\"></h4>\n<img src=Tnet_over.jpg width=50% height = 50%>\n<blockquote>\n<p>Muti-scale processing in the proposed TNet architecture. Starting from level 1, the image is processed in low resolution to get a coarse description of its content (red cube). Extracted features are used for (hard) selection of image regions worth processing in higher resolution. The process is repeated recursively (here to 2 additional levels). Features from all levels are combined (arrows on the right) to create the final image representation used for classificaiton (blue cube).</p>\n</blockquote>\n<p>Saccader</p>\n<h2 id=\"Soft-Attention\">Soft Attention</h2>\n<h3 id=\"NAM-Normalization-based-Attention-Module\">NAM, Normalization-based Attention Module</h3>\n<h4 id=\"\"></h4>\n<blockquote>\n<p>Those methods successfully exploit the mutual information from different dimensions of feawture. However, they lack consideration on the contributing factors of weights, which is capable of furthr suppressing the insignificant channels or pixels.</p>\n</blockquote>\n<p><strong></strong></p>\n<p>bnbnattentionattentionbn<strong>bn</strong>\n$$\n\\begin{align}\natt &amp;= norm(x) \\\natt &amp;= att \\times \\gamma + \\delta \\\natt &amp;= att \\times \\frac\\gamma{sum(\\gamma)} \\\nout &amp;= att.sigmoid() \\times x\n\\end{align}\n$$</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Channel_Att</span>(<span class=\"params\">nn.Module</span>):</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span>(<span class=\"params\">self, channels, t=<span class=\"number\">16</span></span>):</span></span><br><span class=\"line\">        <span class=\"built_in\">super</span>(Channel_Att, self).__init__()</span><br><span class=\"line\">        self.channels = channels   </span><br><span class=\"line\">        self.bn2 = nn.BatchNorm2d(self.channels, affine=<span class=\"literal\">True</span>)</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">forward</span>(<span class=\"params\">self, x</span>):</span></span><br><span class=\"line\">        residual = x</span><br><span class=\"line\">        x = self.bn2(x)</span><br><span class=\"line\">        weight_bn = self.bn2.weight.data.<span class=\"built_in\">abs</span>() / torch.<span class=\"built_in\">sum</span>(self.bn2.weight.data.<span class=\"built_in\">abs</span>())</span><br><span class=\"line\">        x = x.permute(<span class=\"number\">0</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">1</span>).contiguous()</span><br><span class=\"line\">        x = torch.mul(weight_bn, x)</span><br><span class=\"line\">        x = x.permute(<span class=\"number\">0</span>, <span class=\"number\">3</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>).contiguous()</span><br><span class=\"line\">        x = torch.sigmoid(x) * residual  </span><br><span class=\"line\">        <span class=\"keyword\">return</span> x</span><br></pre></td></tr></table></figure>\n<h4 id=\"\"></h4>\n<blockquote>\n<p>It applies a weightsparsity penalty to the attention modules, thus, making them more computational efficient while retaining similar performance.</p>\n<p>To suppress the less salient weights, we add a regularization term into the loss function.</p>\n</blockquote>\n<p>$$\nLoss = \\sum_{(x,y)}l(f(x, W), y) + p\\sum g(\\gamma) + p \\sum g(\\lambda)\n$$</p>\n<p>$g$$\\gamma$bn$\\lambda$pix normalization</p>\n<p><font color=deeppink>loss attentioncomputational efficient? computational efficientparameterFLOPS</font></p>\n<h4 id=\"\"></h4>\n<p><font color=deeppink></font></p>\n<p><font color=deeppink></font></p>\n<h1>Regularization</h1>\n<h2 id=\"ADCM-Attentnion-Dropout-Convolutional-Module\">ADCM: Attentnion Dropout Convolutional Module</h2>\n<p><img src=\"ADCM.jpg\" alt=\"ADCM\"></p>\n<p>CBAMCBAMattention weightsDropfeature mapdropattentionhard attention</p>\n<div id=\"footnotes\"><hr><div id=\"footnotelist\"><ol><li id=\"fn:1\">2018,Learn to pay attention.<a href=\"#fnref:1\" rev=\"footnote\"> </a></li><li id=\"fn:2\">2019, Approximating CNNs with bag-of-local-features models works surprisingly well on ImageNet.<a href=\"#fnref:2\" rev=\"footnote\"> </a></li></ol></div></div>"},{"title":"Transformer and BERT","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-12-18T02:00:56.000Z","password":null,"summary":null,"description":"NLPTransformerBERT.","_content":"\nI will introduce transformer and BERT according to their original papers.\n[^1] [^2]\n\n[^2]:BERT: Pre-training of Deep Bidirectional Transformer for Language Understanding\n[^1]:Attention is all you need\n\nBased on the two paper, we will also take the first step to NLP.\n\n# Transformer #\n\n\n\n# BERT #\n\n","source":"_posts/Transformer-and-BERT.md","raw":"---\ntitle: Transformer and BERT\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-12-18 10:00:56\npassword:\nsummary:\ndescription: NLPTransformerBERT.\ncategories:\n- Natural Language Processing\ntags:\n- Natural Language Processing\n- Transformer\n- BERT\n---\n\nI will introduce transformer and BERT according to their original papers.\n[^1] [^2]\n\n[^2]:BERT: Pre-training of Deep Bidirectional Transformer for Language Understanding\n[^1]:Attention is all you need\n\nBased on the two paper, we will also take the first step to NLP.\n\n# Transformer #\n\n\n\n# BERT #\n\n","slug":"Transformer-and-BERT","published":1,"updated":"2022-02-08T09:24:41.330Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckzhsa4h3000s4fvk2gyzd62r","content":"<html><head></head><body><p>I will introduce transformer and BERT according to their original papers.\n<sup id=\"fnref:1\"><a href=\"#fn:1\" rel=\"footnote\">1</a></sup> <sup id=\"fnref:2\"><a href=\"#fn:2\" rel=\"footnote\">2</a></sup></p>\n<p>Based on the two paper, we will also take the first step to NLP.</p>\n<h1><span class=\"post-title-index\">1. </span>Transformer</h1>\n<h1><span class=\"post-title-index\">2. </span>BERT</h1>\n<div id=\"footnotes\"><hr><div id=\"footnotelist\"><ol><li id=\"fn:1\">Attention is all you need<a href=\"#fnref:1\" rev=\"footnote\"> </a></li><li id=\"fn:2\">BERT: Pre-training of Deep Bidirectional Transformer for Language Understanding<a href=\"#fnref:2\" rev=\"footnote\"> </a></li></ol></div></div></body></html>","site":{"data":{}},"excerpt":"<html><head></head><body></body></html>","more":"<p>I will introduce transformer and BERT according to their original papers.\n<sup id=\"fnref:1\"><a href=\"#fn:1\" rel=\"footnote\">1</a></sup> <sup id=\"fnref:2\"><a href=\"#fn:2\" rel=\"footnote\">2</a></sup></p>\n<p>Based on the two paper, we will also take the first step to NLP.</p>\n<h1>Transformer</h1>\n<h1>BERT</h1>\n<div id=\"footnotes\"><hr><div id=\"footnotelist\"><ol><li id=\"fn:1\">Attention is all you need<a href=\"#fnref:1\" rev=\"footnote\"> </a></li><li id=\"fn:2\">BERT: Pre-training of Deep Bidirectional Transformer for Language Understanding<a href=\"#fnref:2\" rev=\"footnote\"> </a></li></ol></div></div>"}],"PostAsset":[{"_id":"source/_posts/An-Introduction-to-Git/git.jpg","slug":"git.jpg","post":"ckzhsa4g800034fvkhd0g7iv7","modified":0,"renderable":0},{"_id":"source/_posts/First-Step-to-RL/policy_network.py","slug":"policy_network.py","post":"ckzhsa4gs000h4fvkhboa5qsd","modified":0,"renderable":0},{"_id":"source/_posts/First-Step-to-RL/q_learning.py","slug":"q_learning.py","post":"ckzhsa4gs000h4fvkhboa5qsd","modified":0,"renderable":0},{"_id":"source/_posts/Tips-in-Papers/ADCM.jpg","slug":"ADCM.jpg","post":"ckzhsa4h0000o4fvkg3e2dr33","modified":0,"renderable":0},{"_id":"source/_posts/Tips-in-Papers/Saccader_Cell.jpg","slug":"Saccader_Cell.jpg","post":"ckzhsa4h0000o4fvkg3e2dr33","modified":0,"renderable":0},{"_id":"source/_posts/Tips-in-Papers/Saccader_Over.jpg","slug":"Saccader_Over.jpg","post":"ckzhsa4h0000o4fvkg3e2dr33","modified":0,"renderable":0},{"_id":"source/_posts/Tips-in-Papers/Saccader_eq1.jpg","slug":"Saccader_eq1.jpg","post":"ckzhsa4h0000o4fvkg3e2dr33","modified":0,"renderable":0},{"_id":"source/_posts/Tips-in-Papers/Saccader_eq2.jpg","slug":"Saccader_eq2.jpg","post":"ckzhsa4h0000o4fvkg3e2dr33","modified":0,"renderable":0},{"_id":"source/_posts/Tips-in-Papers/Saccader_eq3.jpg","slug":"Saccader_eq3.jpg","post":"ckzhsa4h0000o4fvkg3e2dr33","modified":0,"renderable":0},{"_id":"source/_posts/Tips-in-Papers/Saccader_gl.jpg","slug":"Saccader_gl.jpg","post":"ckzhsa4h0000o4fvkg3e2dr33","modified":0,"renderable":0},{"_id":"source/_posts/Tips-in-Papers/Tnet_over.jpg","slug":"Tnet_over.jpg","post":"ckzhsa4h0000o4fvkg3e2dr33","modified":0,"renderable":0}],"PostCategory":[{"post_id":"ckzhsa4g000014fvkci7l3cof","category_id":"ckzhsa4ga00044fvkelaxcfg7","_id":"ckzhsa4gr000f4fvkg05hbent"},{"post_id":"ckzhsa4gp000c4fvk6aascpoc","category_id":"ckzhsa4ga00044fvkelaxcfg7","_id":"ckzhsa4gv000j4fvkblhqhop0"},{"post_id":"ckzhsa4gf00084fvkal9fhgcp","category_id":"ckzhsa4gv000k4fvk4ui56yqd","_id":"ckzhsa4h4000u4fvk9b648of6"},{"post_id":"ckzhsa4gl00094fvkb7e035ce","category_id":"ckzhsa4h2000p4fvkaqta1xn2","_id":"ckzhsa4h6000z4fvkcpwq8oat"},{"post_id":"ckzhsa4g800034fvkhd0g7iv7","category_id":"ckzhsa4ga00044fvkelaxcfg7","_id":"ckzhsa4h700124fvk9m69gdjq"},{"post_id":"ckzhsa4g800034fvkhd0g7iv7","category_id":"ckzhsa4h5000w4fvk23z12bsm","_id":"ckzhsa4h700154fvkd30g17on"},{"post_id":"ckzhsa4gq000d4fvkhzz97how","category_id":"ckzhsa4h600104fvk0dlk2cf2","_id":"ckzhsa4h800164fvkev7d0bxu"},{"post_id":"ckzhsa4gs000h4fvkhboa5qsd","category_id":"ckzhsa4h700134fvkgshehna2","_id":"ckzhsa4h9001a4fvk2crvgh12"},{"post_id":"ckzhsa4ge00074fvkaqq79sef","category_id":"ckzhsa4ga00044fvkelaxcfg7","_id":"ckzhsa4hb001f4fvk96fw5xsx"},{"post_id":"ckzhsa4ge00074fvkaqq79sef","category_id":"ckzhsa4h800174fvkh65hdhd8","_id":"ckzhsa4hc001j4fvkh9qm6hx0"},{"post_id":"ckzhsa4gu000i4fvk8sj248al","category_id":"ckzhsa4ga00044fvkelaxcfg7","_id":"ckzhsa4hc001l4fvk3vd6d8dd"},{"post_id":"ckzhsa4gu000i4fvk8sj248al","category_id":"ckzhsa4h9001b4fvk86hy8jrs","_id":"ckzhsa4hd001o4fvk01mxah89"},{"post_id":"ckzhsa4gw000m4fvk1bd30rfr","category_id":"ckzhsa4hb001h4fvk6r52d82i","_id":"ckzhsa4he001q4fvkgrapezrb"},{"post_id":"ckzhsa4h0000o4fvkg3e2dr33","category_id":"ckzhsa4hb001h4fvk6r52d82i","_id":"ckzhsa4hi001t4fvk5qax9jy9"},{"post_id":"ckzhsa4h3000s4fvk2gyzd62r","category_id":"ckzhsa4hd001p4fvk0wetcc1x","_id":"ckzhsa4hj001x4fvkdjjm2bsv"}],"PostTag":[{"post_id":"ckzhsa4g000014fvkci7l3cof","tag_id":"ckzhsa4gc00054fvkhxx13cbl","_id":"ckzhsa4h0000n4fvk0qf33qo8"},{"post_id":"ckzhsa4g000014fvkci7l3cof","tag_id":"ckzhsa4gn000b4fvkca9n3n1o","_id":"ckzhsa4h2000q4fvkev95fe4z"},{"post_id":"ckzhsa4g000014fvkci7l3cof","tag_id":"ckzhsa4gs000g4fvkee2tg4vp","_id":"ckzhsa4h4000t4fvk3f4ketse"},{"post_id":"ckzhsa4g800034fvkhd0g7iv7","tag_id":"ckzhsa4gw000l4fvk8tvw366m","_id":"ckzhsa4h4000v4fvk8ytb3p4z"},{"post_id":"ckzhsa4ge00074fvkaqq79sef","tag_id":"ckzhsa4h2000r4fvkc762hfci","_id":"ckzhsa4h5000y4fvk8ej76ya8"},{"post_id":"ckzhsa4gf00084fvkal9fhgcp","tag_id":"ckzhsa4h5000x4fvk638yf5cv","_id":"ckzhsa4h900194fvk1ho44i46"},{"post_id":"ckzhsa4gf00084fvkal9fhgcp","tag_id":"ckzhsa4h600114fvkgzuecwf9","_id":"ckzhsa4h9001c4fvkgfsv0x6l"},{"post_id":"ckzhsa4gf00084fvkal9fhgcp","tag_id":"ckzhsa4h700144fvk919w3mv3","_id":"ckzhsa4ha001e4fvk06rd5aqf"},{"post_id":"ckzhsa4gl00094fvkb7e035ce","tag_id":"ckzhsa4h800184fvkbzcr43e9","_id":"ckzhsa4hb001g4fvk2k77f1r5"},{"post_id":"ckzhsa4gp000c4fvk6aascpoc","tag_id":"ckzhsa4ha001d4fvk3yat7fmn","_id":"ckzhsa4hc001k4fvkarw967ev"},{"post_id":"ckzhsa4gq000d4fvkhzz97how","tag_id":"ckzhsa4hb001i4fvkdl8154a1","_id":"ckzhsa4hh001s4fvk043sh4zg"},{"post_id":"ckzhsa4gq000d4fvkhzz97how","tag_id":"ckzhsa4hd001n4fvkg61ob7tm","_id":"ckzhsa4hi001u4fvk7j201ug4"},{"post_id":"ckzhsa4gs000h4fvkhboa5qsd","tag_id":"ckzhsa4he001r4fvk2oi6bzpq","_id":"ckzhsa4hj001w4fvkd4mo0heo"},{"post_id":"ckzhsa4gu000i4fvk8sj248al","tag_id":"ckzhsa4hi001v4fvk9t48f0fe","_id":"ckzhsa4hj001z4fvkhiuzg9er"},{"post_id":"ckzhsa4gw000m4fvk1bd30rfr","tag_id":"ckzhsa4h5000x4fvk638yf5cv","_id":"ckzhsa4hl00234fvk95tibavy"},{"post_id":"ckzhsa4gw000m4fvk1bd30rfr","tag_id":"ckzhsa4hk00204fvkfblwdac1","_id":"ckzhsa4hl00244fvkgwa8eb0e"},{"post_id":"ckzhsa4gw000m4fvk1bd30rfr","tag_id":"ckzhsa4h700144fvk919w3mv3","_id":"ckzhsa4hl00264fvkd5kzgkjy"},{"post_id":"ckzhsa4h0000o4fvkg3e2dr33","tag_id":"ckzhsa4hk00204fvkfblwdac1","_id":"ckzhsa4hm00284fvk4y3x3pq7"},{"post_id":"ckzhsa4h0000o4fvkg3e2dr33","tag_id":"ckzhsa4h5000x4fvk638yf5cv","_id":"ckzhsa4hm00294fvk4tmg6iow"},{"post_id":"ckzhsa4h3000s4fvk2gyzd62r","tag_id":"ckzhsa4hl00274fvk76r74xr4","_id":"ckzhsa4hn002c4fvk39ong5v3"},{"post_id":"ckzhsa4h3000s4fvk2gyzd62r","tag_id":"ckzhsa4hm002a4fvkbqc2d5up","_id":"ckzhsa4hn002d4fvk7z2j2rtn"},{"post_id":"ckzhsa4h3000s4fvk2gyzd62r","tag_id":"ckzhsa4hm002b4fvkfgvcbx3g","_id":"ckzhsa4hn002e4fvk2tgz4ohw"}],"Tag":[{"name":"vim","_id":"ckzhsa4gc00054fvkhxx13cbl"},{"name":"markdown","_id":"ckzhsa4gn000b4fvkca9n3n1o"},{"name":"vimtex","_id":"ckzhsa4gs000g4fvkee2tg4vp"},{"name":"Git","_id":"ckzhsa4gw000l4fvk8tvw366m"},{"name":"Hexo","_id":"ckzhsa4h2000r4fvkc762hfci"},{"name":"Personal Thought","_id":"ckzhsa4h5000x4fvk638yf5cv"},{"name":"Experiments","_id":"ckzhsa4h600114fvkgzuecwf9"},{"name":"private","_id":"ckzhsa4h700144fvk919w3mv3"},{"name":"Topological Data Analysis","_id":"ckzhsa4h800184fvkbzcr43e9"},{"name":"Multi Task Training","_id":"ckzhsa4ha001d4fvk3yat7fmn"},{"name":"Algorithm","_id":"ckzhsa4hb001i4fvkdl8154a1"},{"name":"Programming","_id":"ckzhsa4hd001n4fvkg61ob7tm"},{"name":"Reinforcement Learning","_id":"ckzhsa4he001r4fvk2oi6bzpq"},{"name":"Linux","_id":"ckzhsa4hi001v4fvk9t48f0fe"},{"name":"Papers","_id":"ckzhsa4hk00204fvkfblwdac1"},{"name":"Natural Language Processing","_id":"ckzhsa4hl00274fvk76r74xr4"},{"name":"Transformer","_id":"ckzhsa4hm002a4fvkbqc2d5up"},{"name":"BERT","_id":"ckzhsa4hm002b4fvkfgvcbx3g"}]}}