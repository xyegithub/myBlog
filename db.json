{"meta":{"version":1,"warehouse":"4.0.0"},"models":{"Asset":[{"_id":"themes/next_8.8/source/css/main.styl","path":"css/main.styl","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/css/noscript.styl","path":"css/noscript.styl","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/bookmark.js","path":"js/bookmark.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/comments-buttons.js","path":"js/comments-buttons.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/comments.js","path":"js/comments.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/config.js","path":"js/config.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/motion.js","path":"js/motion.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/next-boot.js","path":"js/next-boot.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/pjax.js","path":"js/pjax.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/schedule.js","path":"js/schedule.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/utils.js","path":"js/utils.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/images/apple-touch-icon-next.png","path":"images/apple-touch-icon-next.png","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/images/avatar.gif","path":"images/avatar.gif","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/images/favicon-16x16-next.png","path":"images/favicon-16x16-next.png","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/images/logo-algolia-nebula-blue-full.svg","path":"images/logo-algolia-nebula-blue-full.svg","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/images/favicon-32x32-next.png","path":"images/favicon-32x32-next.png","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/images/logo.svg","path":"images/logo.svg","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/images/ye_16.ico","path":"images/ye_16.ico","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/images/ye_32.ico","path":"images/ye_32.ico","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/schemes/muse.js","path":"js/schemes/muse.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/third-party/fancybox.js","path":"js/third-party/fancybox.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/third-party/pace.js","path":"js/third-party/pace.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/third-party/quicklink.js","path":"js/third-party/quicklink.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/third-party/rating.js","path":"js/third-party/rating.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/third-party/analytics/baidu-analytics.js","path":"js/third-party/analytics/baidu-analytics.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/third-party/analytics/google-analytics.js","path":"js/third-party/analytics/google-analytics.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/third-party/analytics/growingio.js","path":"js/third-party/analytics/growingio.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/third-party/chat/chatra.js","path":"js/third-party/chat/chatra.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/third-party/chat/gitter.js","path":"js/third-party/chat/gitter.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/third-party/chat/tidio.js","path":"js/third-party/chat/tidio.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/third-party/comments/changyan.js","path":"js/third-party/comments/changyan.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/third-party/comments/disqus.js","path":"js/third-party/comments/disqus.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/third-party/comments/disqusjs.js","path":"js/third-party/comments/disqusjs.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/third-party/comments/gitalk.js","path":"js/third-party/comments/gitalk.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/third-party/comments/isso.js","path":"js/third-party/comments/isso.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/third-party/comments/livere.js","path":"js/third-party/comments/livere.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/third-party/comments/utterances.js","path":"js/third-party/comments/utterances.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/third-party/math/katex.js","path":"js/third-party/math/katex.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/third-party/math/mathjax.js","path":"js/third-party/math/mathjax.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/third-party/statistics/firestore.js","path":"js/third-party/statistics/firestore.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/third-party/statistics/lean-analytics.js","path":"js/third-party/statistics/lean-analytics.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/third-party/search/algolia-search.js","path":"js/third-party/search/algolia-search.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/third-party/search/local-search.js","path":"js/third-party/search/local-search.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/third-party/tags/mermaid.js","path":"js/third-party/tags/mermaid.js","modified":0,"renderable":1},{"_id":"themes/next_8.8/source/js/third-party/tags/pdf.js","path":"js/third-party/tags/pdf.js","modified":0,"renderable":1}],"Cache":[{"_id":"source/_posts/An-Introduction-to-Git.md","hash":"5bffb32f7ea47f70f18c5367a9654afc2457ea19","modified":1639535532881},{"_id":"source/_posts/Construct-Your-Blog-with-Hexo-and-Github.md","hash":"72bd982e57011f68292f3f2d8d055bac89a37693","modified":1639712271057},{"_id":"source/_posts/Personal-Thought.md","hash":"75ec669371f3ade6e9d6582f0c7c385a8449b872","modified":1639708354369},{"_id":"source/_posts/Experiments.md","hash":"61213e01e07664ce36173128fc603673700bb7df","modified":1639708318769},{"_id":"source/_posts/First-Step-to-RL.md","hash":"15fb3d81dc2d8640f1dd7e9415be2f6c4133e2c7","modified":1639622354208},{"_id":"source/_posts/Tips-in-Papers.md","hash":"a08fee541201279bbf25ca58f4d6f4b2e35903bf","modified":1639704282949},{"_id":"source/about/index.md","hash":"05b5e469a2cd6f7de545752294be494eab99936d","modified":1639712859031},{"_id":"source/categories/index.md","hash":"408ea9b07f3b1a1339731fe7b364d88bc5644aff","modified":1637754696896},{"_id":"source/tags/index.md","hash":"3207ebf9794561395cf0c54633880ab070040ade","modified":1638946119840},{"_id":"source/_posts/First-Step-to-RL/policy_network.py","hash":"b3e8f06360cad0084a0656edaed4539f1b01e327","modified":1638761670499},{"_id":"source/_posts/First-Step-to-RL/q_learning.py","hash":"3a68ec1153d26f2c18c9d34ee5deb5e495b8dca9","modified":1638761670515},{"_id":"source/_posts/Tips-in-Papers/ADCM.jpg","hash":"ee5b75f3a063e07624c5f03111f98902d885cd8e","modified":1639703970059},{"_id":"source/_posts/An-Introduction-to-Git/git.jpg","hash":"db9ed8bb86df7e73d5be3bcae4cc8656e4a7a0ed","modified":1639191445656},{"_id":"themes/next_8.8/.editorconfig","hash":"731c650ddad6eb0fc7c3d4a91cad1698fe7ad311","modified":1638944857842},{"_id":"themes/next_8.8/.gitattributes","hash":"aeeca2f1e987d83232d7870d1435a4e3ed66b648","modified":1638944857843},{"_id":"themes/next_8.8/.eslintrc.json","hash":"611e15c3fcb41dc68fa8532ee595a1262a1b5a8a","modified":1638944857842},{"_id":"themes/next_8.8/.gitignore","hash":"087b7677078303acb2acb47432165950e4d29b43","modified":1638944857853},{"_id":"themes/next_8.8/LICENSE.md","hash":"8cfb03967dd4cbaf3b825271ffce0039aa3fc22a","modified":1638944857853},{"_id":"themes/next_8.8/.stylintrc","hash":"6259e2a0b65d46865ab89564b88fc67638668295","modified":1638944857853},{"_id":"themes/next_8.8/_config.yml","hash":"4ab5a431bed77cf248e5a6f2905e1bbedf1d7d3c","modified":1639637912097},{"_id":"themes/next_8.8/README.md","hash":"43fe29330352545446a532e6630866251129882a","modified":1638944857854},{"_id":"themes/next_8.8/_vendors.yml","hash":"ba72c575e627697a050614411706cb20206d4b71","modified":1638944857855},{"_id":"themes/next_8.8/crowdin.yml","hash":"4a53f5985e545c635cb56b2a57ed290cb8cf8942","modified":1638944857855},{"_id":"themes/next_8.8/renovate.json","hash":"767b077c7b615e20af3cf865813cd64674a9bea6","modified":1638944857899},{"_id":"themes/next_8.8/package.json","hash":"e527d094273cf3be4766630bbfe6cc8cf1eeb529","modified":1638944857899},{"_id":"themes/next_8.8/.githooks/install.js","hash":"305c2a269818466eed9e381b866c6cd1ad7f8afd","modified":1638944857843},{"_id":"themes/next_8.8/.github/CODE_OF_CONDUCT.md","hash":"593ae64e72d43c020a697eac65b1f9c3483ff097","modified":1638944857844},{"_id":"themes/next_8.8/.githooks/pre-commit","hash":"b69b9d0b51e27d5d4c87c3242f5067c2cda26e44","modified":1638944857844},{"_id":"themes/next_8.8/.github/CONTRIBUTING.md","hash":"2fdca1040427cabfe27cae6754ec5e027ec7092e","modified":1638944857844},{"_id":"themes/next_8.8/.github/PULL_REQUEST_TEMPLATE.md","hash":"a103e2d875f7434191859e5b42075cfa9a4cbcb3","modified":1638944857846},{"_id":"themes/next_8.8/.github/config.yml","hash":"0956bf71b6f36632b63b14d26580458041a5abd2","modified":1638944857847},{"_id":"themes/next_8.8/.github/issue_label_bot.yaml","hash":"533fbe6b2f87d7e7ec6949063bb7ea7eb4fbe52d","modified":1638944857847},{"_id":"themes/next_8.8/.github/label-commenter-config.yml","hash":"a1aa85a2fc66ff0c52c65bd97b0fa282e297a73f","modified":1638944857848},{"_id":"themes/next_8.8/.github/labeler.yml","hash":"ff76a903609932a867082b8ccced906e9910533a","modified":1638944857848},{"_id":"themes/next_8.8/.github/release-drafter.yml","hash":"de38f816e3023e0a5c1fd1f3c2b626f78bc35246","modified":1638944857848},{"_id":"themes/next_8.8/docs/AGPL3.md","hash":"f463f95b169d64983f59fa6f3e4b6760290a0e6b","modified":1638944857856},{"_id":"themes/next_8.8/docs/AUTHORS.md","hash":"579014d47f45b27fd1618b9709f0efe9585c7449","modified":1638944857856},{"_id":"themes/next_8.8/docs/LICENSE.txt","hash":"d1cd5a8e83d3bbdb50f902d2b487813da95ddfd3","modified":1638944857857},{"_id":"themes/next_8.8/languages/README.md","hash":"b1c96465b3bc139bf5ba6200974b66581d8ff85a","modified":1638944857859},{"_id":"themes/next_8.8/languages/ar.yml","hash":"cc7e3e2855348563d746f15c4752b9c63fcdd91a","modified":1638944857859},{"_id":"themes/next_8.8/languages/de.yml","hash":"83023c4246b93a2f89f342afe29a7b9e1185f74f","modified":1638944857859},{"_id":"themes/next_8.8/languages/default.yml","hash":"ea5e6aee4cb14510793ac4593a3bddffe23e530c","modified":1638944857860},{"_id":"themes/next_8.8/languages/en.yml","hash":"66445143decfbb5eb7031eb370698e31d5222a7a","modified":1638944857860},{"_id":"themes/next_8.8/languages/es.yml","hash":"07955d78028cea2a590c63fdc2c01ca3ee05a727","modified":1638944857860},{"_id":"themes/next_8.8/languages/fa.yml","hash":"e09fad889ab3ae87874093e1acd51edc9297d869","modified":1638944857861},{"_id":"themes/next_8.8/languages/id.yml","hash":"d7c337ca72efb0bd02ade8b5560c559384ad84dd","modified":1638944857861},{"_id":"themes/next_8.8/languages/it.yml","hash":"c038ff0cadbe405750d980bcacfd3900acf96905","modified":1638944857862},{"_id":"themes/next_8.8/languages/fr.yml","hash":"328c255c82e9b561e20a9f51a4d84abc63d1b90a","modified":1638944857861},{"_id":"themes/next_8.8/languages/ja.yml","hash":"57a35b21aca04ce8bca64fb5933f35626c462ea3","modified":1638944857862},{"_id":"themes/next_8.8/languages/ko.yml","hash":"d6e2add7488065ec4f7d21cfcf7f0eaa877a84f4","modified":1638944857862},{"_id":"themes/next_8.8/languages/nl.yml","hash":"e47858bd1e0d0622c15366ae6c0513d996f589e3","modified":1638944857863},{"_id":"themes/next_8.8/languages/ru.yml","hash":"7d13108f4a70ff6a162508a49678e4a477fa7b56","modified":1638944857863},{"_id":"themes/next_8.8/languages/pt-BR.yml","hash":"305025e932832328b7e2a8a584638a23c462e68f","modified":1638944857863},{"_id":"themes/next_8.8/languages/pt.yml","hash":"ff93459250c33d3c7ba06c30164cc4208edf9b33","modified":1638944857863},{"_id":"themes/next_8.8/languages/si.yml","hash":"c15ed758dbad890e856f4fc281208d7b78cc1a59","modified":1638944857864},{"_id":"themes/next_8.8/languages/tr.yml","hash":"d3262d2221b0583a52e5d20a3cd1380f5dc49378","modified":1638944857864},{"_id":"themes/next_8.8/languages/uk.yml","hash":"f32871f67c63d26bc4e3e15df9b01f5a41236a50","modified":1638944857864},{"_id":"themes/next_8.8/languages/vi.yml","hash":"e452ea8c48993262a3e8fce9d92072cafabfc734","modified":1638944857865},{"_id":"themes/next_8.8/languages/zh-CN.yml","hash":"f8379d15038e22ef7039d91272cb4f36842dbbe1","modified":1638944857865},{"_id":"themes/next_8.8/languages/zh-HK.yml","hash":"c1ee97ceb56da76ecdc7b69fa975f28c8574441b","modified":1638944857865},{"_id":"themes/next_8.8/languages/zh-TW.yml","hash":"70c45076ad722b777956048fcc430eac37844c11","modified":1638944857865},{"_id":"themes/next_8.8/layout/_layout.njk","hash":"2842f3e9fdde5bbd14cac89629221e68d80c8ea1","modified":1638944857866},{"_id":"themes/next_8.8/layout/category.njk","hash":"82f541452cae76a94ee15cb8d8a888f44260a0fd","modified":1638944857897},{"_id":"themes/next_8.8/layout/archive.njk","hash":"aa491dba8f746e626c273a920effedf7d0b32170","modified":1638944857897},{"_id":"themes/next_8.8/layout/post.njk","hash":"707a50e50b90df5fbeaf8407d12895d04163a290","modified":1638944857898},{"_id":"themes/next_8.8/layout/index.njk","hash":"fa52c3049871e879980cb6abccdea3792ca4ce70","modified":1638944857898},{"_id":"themes/next_8.8/layout/page.njk","hash":"fddfdee95f5da86eab8a85d6eb1901996d2153cf","modified":1638944857898},{"_id":"themes/next_8.8/layout/tag.njk","hash":"b6c017d30d08ddd30d66e9c6f3a71aa65d214eac","modified":1638944857899},{"_id":"themes/next_8.8/test/index.js","hash":"983a505399796b9d9e174ba46d89abbdde38f8ee","modified":1638944857965},{"_id":"themes/next_8.8/.github/ISSUE_TEMPLATE/bug-report.md","hash":"032194e7975564176f2109aa8b7c020fa6d5e6b1","modified":1638944857845},{"_id":"themes/next_8.8/.github/ISSUE_TEMPLATE/config.yml","hash":"daeedc5da2ee74ac31cf71846b766ca6499e9fc6","modified":1638944857845},{"_id":"themes/next_8.8/.github/ISSUE_TEMPLATE/feature-request.md","hash":"4a7885fe2c8b25be02ab57c345cd862aeeeeacaf","modified":1638944857846},{"_id":"themes/next_8.8/.github/ISSUE_TEMPLATE/other.md","hash":"618d07b49f4774cd79613d4001984a19d954a6ad","modified":1638944857846},{"_id":"themes/next_8.8/.github/workflows/label-commenter.yml","hash":"7dec949b13131783e726facb2f4acde0945db1b8","modified":1638944857849},{"_id":"themes/next_8.8/.github/workflows/labeler.yml","hash":"46d0b29dc561fe571d91fd06a7c8ef606b984c72","modified":1638944857849},{"_id":"themes/next_8.8/.github/workflows/lock.yml","hash":"58eca481fd71088a8ae1dbc04645bcfc03460b87","modified":1638944857849},{"_id":"themes/next_8.8/.github/workflows/linter.yml","hash":"b57d876c90d1645a52bbba8a52d47ad0b0c96140","modified":1638944857849},{"_id":"themes/next_8.8/.github/workflows/release-drafter.yml","hash":"359b74890a47d784e35a5cc3c7885d5cdf302e82","modified":1638944857852},{"_id":"themes/next_8.8/.github/workflows/tester.yml","hash":"645bb69d0b6cc062c47fabb1ccb2297ccbcfa7f5","modified":1638944857852},{"_id":"themes/next_8.8/.github/workflows/stale.yml","hash":"32e7dfb55ecf8af66aebfed471be09ef2eb10e18","modified":1638944857852},{"_id":"themes/next_8.8/docs/ru/README.md","hash":"e1d6bf38cf34972ca2ee5331a727787fe14082a3","modified":1638944857857},{"_id":"themes/next_8.8/docs/zh-CN/CODE_OF_CONDUCT.md","hash":"7befb4325b107dd668d9eae3d7e86a34910ce3f2","modified":1638944857858},{"_id":"themes/next_8.8/docs/zh-CN/CONTRIBUTING.md","hash":"a09ceb82b45dd8b7da76c227f3d0bb7eebe7d5d1","modified":1638944857858},{"_id":"themes/next_8.8/docs/zh-CN/README.md","hash":"354b0b0a24cbe97cccf2ec8bd97eb7d624fa0dea","modified":1638944857858},{"_id":"themes/next_8.8/layout/_macro/post-collapse.njk","hash":"d9d8e6d7a6a8c80009dd5334cc17fd3e4977a008","modified":1638944857867},{"_id":"themes/next_8.8/layout/_macro/post.njk","hash":"367cafd3acc1c6a045d8a72de0479aabbf4a3559","modified":1638944857867},{"_id":"themes/next_8.8/layout/_macro/sidebar.njk_backup","hash":"eec74e135d01948361020140c3798769e1e7363b","modified":1639644621600},{"_id":"themes/next_8.8/layout/_partials/comments.njk","hash":"d6b7bb7764e3b471ed6b4e5715f6cbe2dd453f59","modified":1638944857868},{"_id":"themes/next_8.8/layout/_macro/sidebar.njk","hash":"f3c1fc4b3333cb09a40b6b3b9042e5ab277fe885","modified":1639645479653},{"_id":"themes/next_8.8/layout/_partials/footer.njk","hash":"0347cb6077a969136aac26ebdc205a7817010ee7","modified":1639127865723},{"_id":"themes/next_8.8/layout/_partials/languages.njk","hash":"537026fc120adeef9148c98ebf074207e3810538","modified":1638944857871},{"_id":"themes/next_8.8/layout/_partials/pagination.njk","hash":"2de77d533c91532a8a4052000244d0c1693370df","modified":1638944857873},{"_id":"themes/next_8.8/layout/_partials/widgets.njk","hash":"967594ee64805e27b7ff9d957e23ab3f5c948600","modified":1638944857877},{"_id":"themes/next_8.8/layout/_scripts/index.njk","hash":"4eb65641b47ea9b23ed2ddfd69b18f21d7d8f214","modified":1638944857877},{"_id":"themes/next_8.8/layout/_scripts/vendors.njk","hash":"0a1470440f11362df2b1cd6b6228e273d9f999d6","modified":1638944857877},{"_id":"themes/next_8.8/layout/_third-party/fancybox.njk","hash":"53ad3c31762b74e5d29787b37d5e494cc4fded9b","modified":1638944857888},{"_id":"themes/next_8.8/layout/_third-party/pace.njk","hash":"13b2a77b4858a127f458ea092b6f713b052befac","modified":1638944857890},{"_id":"themes/next_8.8/layout/_third-party/index.njk","hash":"33a4a3275474bd3bb2e8d1b0ea01b42dda9ea608","modified":1638944857888},{"_id":"themes/next_8.8/layout/_third-party/quicklink.njk","hash":"73bc15a9c3c5c239ab90efa19a1e721f41f3cb93","modified":1638944857890},{"_id":"themes/next_8.8/layout/_third-party/rating.njk","hash":"d0444179fec512760ab1d4f76928d795b971c884","modified":1638944857891},{"_id":"themes/next_8.8/scripts/events/index.js","hash":"8bca7ae3cebb3857866d718a562c5d8820fcfbe5","modified":1638944857900},{"_id":"themes/next_8.8/scripts/filters/default-injects.js","hash":"0c9a1fe9906672724dbf274154a37bac1915ca2c","modified":1638944857905},{"_id":"themes/next_8.8/scripts/filters/post.js","hash":"5a132b7f9280a40b3d5fb40928c8cbbe071fe6f6","modified":1638944857906},{"_id":"themes/next_8.8/scripts/filters/minify.js","hash":"9789307212d729c8cb65e3541348938a1965ff6f","modified":1638944857906},{"_id":"themes/next_8.8/scripts/filters/locals.js","hash":"8499b9c8c6cdae8aa7e4f5ec5b4b76037969db76","modified":1638944857905},{"_id":"themes/next_8.8/scripts/helpers/engine.js","hash":"18cc82558e7a9f3b6086c41ce9de0c46e807a66c","modified":1638944857906},{"_id":"themes/next_8.8/scripts/filters/number.js","hash":"63735cb9d02921e25b2606490340a70db89abbec","modified":1638945314670},{"_id":"themes/next_8.8/scripts/helpers/font.js","hash":"0a6fa582a0890ecaf5f03f758a730936e48aeca1","modified":1638944857907},{"_id":"themes/next_8.8/scripts/helpers/next-config.js","hash":"e73f43f1bcb46965e317285d6831e129a40ea59b","modified":1638944857907},{"_id":"themes/next_8.8/scripts/helpers/next-url.js","hash":"98fc68cf3fcd6253bbb94068ab1d86578a4ef9ea","modified":1638944857908},{"_id":"themes/next_8.8/scripts/helpers/next-vendors.js","hash":"52acbc74c1ead8a77cd3bbcba4e033053683f7d0","modified":1638944857908},{"_id":"themes/next_8.8/scripts/tags/button.js","hash":"86c71c73a63744efbbbb367612871fede0d69529","modified":1638944857909},{"_id":"themes/next_8.8/scripts/tags/caniuse.js","hash":"8e912c715702addaf0cefe63e580e45b97ae8c3f","modified":1638944857909},{"_id":"themes/next_8.8/scripts/tags/group-pictures.js","hash":"1c609312a71d47f838226346aad5c2e1c35f15dd","modified":1638944857909},{"_id":"themes/next_8.8/scripts/tags/center-quote.js","hash":"b4d12e6fe29089be0f43bafc9eea736602cd16bf","modified":1638944857909},{"_id":"themes/next_8.8/scripts/tags/index.js","hash":"255dd1090e8319b557eeca43571f0e4f8aab013b","modified":1638944857910},{"_id":"themes/next_8.8/scripts/tags/label.js","hash":"c18b0e619a779ed40be7f014db92af18f45fbd5c","modified":1638944857910},{"_id":"themes/next_8.8/scripts/tags/link-grid.js","hash":"3f358bb78c5c6fdf45de287f3ead553e3a6a93c2","modified":1638944857910},{"_id":"themes/next_8.8/scripts/tags/mermaid.js","hash":"b3844e168b51a99d495ca05562ffac47677f5728","modified":1638944857911},{"_id":"themes/next_8.8/scripts/tags/pdf.js","hash":"317ba4611020cc840854386dde098dbbe452777e","modified":1638944857911},{"_id":"themes/next_8.8/scripts/tags/note.js","hash":"a12fd53e421400836a3722ae69130969558d6ac0","modified":1638944857911},{"_id":"themes/next_8.8/scripts/tags/video.js","hash":"f6ad3f52779f0636251238d3cbdc5b6f91cc5aba","modified":1638944857912},{"_id":"themes/next_8.8/scripts/tags/tabs.js","hash":"e0ed5fe1bc9d2957952a1aacdf3252d6ef3f9743","modified":1638944857912},{"_id":"themes/next_8.8/source/css/_mixins.styl","hash":"2ca820b221fb7458e6ef4fbcff826e1d1cf4b473","modified":1638944857938},{"_id":"themes/next_8.8/source/css/_colors.styl","hash":"a88430865c99f47ce1d8240f8895819b8b7b0c06","modified":1638944857912},{"_id":"themes/next_8.8/source/css/main.styl","hash":"38b8a12681a3a04bed02aa1659054912ed6def11","modified":1638944857948},{"_id":"themes/next_8.8/source/css/noscript.styl","hash":"7dc97674c232f6ca71e48b95e3f66472cd8e9c05","modified":1638944857948},{"_id":"themes/next_8.8/source/js/bookmark.js","hash":"1457291a7244b7786ec35b949d97183e4fbd181d","modified":1638944857950},{"_id":"themes/next_8.8/source/js/comments-buttons.js","hash":"81ea6cbcdf0357094753d7523919c1eafa38e79f","modified":1638944857951},{"_id":"themes/next_8.8/source/js/comments.js","hash":"0b4daf0ce610760bd52e95d423f61f3e1c72442a","modified":1638944857951},{"_id":"themes/next_8.8/source/js/config.js","hash":"211a9ab35205ccfa6b7c74394bade84da0d00af7","modified":1638944857951},{"_id":"themes/next_8.8/source/js/motion.js","hash":"20b979ebe3671cb415e6e7171485d65cc347086e","modified":1638944857952},{"_id":"themes/next_8.8/source/js/next-boot.js","hash":"b0bdb542a809932182cfbb8772328115142a0b77","modified":1638944857952},{"_id":"themes/next_8.8/source/js/pjax.js","hash":"85293c253e0f43540572c4e4615c712325a732e2","modified":1638944857952},{"_id":"themes/next_8.8/source/js/schedule.js","hash":"6dade4388aa6579576a35758075134f573985d57","modified":1638944857953},{"_id":"themes/next_8.8/source/js/utils.js","hash":"c13fa66aae52f59f88881738c00ebdcaf0209496","modified":1638944857963},{"_id":"themes/next_8.8/source/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1638944857948},{"_id":"themes/next_8.8/source/images/avatar.gif","hash":"2dbc3e2f2d624b2ca1afe6edc2ca17307f1950c8","modified":1638944857949},{"_id":"themes/next_8.8/source/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1638944857949},{"_id":"themes/next_8.8/source/images/logo-algolia-nebula-blue-full.svg","hash":"b85e274207b1392782476a0430feac98db1e7da0","modified":1638944857950},{"_id":"themes/next_8.8/source/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1638944857949},{"_id":"themes/next_8.8/source/images/logo.svg","hash":"2cb74fd3ea2635e015eabc58a8d488aed6cf6417","modified":1638944857950},{"_id":"themes/next_8.8/source/images/ye_16.ico","hash":"b8fb01b5361da89831d232a831a1532e9822bd72","modified":1638945436254},{"_id":"themes/next_8.8/source/images/ye_32.ico","hash":"375c99cd785d93dd989c36604ffbd10ada71322a","modified":1638945436261},{"_id":"themes/next_8.8/test/helpers/font.js","hash":"6f5076bd3f2724e47b46ca69028393a9b6275cd1","modified":1638944857964},{"_id":"themes/next_8.8/test/helpers/index.js","hash":"2fb58dca3df2fe53116ee2b1232fa26ebe7b2ce5","modified":1638944857964},{"_id":"themes/next_8.8/test/helpers/next-url.js","hash":"08e84781f1cd54e5634b86877ad9cefae4a78e95","modified":1638944857964},{"_id":"themes/next_8.8/test/tags/center-quote.js","hash":"2ac4b5a358681691a17e736de06fce0b640a7023","modified":1638944857966},{"_id":"themes/next_8.8/test/tags/button.js","hash":"a50ca44eaec3d91c2958e3157d624cd3e68828c7","modified":1638944857965},{"_id":"themes/next_8.8/test/tags/caniuse.js","hash":"2852be850d9103c25114253a45e6c62e32517de4","modified":1638944857965},{"_id":"themes/next_8.8/test/tags/group-pictures.js","hash":"8f66d3c6f03fb11d85aa2ab05c9b3c9aa2b4e994","modified":1638944857966},{"_id":"themes/next_8.8/test/tags/index.js","hash":"5cad001936a694bf32d59751cc2b68a66199f976","modified":1638944857966},{"_id":"themes/next_8.8/test/tags/label.js","hash":"6cad7d84c42511459a89cda3971e8ea5cdee0125","modified":1638944857967},{"_id":"themes/next_8.8/test/tags/link-grid.js","hash":"41730266306c02362258384cd73659223928361f","modified":1638944857967},{"_id":"themes/next_8.8/test/tags/mermaid.js","hash":"f718a3d0e303d842e2ca5a3b162539a49e45a520","modified":1638944857967},{"_id":"themes/next_8.8/test/tags/note.js","hash":"161a81ce749e239d2403681372d48ecc1b51d7b9","modified":1638944857968},{"_id":"themes/next_8.8/test/tags/tabs.js","hash":"b19d2592347eae5d6a7a97ca7e8cec03e8f25b51","modified":1638944857968},{"_id":"themes/next_8.8/test/validate/index.js","hash":"560862194991c5963da5a411629d8e6c71d20ee2","modified":1638944857969},{"_id":"themes/next_8.8/test/tags/pdf.js","hash":"2d114596a8a180b2f3cd2a9c6528a328961f12d4","modified":1638944857968},{"_id":"themes/next_8.8/layout/_partials/head/head-unique.njk","hash":"bd87e3a877ebab4508fc2b48b41c96b45c4dd970","modified":1638944857869},{"_id":"themes/next_8.8/test/tags/video.js","hash":"88db9a3a26cd35525c43c0339fcd1c5965ec9518","modified":1638944857969},{"_id":"themes/next_8.8/layout/_partials/header/brand.njk","hash":"8e08c19e1bd92f3179907b0ff3743d6e2371d7ae","modified":1638944857869},{"_id":"themes/next_8.8/layout/_partials/head/head.njk","hash":"abcc550cb14374fb7452d6edee63967ad9583d1c","modified":1638944857869},{"_id":"themes/next_8.8/layout/_partials/header/index.njk","hash":"1b2ae17f3c394ce310fe2d9ed5f4d07d8cc74ae7","modified":1638944857870},{"_id":"themes/next_8.8/layout/_partials/header/menu.njk","hash":"67372599fe025ebe442b73151e5bb56415758356","modified":1638944857870},{"_id":"themes/next_8.8/layout/_partials/header/menu-item.njk","hash":"f066390762faf6684a523e2eb943420023aac2b1","modified":1638944857870},{"_id":"themes/next_8.8/layout/_partials/header/sub-menu.njk","hash":"940cad08a67e6c361214045096bd3cdffdf44fcf","modified":1638944857870},{"_id":"themes/next_8.8/layout/_partials/page/breadcrumb.njk","hash":"9c136edd2248e2d50c1f6110b75e2b75c299bbd7","modified":1638944857871},{"_id":"themes/next_8.8/layout/_partials/page/page-header.njk","hash":"92553feb26f30f7fc9147bc4ef122908a9da06be","modified":1638944857872},{"_id":"themes/next_8.8/layout/_partials/page/categories.njk","hash":"b352346dd2cb42f7eeaec5e39d9a2a353b029775","modified":1638944857872},{"_id":"themes/next_8.8/layout/_partials/page/schedule.njk","hash":"130e776575d634201d4f8ef3d78dc12624f19fde","modified":1638944857872},{"_id":"themes/next_8.8/layout/_partials/page/tags.njk","hash":"752df7d12360a077c51a25609916a3ecc1763bb3","modified":1638944857872},{"_id":"themes/next_8.8/layout/_partials/post/post-copyright.njk","hash":"0ebc0142abebbeef4278e32abb543c7d7fa75d88","modified":1638944857873},{"_id":"themes/next_8.8/layout/_partials/post/post-followme.njk","hash":"ebf83083856f8bd81ad47ffb985d44e338b4e6bb","modified":1638944857873},{"_id":"themes/next_8.8/layout/_partials/post/post-meta.njk","hash":"9a9c4fb7e7c4fe4b7d474bdfdb4ed2b0a5423df2","modified":1638944857874},{"_id":"themes/next_8.8/layout/_partials/post/post-footer.njk","hash":"e3502059bcc443ce932946a9891fcbe8b2bb362d","modified":1638944857874},{"_id":"themes/next_8.8/layout/_partials/post/post-related.njk","hash":"80d3dac42740d2aef677e25165e31c05eb048887","modified":1638944857875},{"_id":"themes/next_8.8/layout/_partials/post/post-reward.njk","hash":"58b3f657a47bae406e5fcf19cd5e42680785ac71","modified":1638944857875},{"_id":"themes/next_8.8/layout/_partials/search/algolia-search.njk","hash":"93fbb449fbd599cb4315d7eb0daeb239811b233f","modified":1638944857875},{"_id":"themes/next_8.8/layout/_partials/search/localsearch.njk","hash":"f73d25a8ccfdd5d4ca2953dc434ff8ce36034c57","modified":1638944857876},{"_id":"themes/next_8.8/layout/_partials/search/index.njk","hash":"9766852e72c1809d8c1eea71ac6116b4cc0886d2","modified":1638944857876},{"_id":"themes/next_8.8/layout/_partials/sidebar/site-overview.njk","hash":"c5c38b4fb137cc799a6ec31f391d1efc12234c8c","modified":1638944857876},{"_id":"themes/next_8.8/layout/_third-party/analytics/baidu-analytics.njk","hash":"3e80332f88b101141be69f2a07f54ed8c053eabb","modified":1638944857880},{"_id":"themes/next_8.8/layout/_third-party/analytics/cloudflare.njk","hash":"c7cea42f6db2137c11ca1d83e43fcb7ad7ccfb89","modified":1638944857881},{"_id":"themes/next_8.8/layout/_third-party/analytics/growingio.njk","hash":"9ff9ec05c2037beea229a6bb698f9e3546973220","modified":1638944857882},{"_id":"themes/next_8.8/layout/_third-party/analytics/google-analytics.njk","hash":"52ad137450f7b3d6a330e16b3ed1c6174290f0eb","modified":1638944857881},{"_id":"themes/next_8.8/layout/_third-party/analytics/index.njk","hash":"465fcffd4216f8ca0ea2613fe9cf7308f71b9da5","modified":1638944857882},{"_id":"themes/next_8.8/layout/_third-party/chat/chatra.njk","hash":"09d2c9487d75894d45a823e3237ae9f90fd6ee01","modified":1638944857882},{"_id":"themes/next_8.8/layout/_third-party/chat/gitter.njk","hash":"375a86f0b19e130cfa7707007e3a53d9ae7c9b64","modified":1638944857883},{"_id":"themes/next_8.8/layout/_third-party/chat/tidio.njk","hash":"3fbc72427c1211e5dcfd269af1a74852a7ba5c1a","modified":1638944857883},{"_id":"themes/next_8.8/layout/_third-party/comments/changyan.njk","hash":"5f7967bd946060f4102263a552ddfbae9975e7ea","modified":1638944857884},{"_id":"themes/next_8.8/layout/_third-party/comments/disqus.njk","hash":"b0828dd1b1fd66ecd612d9e886a08e7579e9a4f7","modified":1638944857884},{"_id":"themes/next_8.8/layout/_third-party/comments/disqusjs.njk","hash":"c5086b4c35f730f82c99c4a8317f2f153ebde869","modified":1638944857884},{"_id":"themes/next_8.8/layout/_third-party/comments/gitalk.njk","hash":"6fd4df5c21cfe530dbb0c012bc0b202f2c362b9c","modified":1638944857884},{"_id":"themes/next_8.8/layout/_third-party/comments/livere.njk","hash":"b8e0d5de584cece5e05b03db5b86145aa1e422b4","modified":1638944857885},{"_id":"themes/next_8.8/layout/_third-party/comments/isso.njk","hash":"38badcc7624a13961381c2465478056b9602aee5","modified":1638944857885},{"_id":"themes/next_8.8/layout/_third-party/comments/utterances.njk","hash":"a7921be7328e1509d33b435175f5333a9aada66f","modified":1638944857888},{"_id":"themes/next_8.8/layout/_third-party/math/index.njk","hash":"1856c4b035c5b8e64300a11af0461b519dfc4cf4","modified":1638944857889},{"_id":"themes/next_8.8/layout/_third-party/math/katex.njk","hash":"a84db8bc8804335f95609a221ac1746433dcdc89","modified":1638944857889},{"_id":"themes/next_8.8/layout/_third-party/math/mathjax.njk","hash":"a62aa1ed4e35b8d0451d83f341bf0a97538bc9a4","modified":1638944857890},{"_id":"themes/next_8.8/layout/_third-party/search/algolia-search.njk","hash":"67f67a77f27103177b9940446f43610229536d82","modified":1638944857891},{"_id":"themes/next_8.8/layout/_third-party/search/localsearch.njk","hash":"210c32b654adae3d8076c4417d370b42af258cea","modified":1638944857891},{"_id":"themes/next_8.8/layout/_third-party/statistics/busuanzi-counter.njk","hash":"d97790e4b442a1e3ded7d7b4f84b8ee6cdb6e8ea","modified":1638944857892},{"_id":"themes/next_8.8/layout/_third-party/statistics/firestore.njk","hash":"af5336e8bbdc4638435971da115bb7443d374ade","modified":1638944857892},{"_id":"themes/next_8.8/layout/_third-party/statistics/index.njk","hash":"866ffa15a3250678eb8a90aa6f609fa965db90fd","modified":1638944857895},{"_id":"themes/next_8.8/layout/_third-party/statistics/lean-analytics.njk","hash":"8703d1855bb8d251c9b7c2940b7e3be525e53000","modified":1638944857895},{"_id":"themes/next_8.8/layout/_third-party/tags/mermaid.njk","hash":"dd8f963acd5a3685be46fd5319c06df0308d99b2","modified":1638944857896},{"_id":"themes/next_8.8/layout/_third-party/tags/pdf.njk","hash":"0386c708975cc5faea4f782611c5d2c6b8ac2850","modified":1638944857897},{"_id":"themes/next_8.8/scripts/events/lib/config.js","hash":"a912944cae0d864458d365867b8a9c89f348e68a","modified":1638944857900},{"_id":"themes/next_8.8/scripts/events/lib/highlight.js","hash":"00cec6980cafd417def885f496371856cd524a25","modified":1638944857901},{"_id":"themes/next_8.8/scripts/events/lib/injects.js","hash":"1f1ea7b579a49f17574c31d78d663c54896133eb","modified":1638944857901},{"_id":"themes/next_8.8/scripts/events/lib/utils.js","hash":"8508e96a5f883a5a57d8c1b8b5ea438fa29aafd3","modified":1638944857901},{"_id":"themes/next_8.8/scripts/events/lib/vendors.js","hash":"2f7057a8d3fce08aa7e2a17d7b7a1f03ac3d8ed6","modified":1638944857902},{"_id":"themes/next_8.8/scripts/filters/comment/changyan.js","hash":"cfff8331fdaa2ede4ab08c58cfc6d98c7d2374d9","modified":1638944857902},{"_id":"themes/next_8.8/scripts/filters/comment/common.js","hash":"713056d33dbcd8e9748205c5680b456c21174f4e","modified":1638944857903},{"_id":"themes/next_8.8/scripts/filters/comment/default-config.js","hash":"1cb58aa6b88f7461c3c3f9605273686adcc30979","modified":1638944857903},{"_id":"themes/next_8.8/scripts/filters/comment/disqus.js","hash":"3283bdd6e5ac7d10376df8ddd5faaec5dc1bd667","modified":1638944857903},{"_id":"themes/next_8.8/scripts/filters/comment/gitalk.js","hash":"96e58efba0dc76af409cc7d2db225f0fe4526ea8","modified":1638944857904},{"_id":"themes/next_8.8/scripts/filters/comment/isso.js","hash":"c22cbccd7d514947e084eeac6a3af1aa41ec857a","modified":1638944857904},{"_id":"themes/next_8.8/scripts/filters/comment/disqusjs.js","hash":"70eb507ef7f1a4fc3ca71a3814cc57afe7f3f60c","modified":1638944857903},{"_id":"themes/next_8.8/scripts/filters/comment/livere.js","hash":"bb8ebb541c40362c0cbbd8e83d3b777302bb6c40","modified":1638944857904},{"_id":"themes/next_8.8/scripts/filters/comment/utterances.js","hash":"a50718c081685fd35ff8ea9ca13682c284399ed8","modified":1638944857905},{"_id":"themes/next_8.8/source/css/_variables/Gemini.styl","hash":"c4537fa2de33d98baff2c87a73801770414e0b69","modified":1638944857946},{"_id":"themes/next_8.8/source/css/_variables/Mist.styl","hash":"ee5024be8e39605f0c6d71db038e15e0693d0f41","modified":1638944857946},{"_id":"themes/next_8.8/source/css/_variables/Muse.styl","hash":"d3a8f6e71c86926d0c2a247a31d7446d829736d5","modified":1638944857946},{"_id":"themes/next_8.8/source/css/_variables/Pisces.styl","hash":"58014a2d087c4126058a99b5b1cb7d8a2eb6224d","modified":1638944857947},{"_id":"themes/next_8.8/source/css/_variables/base.styl","hash":"0876b50a58f114bc0b7982b85c5e5011730253b8","modified":1638944857947},{"_id":"themes/next_8.8/source/js/schemes/muse.js","hash":"e1b4bf9aa47d14c790a0920d7dbb3e9812d4358b","modified":1638944857953},{"_id":"themes/next_8.8/source/js/third-party/fancybox.js","hash":"8a847a7bbdbc0086dd1de12b82107a854b43f5e5","modified":1638944857958},{"_id":"themes/next_8.8/source/js/third-party/pace.js","hash":"0ebee77b2307bf4b260afb06c060171ef42b7141","modified":1638944857959},{"_id":"themes/next_8.8/source/js/third-party/quicklink.js","hash":"539c5bb51244f7f4aa98884f3229d128c1cefc40","modified":1638944857960},{"_id":"themes/next_8.8/source/js/third-party/rating.js","hash":"a1f44247c18ac00ee3e0026560398429e4c77dd7","modified":1638944857960},{"_id":"themes/next_8.8/source/css/_common/scaffolding/base.styl","hash":"e2da25ff86d2be5ff0a0cee33c7d4c5e11046736","modified":1639712427384},{"_id":"themes/next_8.8/source/css/_common/scaffolding/base.styl_backup","hash":"1239f1b432a6932b2bb9ebcfbaabf724b8f4e59a","modified":1639711097302},{"_id":"themes/next_8.8/source/css/_common/scaffolding/buttons.styl","hash":"f768ecb2fe3e9384777c1c115cd7409e9155edd7","modified":1638944857932},{"_id":"themes/next_8.8/source/css/_common/scaffolding/comments.styl","hash":"cf8446f4378dcab27b55ede1635c608ae6b8a5c8","modified":1638944857932},{"_id":"themes/next_8.8/source/css/_common/scaffolding/index.styl","hash":"43045d115f8fe95732c446aa45bf1c97609ff2a5","modified":1638944857933},{"_id":"themes/next_8.8/source/css/_common/scaffolding/normalize.styl","hash":"6d740699fb6a7640647a8fd77c4ea4992d8d6437","modified":1638944857933},{"_id":"themes/next_8.8/source/css/_common/scaffolding/pagination.styl","hash":"34416a5792d0235caa8c0c7e59725f2df0fa614c","modified":1638944857934},{"_id":"themes/next_8.8/source/css/_common/scaffolding/tables.styl","hash":"b9388016f8d9274703e77e306a1feaad1b7b9d6c","modified":1638944857934},{"_id":"themes/next_8.8/source/css/_common/scaffolding/toggles.styl","hash":"90f7d3baab061e860172b536c9edc38c7fd2ef5c","modified":1638944857938},{"_id":"themes/next_8.8/source/css/_common/components/back-to-top.styl","hash":"2bbf9046ef2a8f99ef3668bbb8be4e52e9d97bb7","modified":1638944857913},{"_id":"themes/next_8.8/source/css/_common/components/index.styl","hash":"991c1f80995cec418dc00d3d6b13e2d911ac9894","modified":1638944857913},{"_id":"themes/next_8.8/source/css/_common/components/reading-progress.styl","hash":"f3defd56be33dba4866a695396d96c767ce63182","modified":1638944857920},{"_id":"themes/next_8.8/source/css/_common/outline/index.styl","hash":"7782dfae7a0f8cd61b936fa8ac980440a7bbd3bb","modified":1638944857927},{"_id":"themes/next_8.8/source/css/_common/outline/mobile.styl","hash":"2db4462e9cb87b8aef3f50f850fed407de16da3e","modified":1638944857927},{"_id":"themes/next_8.8/source/css/_schemes/Gemini/index.styl","hash":"f51b6a4f06359ed56b2d10caa6f15362d3b3751d","modified":1638944857939},{"_id":"themes/next_8.8/source/css/_schemes/Mist/_header.styl","hash":"b1054313ca9419e76fea0451417c881616f50a38","modified":1638944857939},{"_id":"themes/next_8.8/source/css/_schemes/Mist/_menu.styl","hash":"f337981f8f20944ed366694aea88146c7b0a13ab","modified":1638944857940},{"_id":"themes/next_8.8/source/css/_schemes/Mist/_layout.styl","hash":"00366a6bd1a66f99f845c5ebfc9e8cf56651b815","modified":1638944857939},{"_id":"themes/next_8.8/source/css/_schemes/Mist/index.styl","hash":"89bf3f6b82cb0fafbbd483431df8f450857c5a0b","modified":1638944857941},{"_id":"themes/next_8.8/source/css/_schemes/Mist/_posts-expand.styl","hash":"c9a9e07b721bb2376e24753ae0a9452431439114","modified":1638944857941},{"_id":"themes/next_8.8/source/css/_schemes/Pisces/_header.styl","hash":"9b2cba0c9aa5a64957294f7548c199db1f63f0f4","modified":1638944857943},{"_id":"themes/next_8.8/source/css/_schemes/Pisces/_layout.styl","hash":"9f60d501808f67d151af437221d0dfacc27c180c","modified":1638944857944},{"_id":"themes/next_8.8/source/css/_schemes/Pisces/_menu.styl","hash":"1d29eca70fa686d895f8e98a283e4a159e40905a","modified":1638944857944},{"_id":"themes/next_8.8/source/css/_schemes/Pisces/_sidebar.styl","hash":"42bf453def88da82c842dca84e8f47087091f08e","modified":1638944857944},{"_id":"themes/next_8.8/source/css/_schemes/Pisces/index.styl","hash":"7905f428b46d100ac5928875cb1e2b99fa86fc0b","modified":1638944857945},{"_id":"themes/next_8.8/source/css/_schemes/Pisces/_sub-menu.styl","hash":"b5c3dd08c520a16ee49f85fa12b4935e725ef261","modified":1638944857945},{"_id":"themes/next_8.8/source/css/_schemes/Muse/_header.styl","hash":"fd89988442f380cba907752fe3f608e3498f8c93","modified":1638944857941},{"_id":"themes/next_8.8/source/css/_schemes/Muse/_menu.styl","hash":"28030c61288cc0e1321b18373a5c79029fd76a53","modified":1638944857942},{"_id":"themes/next_8.8/source/css/_schemes/Muse/_layout.styl","hash":"018b6a761e197086174c9f06b4d5ea21cc230951","modified":1638944857941},{"_id":"themes/next_8.8/source/css/_schemes/Muse/_sidebar.styl","hash":"134272cb8096156c9e32fbbe085394633c7509cd","modified":1638944857942},{"_id":"themes/next_8.8/source/css/_schemes/Muse/index.styl","hash":"25c2a7930da14f023329df20f38df2728057fb4d","modified":1638944857943},{"_id":"themes/next_8.8/source/css/_schemes/Muse/_sub-menu.styl","hash":"2d3e05015796a790abd9d68957a5c698c0c9f9b6","modified":1638944857943},{"_id":"themes/next_8.8/source/js/third-party/analytics/baidu-analytics.js","hash":"f9579a02599de063ccff336177ba964a2931a6e9","modified":1638944857954},{"_id":"themes/next_8.8/source/js/third-party/analytics/growingio.js","hash":"f755e8537ccbbb0bd84c26923f320d4e206e7428","modified":1638944857954},{"_id":"themes/next_8.8/source/js/third-party/analytics/google-analytics.js","hash":"d77d4934d959e7125128754b568f1d041c3fbfff","modified":1638944857954},{"_id":"themes/next_8.8/source/js/third-party/chat/chatra.js","hash":"72e0766752b78a723fb30e92d533a8b353104e2d","modified":1638944857955},{"_id":"themes/next_8.8/source/js/third-party/chat/gitter.js","hash":"14b024c920a8b359777d79dd8e1a849387f8f3ad","modified":1638944857955},{"_id":"themes/next_8.8/source/js/third-party/chat/tidio.js","hash":"77c231bcd64f1c09bd9989909e9fee703b65f47f","modified":1638944857955},{"_id":"themes/next_8.8/source/js/third-party/comments/changyan.js","hash":"b1dd519dc3b1153c9d2ba2d35f68ca8f73f33bae","modified":1638944857956},{"_id":"themes/next_8.8/source/js/third-party/comments/disqusjs.js","hash":"1c282d6c2151346d1f0aa95055d17abe77054ec9","modified":1638944857957},{"_id":"themes/next_8.8/source/js/third-party/comments/disqus.js","hash":"5460de247c038d6cfbe774d7f8747f0a958d9017","modified":1638944857956},{"_id":"themes/next_8.8/source/js/third-party/comments/gitalk.js","hash":"1e8509356fb027d948d118ab220d9631f4d482fa","modified":1638944857957},{"_id":"themes/next_8.8/source/js/third-party/comments/isso.js","hash":"b9b9fd2f0e098a123b34a4932da912a9485ffe6c","modified":1638944857957},{"_id":"themes/next_8.8/source/js/third-party/comments/livere.js","hash":"68892d74ef5fc308c6e7e6b4f190826d79f3055d","modified":1638944857957},{"_id":"themes/next_8.8/source/js/third-party/comments/utterances.js","hash":"ec44d7f1c8b51b0aa3cccba099a78f3575ac828c","modified":1638944857958},{"_id":"themes/next_8.8/source/js/third-party/math/katex.js","hash":"5c63ec71458b4fe0cd98fd4a04e11c3746764f11","modified":1638944857959},{"_id":"themes/next_8.8/source/js/third-party/math/mathjax.js","hash":"d93556184b2c0aa1dbc4a6fb892d2f77b80d7d9f","modified":1638944857959},{"_id":"themes/next_8.8/source/js/third-party/statistics/firestore.js","hash":"d0829fe41d2fe86b8499e2a896556c1275ea0066","modified":1638944857961},{"_id":"themes/next_8.8/source/js/third-party/statistics/lean-analytics.js","hash":"6abdc209f4503d4efd676e18bc30ddea813b6ff9","modified":1638944857961},{"_id":"themes/next_8.8/source/js/third-party/search/algolia-search.js","hash":"ea94731438d8c518d946601f8f46a65b92381fac","modified":1638944857960},{"_id":"themes/next_8.8/source/js/third-party/search/local-search.js","hash":"dc2b0e89aa32afc7f7a7e2d7a277dadb7f96e06d","modified":1638944857961},{"_id":"themes/next_8.8/source/js/third-party/tags/mermaid.js","hash":"2618135cbcee6bf228f6734767de1995e5eaaac6","modified":1638944857962},{"_id":"themes/next_8.8/source/js/third-party/tags/pdf.js","hash":"e109c2d6828f527f0289d5fa3bb02fce63ee6d93","modified":1638944857962},{"_id":"themes/next_8.8/source/css/_common/scaffolding/highlight/index.styl","hash":"5f706f3382652835379cf9b9fec24ccd4513ab65","modified":1638944857933},{"_id":"themes/next_8.8/source/css/_common/scaffolding/highlight/copy-code.styl","hash":"a4003e1408844568cb5102a5a111046cb19b2d31","modified":1638944857933},{"_id":"themes/next_8.8/source/css/_common/scaffolding/tags/index.styl","hash":"e22fde6f1657d311d46f64d868c4491d535c8caa","modified":1638944857935},{"_id":"themes/next_8.8/source/css/_common/scaffolding/tags/label.styl","hash":"531daf2612c6217950677a2d03924459ce57c291","modified":1638944857936},{"_id":"themes/next_8.8/source/css/_common/scaffolding/tags/group-pictures.styl","hash":"8d9218980e185210ce034e9769ab639b9630fd88","modified":1638944857935},{"_id":"themes/next_8.8/source/css/_common/scaffolding/tags/blockquote-center.styl","hash":"6b3680e0dbea8e14c1cec24ef63b7fae5e37f7ef","modified":1638944857935},{"_id":"themes/next_8.8/source/css/_common/scaffolding/tags/mermaid.styl","hash":"c7754dc6c866928b538f0863a05b96ec44b5e986","modified":1638944857936},{"_id":"themes/next_8.8/source/css/_common/scaffolding/tags/link-grid.styl","hash":"7075dd32dd70da1e161e4bd14b46f1e8be62fa3c","modified":1638944857936},{"_id":"themes/next_8.8/source/css/_common/scaffolding/tags/note.styl","hash":"2e9dc3b3546e19e9de18050ad04b1741841116bc","modified":1638944857937},{"_id":"themes/next_8.8/source/css/_common/scaffolding/tags/tabs.styl","hash":"40a38f2129617ffd4e8d5cd78e982fdfc9941acf","modified":1638944857937},{"_id":"themes/next_8.8/source/css/_common/components/pages/breadcrumb.styl","hash":"fde10ce94e9ae21a03b60d41d532835b54abdcb1","modified":1638944857914},{"_id":"themes/next_8.8/source/css/_common/scaffolding/tags/pdf.styl","hash":"77122986509a6b4968bae2729417b7016137534c","modified":1638944857937},{"_id":"themes/next_8.8/source/css/_common/components/pages/categories.styl","hash":"80595d274f593b321c0b644a06f3165fe07b16f5","modified":1638944857914},{"_id":"themes/next_8.8/source/css/_common/components/pages/index.styl","hash":"6cf78a379bb656cc0abb4ab80fcae60152ce41ad","modified":1638944857915},{"_id":"themes/next_8.8/source/css/_common/components/pages/schedule.styl","hash":"091b8c763e43447d087c122a86538f290f83136a","modified":1638944857915},{"_id":"themes/next_8.8/source/css/_common/components/pages/tag-cloud.styl","hash":"56d719bcdcba3d725141c55bbd4b168f3942f912","modified":1638944857916},{"_id":"themes/next_8.8/source/css/_common/components/post/index.styl","hash":"df2fbd0ada00f37439b0de965c6f1c29d3c97429","modified":1638944857916},{"_id":"themes/next_8.8/source/css/_common/components/post/post-body.styl","hash":"7a34d020877273dcf11c25fa481409300efb8659","modified":1638944857917},{"_id":"themes/next_8.8/source/css/_common/components/post/post-collapse.styl","hash":"eebe3013a9a976011570dce2d04dfeae4c31d790","modified":1638944857917},{"_id":"themes/next_8.8/source/css/_common/components/post/post-followme.styl","hash":"791bc9befb0d4d06e3e517eccfe0bc3551a02a60","modified":1638944857917},{"_id":"themes/next_8.8/source/css/_common/components/post/post-header.styl","hash":"4d29b6ae7ed3dc44b10df851a4128b6441efa8be","modified":1638944857918},{"_id":"themes/next_8.8/source/css/_common/components/post/post-nav.styl","hash":"69dff7cf231d01f85671758455726dd666664a73","modified":1638944857918},{"_id":"themes/next_8.8/source/css/_common/components/post/post-footer.styl","hash":"e53a5eb1d1771e284044bdb0bc0ed2de27923669","modified":1638944857918},{"_id":"themes/next_8.8/source/css/_common/components/post/post-gallery.styl","hash":"c34936a17c3d8af6c0988ac6746d7509dc0b50eb","modified":1638944857918},{"_id":"themes/next_8.8/source/css/_common/components/post/post-reward.styl","hash":"9043d9bc2db35ca000c79258ef89fdb161dc43fb","modified":1638944857919},{"_id":"themes/next_8.8/source/css/_common/components/post/post-widgets.styl","hash":"0a779f955a0e25df0852e0731517dadb234aa181","modified":1638944857919},{"_id":"themes/next_8.8/source/css/_common/components/third-party/disqusjs.styl","hash":"c1e9edbfd1c3696b35d5452ae2e6d766f3fe91aa","modified":1638944857920},{"_id":"themes/next_8.8/source/css/_common/components/third-party/index.styl","hash":"25ea9a0af888355b3a046db1100b5cb0e2d6ef6e","modified":1638944857921},{"_id":"themes/next_8.8/source/css/_common/components/third-party/gitalk.styl","hash":"fb165c1a0d990c5cf98b87773e0dc50410229b96","modified":1638944857920},{"_id":"themes/next_8.8/source/css/_common/components/third-party/math.styl","hash":"1e5776ad4c5c8bcf7596ac74dcabc30704b3f5a0","modified":1638944857921},{"_id":"themes/next_8.8/source/css/_common/components/third-party/search.styl","hash":"49c26184580fde8a732899a4de5aae8662e289b8","modified":1638944857922},{"_id":"themes/next_8.8/source/css/_common/components/third-party/related-posts.styl","hash":"0527153aa821bdbdb84c7b47f60e3cefd95a742f","modified":1638944857921},{"_id":"themes/next_8.8/source/css/_common/components/third-party/utterances.styl","hash":"d28856f365a9373c4ae6fe1e5673d63df2dfd65f","modified":1638944857922},{"_id":"themes/next_8.8/source/css/_common/outline/footer/index.styl","hash":"02b6d1a53f7a02c6b0929b11f3ab904b5b873a0e","modified":1638944857923},{"_id":"themes/next_8.8/source/css/_common/outline/header/bookmark.styl","hash":"c8648c8ea3105556be0068d9fb2735261d0d94bc","modified":1638944857923},{"_id":"themes/next_8.8/source/css/_common/outline/header/github-banner.styl","hash":"05af22f3edc2383a3d97ec4c05e9ac43b014bead","modified":1638944857924},{"_id":"themes/next_8.8/source/css/_common/outline/header/menu.styl","hash":"2db695204d39e4c7daa7b91585a0ea4b06b49f11","modified":1638944857926},{"_id":"themes/next_8.8/source/css/_common/outline/header/index.styl","hash":"67fc7a1eb59c8451eec34e572cbb2fd1424757bc","modified":1638944857924},{"_id":"themes/next_8.8/source/css/_common/outline/header/site-nav.styl","hash":"d9bc2b520636b9df7f946295cd430593df4118ff","modified":1638944857926},{"_id":"themes/next_8.8/source/css/_common/outline/header/site-meta.styl","hash":"86b0925e968f35bbc76b473a861e8f9797f7580e","modified":1638944857926},{"_id":"themes/next_8.8/source/css/_common/outline/sidebar/index.styl","hash":"9964a96f9a647cfb16b97679eced79d07e084e6d","modified":1638944857928},{"_id":"themes/next_8.8/source/css/_common/outline/sidebar/sidebar-author-links.styl","hash":"2c2bfbc34b6f19d262ae7c041474985e12f4f4ad","modified":1638944857928},{"_id":"themes/next_8.8/source/css/_common/outline/sidebar/sidebar-author.styl","hash":"d8a028f532d562e6a86bb3b9c7b992e4b6dbbb51","modified":1638944857929},{"_id":"themes/next_8.8/source/css/_common/outline/sidebar/sidebar-button.styl","hash":"63d8f5f169c2b1c969928fc79244c5fe89ee484e","modified":1638944857929},{"_id":"themes/next_8.8/source/css/_common/outline/sidebar/sidebar-toc.styl","hash":"081345490271840855d1238b969dbf2e0a2bba8f","modified":1638944857930},{"_id":"themes/next_8.8/source/css/_common/outline/sidebar/sidebar-blogroll.styl","hash":"1c324d56ae83e96db2c4c6d63edd7ee51c936fc1","modified":1638944857929},{"_id":"themes/next_8.8/source/css/_common/outline/sidebar/sidebar-dimmer.styl","hash":"57ed6770535ecb2e6485a0c87d4de6d6476368b9","modified":1638944857929},{"_id":"themes/next_8.8/source/css/_common/outline/sidebar/sidebar-nav.styl","hash":"db4f3263b2b6551dd56bfdf33cceaf81661a3611","modified":1638944857930},{"_id":"themes/next_8.8/source/css/_common/outline/sidebar/sidebar-toggle.styl","hash":"6681ffe283f8a7e3c86310ef4f6ca1e499c1a19f","modified":1638944857930},{"_id":"themes/next_8.8/source/css/_common/outline/sidebar/site-state.styl","hash":"2de038def2cb91da143b14696366c14a66e0e569","modified":1638944857931},{"_id":"public/sitemap.xml","hash":"e0488c78714df33dd82857a915c22ef904eb2d0b","modified":1639712733495},{"_id":"public/about/index.html","hash":"fbf5b189795f3d7f36a3d0c98316a4754cde1c2b","modified":1639712866490},{"_id":"public/categories/index.html","hash":"7ed2c560b99c819702c31755b805ccd21256d3c2","modified":1639712435789},{"_id":"public/tags/index.html","hash":"7b115af52739390b672e4c2bd45030c48a12a1c3","modified":1639712435789},{"_id":"public/2021/12/17/Experiments/index.html","hash":"9c58cdb839f61e27f094dd2a9e6b21188686c26a","modified":1639712435789},{"_id":"public/2021/12/10/An-Introduction-to-Git/index.html","hash":"eb33b8f843497e52977f03c637b8720f62902b37","modified":1639712435789},{"_id":"public/archives/index.html","hash":"02f76f6a9edf37e0f5e082467b2be4003065e32e","modified":1639712435789},{"_id":"public/archives/2021/index.html","hash":"5a3562429aa2ca6edfc9463842aec699abd2a601","modified":1639712435789},{"_id":"public/archives/2021/11/index.html","hash":"36c599b8319e0ea58b29b62acae60166f890f613","modified":1639712435789},{"_id":"public/archives/2021/12/index.html","hash":"d6654b442c429bfc68199722a718b6a39c7bdbfb","modified":1639712435789},{"_id":"public/categories/Little-Things/index.html","hash":"65472368d0b87f50d47c4eef12b4bbce3b8925cf","modified":1639712435789},{"_id":"public/categories/Experiments/index.html","hash":"3ed4d3876158fb626cbd9af8b8aeac81c83b316c","modified":1639712435789},{"_id":"public/categories/About-Papers/index.html","hash":"d737a34ecafdd53bb8d356742c4e647a5c9b5b0b","modified":1639712435789},{"_id":"public/categories/Little-Things/Git/index.html","hash":"73e567dd09fdd0f2e247177ed12a11821f2514a3","modified":1639712435789},{"_id":"public/categories/Reinforcement-Learning/index.html","hash":"166df330b88708c2ffd8b95170d86244e03e3fac","modified":1639712435789},{"_id":"public/categories/Little-Things/Hexo/index.html","hash":"a0abc457037681c2797759a91fefd383be00b7b0","modified":1639712435789},{"_id":"public/tags/Git/index.html","hash":"f9a5d7ae86cb83e7cd463112ccfe3f5628250570","modified":1639712435789},{"_id":"public/tags/Hexo/index.html","hash":"65235bb85302805e6d9372e2c29cf8613a19c849","modified":1639712435789},{"_id":"public/tags/Experiments/index.html","hash":"0218b3b4c23151e73244e908c48e1640c5f2ef2b","modified":1639712435789},{"_id":"public/tags/Personal-Thought/index.html","hash":"6aca4678c7cb5de923358e1091baafc9dc330f03","modified":1639712435789},{"_id":"public/tags/private/index.html","hash":"f8303f88ebf9603fec0fdf7632f29867c31bf137","modified":1639712435789},{"_id":"public/tags/Papers/index.html","hash":"f974e65a9815dec9ffed65f7ebd60a41bfabeb37","modified":1639712435789},{"_id":"public/tags/Reinforcement-Learning/index.html","hash":"8f8a36a20bf2a7fc702d047873512724d51bab0d","modified":1639712435789},{"_id":"public/2021/12/15/Personal-Thought/index.html","hash":"f76abdf9b50972bfc4622146632694bf19448582","modified":1639712435789},{"_id":"public/2021/12/14/Tips-in-Papers/index.html","hash":"dabb15aa9af7d4567b4f71204b93943f3496c752","modified":1639712435789},{"_id":"public/2021/12/03/First-Step-to-RL/index.html","hash":"3ecc96bbafa86bc708773ed3f0ee348e22fadbe7","modified":1639712435789},{"_id":"public/2021/11/24/Construct-Your-Blog-with-Hexo-and-Github/index.html","hash":"f79560b6e444162ac0c0eea05f0f3c00a5488e1b","modified":1639712435789},{"_id":"public/index.html","hash":"ed9cba6e243ef6be878a822b4ba8ea0edb61158a","modified":1639712435789},{"_id":"public/images/avatar.gif","hash":"2dbc3e2f2d624b2ca1afe6edc2ca17307f1950c8","modified":1639712435789},{"_id":"public/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1639712435789},{"_id":"public/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1639712435789},{"_id":"public/images/logo-algolia-nebula-blue-full.svg","hash":"b85e274207b1392782476a0430feac98db1e7da0","modified":1639712435789},{"_id":"public/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1639712435789},{"_id":"public/images/logo.svg","hash":"2cb74fd3ea2635e015eabc58a8d488aed6cf6417","modified":1639712435789},{"_id":"public/images/ye_16.ico","hash":"b8fb01b5361da89831d232a831a1532e9822bd72","modified":1639712435789},{"_id":"public/images/ye_32.ico","hash":"375c99cd785d93dd989c36604ffbd10ada71322a","modified":1639712435789},{"_id":"public/2021/12/03/First-Step-to-RL/policy_network.py","hash":"b3e8f06360cad0084a0656edaed4539f1b01e327","modified":1639712435789},{"_id":"public/2021/12/03/First-Step-to-RL/q_learning.py","hash":"3a68ec1153d26f2c18c9d34ee5deb5e495b8dca9","modified":1639712435789},{"_id":"public/2021/12/14/Tips-in-Papers/ADCM.jpg","hash":"ee5b75f3a063e07624c5f03111f98902d885cd8e","modified":1639712435789},{"_id":"public/css/hbe.style.css","hash":"b0a0077cb588c0941823905fcc383aa7509ade73","modified":1639712435789},{"_id":"public/lib/hbe.js","hash":"136dba00826bdd086153bf0acb5473aea7183ad1","modified":1639712435789},{"_id":"public/js/bookmark.js","hash":"0f563ffbf05fad30e854e413ab17ff7164ab5a53","modified":1639712435789},{"_id":"public/css/noscript.css","hash":"54d14cd43dc297950a4a8d39ec9644dd5fc3499f","modified":1639712435789},{"_id":"public/js/config.js","hash":"4c4ebbe3b3f3841a26f9d5af6d0ba8bc6da01c54","modified":1639712435789},{"_id":"public/js/comments.js","hash":"66ae2e26ea36a41b72c638ea8b220296638ae952","modified":1639712435789},{"_id":"public/js/motion.js","hash":"6d4bd07a6f8e1b4083119dca0acb5b289533b619","modified":1639712435789},{"_id":"public/js/pjax.js","hash":"919f5281c4a04d11cfd94573ecf57b3dbabd3cc8","modified":1639712435789},{"_id":"public/js/comments-buttons.js","hash":"1a7344440321713426a0b2ab17e276b5bdf85ade","modified":1639712435789},{"_id":"public/js/next-boot.js","hash":"48497e2156a10155dc42311633a110c9685692c9","modified":1639712435789},{"_id":"public/js/schedule.js","hash":"2b43e2d576a308289880befc27580dbb2aa34439","modified":1639712435789},{"_id":"public/js/schemes/muse.js","hash":"9a836d2bcc3defe4bd1ee51f5f4eb7006ebdd41b","modified":1639712435789},{"_id":"public/js/third-party/pace.js","hash":"0ef04218b93561ba4d0ff420d556c3d90a756d32","modified":1639712435789},{"_id":"public/js/third-party/fancybox.js","hash":"c098d14e65dd170537134358d4b8359ad0539c2c","modified":1639712435789},{"_id":"public/js/utils.js","hash":"e447160d342b1f93df5214b6a733441039ced439","modified":1639712435789},{"_id":"public/css/main.css","hash":"a11ba827a33ddb3529cc9d6ab60b000b66656094","modified":1639712435789},{"_id":"public/js/third-party/quicklink.js","hash":"6f58cd7aa8f6f1ab92d5a96551add293f4e55312","modified":1639712435789},{"_id":"public/js/third-party/rating.js","hash":"4e92c2d107ba47b47826829f9668030d5ea9bfb8","modified":1639712435789},{"_id":"public/js/third-party/analytics/baidu-analytics.js","hash":"f629acc46ff40c071ffd31b77d5c7616f0fdd778","modified":1639712435789},{"_id":"public/js/third-party/analytics/google-analytics.js","hash":"59684383385059dc4f8a1ff85dbbeb703bcdbcb5","modified":1639712435789},{"_id":"public/js/third-party/analytics/growingio.js","hash":"78dd3cf04082b7dbe6246e404b2aa8e726922402","modified":1639712435789},{"_id":"public/js/third-party/chat/chatra.js","hash":"c32180522788c10e51df1803aa6842ef0432ddc9","modified":1639712435789},{"_id":"public/js/third-party/chat/tidio.js","hash":"b0079f6a4601e06ca6fe46e83a2f5af553e9bc3c","modified":1639712435789},{"_id":"public/js/third-party/comments/changyan.js","hash":"8c8ebec444c727b704ea41ad88b0b96ed2e4b8d4","modified":1639712435789},{"_id":"public/js/third-party/chat/gitter.js","hash":"cc38c94125f90dadde11b5ebac7d8bf99a1a08a2","modified":1639712435789},{"_id":"public/js/third-party/comments/disqusjs.js","hash":"b6c58f098473b526d6a3cd35655caf34b77f7cff","modified":1639712435789},{"_id":"public/js/third-party/comments/isso.js","hash":"753a873b6f566aff5ba77ca23f91b78eb880ca64","modified":1639712435789},{"_id":"public/js/third-party/comments/disqus.js","hash":"e1cc671b0d524864fd445e3ab4ade9ee6d07e565","modified":1639712435789},{"_id":"public/js/third-party/comments/utterances.js","hash":"f67f90eb03e284c82da2b8cf2f1e31801813c16d","modified":1639712435789},{"_id":"public/js/third-party/comments/livere.js","hash":"2247d88c934c765c43013337860774aaa99f0b31","modified":1639712435789},{"_id":"public/js/third-party/comments/gitalk.js","hash":"0ec038cf83e8ec067534f16a54041e47a3c1e59a","modified":1639712435789},{"_id":"public/js/third-party/math/katex.js","hash":"83c54ee536e487a1031783443fe0cb63b1b4767e","modified":1639712435789},{"_id":"public/js/third-party/statistics/firestore.js","hash":"0960f16107ed61452fb0dffc6ed22dc143de34ef","modified":1639712435789},{"_id":"public/js/third-party/math/mathjax.js","hash":"5c749b9c1c3bb738122d0516211ecff6496d4907","modified":1639712435789},{"_id":"public/js/third-party/search/algolia-search.js","hash":"ac401e3736d56a3c9cb85ab885744cce0b813c55","modified":1639712435789},{"_id":"public/js/third-party/statistics/lean-analytics.js","hash":"5a928990856b8e456f0663cf3b6b406733672e39","modified":1639712435789},{"_id":"public/js/third-party/search/local-search.js","hash":"45c485f82258d246f37deb66884bd2643323ef3a","modified":1639712435789},{"_id":"public/js/third-party/tags/pdf.js","hash":"af78c22f0e61c8c8aa8794e585e0d632c6d4fcb8","modified":1639712435789},{"_id":"public/js/third-party/tags/mermaid.js","hash":"3dc4628efa6debd6490fc0ebddff2424a7b319d8","modified":1639712435789},{"_id":"public/2021/12/10/An-Introduction-to-Git/git.jpg","hash":"db9ed8bb86df7e73d5be3bcae4cc8656e4a7a0ed","modified":1639712435789}],"Category":[{"name":"Little Things","_id":"ckx9ug5460004s4ul3b8the3i"},{"name":"Experiments","_id":"ckx9ug54c000es4ulfnopgd96"},{"name":"About Papers","_id":"ckx9ug54d000hs4ul6oem5esz"},{"name":"Git","parent":"ckx9ug5460004s4ul3b8the3i","_id":"ckx9ug54e000ks4ul3dfcbxn3"},{"name":"Reinforcement Learning","_id":"ckx9ug54f000ps4ul6agz06ki"},{"name":"Hexo","parent":"ckx9ug5460004s4ul3b8the3i","_id":"ckx9ug54g000vs4ul9s3vgmfs"}],"Data":[],"Page":[{"title":"about","date":"2021-12-12T13:52:49.000Z","_content":"\n\n\nI received the B.S. degree in the School of Engineering and Technology, China University of Geosciences (Beijing) in 2015. I am currently working towards the Ph.D degree in the Beijing Key Laboratory of Work Safety Intelligent Monitoring, the Department of EE, BUPT.\n\nI major in deep learning, computer vision, natural language processing, and reinforcement learning.\n\nI am also interested in high performance computing.\n\n<br/>\n\n<br/>\n\n---\n\n<br/>\n\n<br/>\n\n>      *There is a pleasure in the pathless woods;*\n>      *there is a rapture on the lonely shore;*\n>      *there is society, where none intrudes,*\n>      *by the deep sea, and music in its roar;*\n>      *I love not man the less, but nature more...*\n>                           *by George Gordon Byron* \n\n","source":"about/index.md","raw":"---\ntitle: about\ndate: 2021-12-12 21:52:49\n---\n\n\n\nI received the B.S. degree in the School of Engineering and Technology, China University of Geosciences (Beijing) in 2015. I am currently working towards the Ph.D degree in the Beijing Key Laboratory of Work Safety Intelligent Monitoring, the Department of EE, BUPT.\n\nI major in deep learning, computer vision, natural language processing, and reinforcement learning.\n\nI am also interested in high performance computing.\n\n<br/>\n\n<br/>\n\n---\n\n<br/>\n\n<br/>\n\n>      *There is a pleasure in the pathless woods;*\n>      *there is a rapture on the lonely shore;*\n>      *there is society, where none intrudes,*\n>      *by the deep sea, and music in its roar;*\n>      *I love not man the less, but nature more...*\n>                           *by George Gordon Byron* \n\n","updated":"2021-12-17T03:47:39.031Z","path":"about/index.html","_id":"ckx9ug53y0000s4ulhyic5ndl","comments":1,"layout":"page","content":"<html><head></head><body><p>I received the B.S. degree in the School of Engineering and Technology, China University of Geosciences (Beijing) in 2015. I am currently working towards the Ph.D degree in the Beijing Key Laboratory of Work Safety Intelligent Monitoring, the Department of EE, BUPT.</p>\n<p>I major in deep learning, computer vision, natural language processing, and reinforcement learning.</p>\n<p>I am also interested in high performance computing.</p>\n<br>\n\n<br>\n\n<hr>\n<br>\n\n<br>\n\n<blockquote>\n<p>     <em>There is a pleasure in the pathless woods;</em><br>     <em>there is a rapture on the lonely shore;</em><br>     <em>there is society, where none intrudes,</em><br>     <em>by the deep sea, and music in its roar;</em><br>     <em>I love not man the less, but nature more</em><br>                          <em>by George Gordon Byron</em> </p>\n</blockquote>\n</body></html>","site":{"data":{}},"excerpt":"<html><head></head><body></body></html>","more":"<p>I received the B.S. degree in the School of Engineering and Technology, China University of Geosciences (Beijing) in 2015. I am currently working towards the Ph.D degree in the Beijing Key Laboratory of Work Safety Intelligent Monitoring, the Department of EE, BUPT.</p>\n<p>I major in deep learning, computer vision, natural language processing, and reinforcement learning.</p>\n<p>I am also interested in high performance computing.</p>\n<br/>\n\n<br/>\n\n<hr>\n<br/>\n\n<br/>\n\n<blockquote>\n<p>     <em>There is a pleasure in the pathless woods;</em><br>     <em>there is a rapture on the lonely shore;</em><br>     <em>there is society, where none intrudes,</em><br>     <em>by the deep sea, and music in its roar;</em><br>     <em>I love not man the less, but nature more</em><br>                          <em>by George Gordon Byron</em> </p>\n</blockquote>\n"},{"title":"categories","date":"2021-11-24T11:46:36.000Z","type":"categories","_content":"","source":"categories/index.md","raw":"---\ntitle: categories\ndate: 2021-11-24 19:46:36\ntype: \"categories\"\n---\n","updated":"2021-11-24T11:51:36.896Z","path":"categories/index.html","comments":1,"layout":"page","_id":"ckx9ug5440002s4ulbrq113f1","content":"<html><head></head><body></body></html>","site":{"data":{}},"excerpt":"<html><head></head><body></body></html>","more":""},{"title":"tags","date":"2021-12-08T06:48:06.000Z","type":"tags","_content":"","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2021-12-08 14:48:06\ntype: \"tags\"\n---\n","updated":"2021-12-08T06:48:39.840Z","path":"tags/index.html","comments":1,"layout":"page","_id":"ckx9ug5470006s4ul39gx4jdc","content":"<html><head></head><body></body></html>","site":{"data":{}},"excerpt":"<html><head></head><body></body></html>","more":""}],"Post":[{"title":"An Introduction to Git","date":"2021-12-10T13:55:33.000Z","description":"gitgit","summary":null,"_content":"\n\n\n\n\n\n\n![The Structure of Git](git.jpg)\n\ngit checkout\n\ngit ls-files\n\n--cached (-c) \n\n--midified (-m)\n\n--delete (-d)\n\n--other (-o)git\n\n","source":"_posts/An-Introduction-to-Git.md","raw":"---\ntitle: An Introduction to Git\ndate: 2021-12-10 21:55:33\ndescription: gitgit\nsummary:\ncategories:\n- Little Things\n- Git\ntags:\n- Git\n---\n\n\n\n\n\n\n\n![The Structure of Git](git.jpg)\n\ngit checkout\n\ngit ls-files\n\n--cached (-c) \n\n--midified (-m)\n\n--delete (-d)\n\n--other (-o)git\n\n","slug":"An-Introduction-to-Git","published":1,"updated":"2021-12-15T02:32:12.881Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckx9ug5410001s4ulb3dt9ug2","content":"<html><head></head><body><p><img src=\"git.jpg\" alt=\"The Structure of Git\"></p>\n<p>git checkout</p>\n<p>git ls-files</p>\n<p>cached (-c) </p>\n<p>midified (-m)</p>\n<p>delete (-d)</p>\n<p>other (-o)git</p>\n</body></html>","site":{"data":{}},"excerpt":"<html><head></head><body></body></html>","more":"<p><img src=\"git.jpg\" alt=\"The Structure of Git\"></p>\n<p>git checkout</p>\n<p>git ls-files</p>\n<p>cached (-c) </p>\n<p>midified (-m)</p>\n<p>delete (-d)</p>\n<p>other (-o)git</p>\n"},{"title":"Construct Your Blog with Hexo and Github","date":"2021-11-24T08:20:43.000Z","description":"Hexo, Next","_content":"\n\n# \n\nhttps://segmentfault.com/a/1190000017986794\n\nhttps://godweiyang.com/2018/04/13/hexo-blog/\n\nhttps://blog.guaoxiaohei.com/posts/Hexo-Level/\n\nhttps://www.itfanr.cc/2021/04/16/hexo-blog-article-encryption/\n\nhttps://www.zhangxinxu.com/wordpress/2021/05/css-html-hr/\n\n# \n\n## hexo d GitHub\n\n_config.yml\n\n\n\nurl: github,  https://xyegithub.github.io/myBlog/\n\nroot: url/myBlog/\n\nhexo clean; hexo g; hexo d\n\n##  git\n\n\n\nhttps://juejin.cn/post/6844904193170341896\n\ndnscmd ipconfig /flushdns\n\n\n\n### \n\nhexo _config.ymlgit`https://github.com/xxx`ssh `git@github.com:xxx/xxx`\n\n## github page \n\n\n\nhttps://mizeri.github.io/2021/04/18/hexo-sitemap-google/\n","source":"_posts/Construct-Your-Blog-with-Hexo-and-Github.md","raw":"---\ntitle: Construct Your Blog with Hexo and Github\ndate: 2021-11-24 16:20:43\ndescription:  Hexo, Next\ntags: \n- Hexo\ncategories:\n- Little Things\n- Hexo\n---\n\n\n# \n\nhttps://segmentfault.com/a/1190000017986794\n\nhttps://godweiyang.com/2018/04/13/hexo-blog/\n\nhttps://blog.guaoxiaohei.com/posts/Hexo-Level/\n\nhttps://www.itfanr.cc/2021/04/16/hexo-blog-article-encryption/\n\nhttps://www.zhangxinxu.com/wordpress/2021/05/css-html-hr/\n\n# \n\n## hexo d GitHub\n\n_config.yml\n\n\n\nurl: github,  https://xyegithub.github.io/myBlog/\n\nroot: url/myBlog/\n\nhexo clean; hexo g; hexo d\n\n##  git\n\n\n\nhttps://juejin.cn/post/6844904193170341896\n\ndnscmd ipconfig /flushdns\n\n\n\n### \n\nhexo _config.ymlgit`https://github.com/xxx`ssh `git@github.com:xxx/xxx`\n\n## github page \n\n\n\nhttps://mizeri.github.io/2021/04/18/hexo-sitemap-google/\n","slug":"Construct-Your-Blog-with-Hexo-and-Github","published":1,"updated":"2021-12-17T03:37:51.057Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckx9ug5440003s4ul1onaa3g6","content":"<html><head></head><body><h1 id=\"\"><span class=\"post-title-index\">1. </span><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p><a href=\"https://segmentfault.com/a/1190000017986794\">https://segmentfault.com/a/1190000017986794</a></p>\n<p><a href=\"https://godweiyang.com/2018/04/13/hexo-blog/\">https://godweiyang.com/2018/04/13/hexo-blog/</a></p>\n<p><a href=\"https://blog.guaoxiaohei.com/posts/Hexo-Level/\">https://blog.guaoxiaohei.com/posts/Hexo-Level/</a></p>\n<p><a href=\"https://www.itfanr.cc/2021/04/16/hexo-blog-article-encryption/\">https://www.itfanr.cc/2021/04/16/hexo-blog-article-encryption/</a></p>\n<p><a href=\"https://www.zhangxinxu.com/wordpress/2021/05/css-html-hr/\">https://www.zhangxinxu.com/wordpress/2021/05/css-html-hr/</a></p>\n<h1 id=\"\"><span class=\"post-title-index\">2. </span><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><h2 id=\"hexo-d-GitHub\"><span class=\"post-title-index\">2.1. </span><a href=\"#hexo-d-GitHub\" class=\"headerlink\" title=\"hexo d GitHub\"></a>hexo d GitHub</h2><p>_config.yml</p>\n<p>url: github,  <a href=\"https://xyegithub.github.io/myBlog/\">https://xyegithub.github.io/myBlog/</a></p>\n<p>root: url/myBlog/</p>\n<p>hexo clean; hexo g; hexo d</p>\n<h2 id=\"git\"><span class=\"post-title-index\">2.2. </span><a href=\"#git\" class=\"headerlink\" title=\"git\"></a>git</h2><p></p>\n<p><a href=\"https://juejin.cn/post/6844904193170341896\">https://juejin.cn/post/6844904193170341896</a></p>\n<p>dnscmd ipconfig /flushdns</p>\n<p></p>\n<h3 id=\"\"><span class=\"post-title-index\">2.2.1. </span><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>hexo _config.ymlgit<code>https://github.com/xxx</code>ssh <code>git@github.com:xxx/xxx</code></p>\n<h2 id=\"github-page-\"><span class=\"post-title-index\">2.3. </span><a href=\"#github-page-\" class=\"headerlink\" title=\"github page \"></a>github page </h2><p></p>\n<p><a href=\"https://mizeri.github.io/2021/04/18/hexo-sitemap-google/\">https://mizeri.github.io/2021/04/18/hexo-sitemap-google/</a></p>\n</body></html>","site":{"data":{}},"excerpt":"<html><head></head><body></body></html>","more":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p><a href=\"https://segmentfault.com/a/1190000017986794\">https://segmentfault.com/a/1190000017986794</a></p>\n<p><a href=\"https://godweiyang.com/2018/04/13/hexo-blog/\">https://godweiyang.com/2018/04/13/hexo-blog/</a></p>\n<p><a href=\"https://blog.guaoxiaohei.com/posts/Hexo-Level/\">https://blog.guaoxiaohei.com/posts/Hexo-Level/</a></p>\n<p><a href=\"https://www.itfanr.cc/2021/04/16/hexo-blog-article-encryption/\">https://www.itfanr.cc/2021/04/16/hexo-blog-article-encryption/</a></p>\n<p><a href=\"https://www.zhangxinxu.com/wordpress/2021/05/css-html-hr/\">https://www.zhangxinxu.com/wordpress/2021/05/css-html-hr/</a></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><h2 id=\"hexo-d-GitHub\"><a href=\"#hexo-d-GitHub\" class=\"headerlink\" title=\"hexo d GitHub\"></a>hexo d GitHub</h2><p>_config.yml</p>\n<p>url: github,  <a href=\"https://xyegithub.github.io/myBlog/\">https://xyegithub.github.io/myBlog/</a></p>\n<p>root: url/myBlog/</p>\n<p>hexo clean; hexo g; hexo d</p>\n<h2 id=\"git\"><a href=\"#git\" class=\"headerlink\" title=\"git\"></a>git</h2><p></p>\n<p><a href=\"https://juejin.cn/post/6844904193170341896\">https://juejin.cn/post/6844904193170341896</a></p>\n<p>dnscmd ipconfig /flushdns</p>\n<p></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>hexo _config.ymlgit<code>https://github.com/xxx</code>ssh <code>git@github.com:xxx/xxx</code></p>\n<h2 id=\"github-page-\"><a href=\"#github-page-\" class=\"headerlink\" title=\"github page \"></a>github page </h2><p></p>\n<p><a href=\"https://mizeri.github.io/2021/04/18/hexo-sitemap-google/\">https://mizeri.github.io/2021/04/18/hexo-sitemap-google/</a></p>\n"},{"title":"Experiments","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-12-17T02:00:56.000Z","password":null,"summary":null,"description":"diy","_content":"\n\n\n# Deep Learning\n\n## Feature Map Multiplication\n\n","source":"_posts/Experiments.md","raw":"---\ntitle: Experiments\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-12-17 10:00:56\npassword:\nsummary:\ndescription: diy\ncategories:\n- Experiments\ntags:\n- Experiments\n- private\n---\n\n\n\n# Deep Learning\n\n## Feature Map Multiplication\n\n","slug":"Experiments","published":1,"updated":"2021-12-17T02:31:58.769Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckx9ug5480007s4ulebfkghcl","content":"<div class=\"hbe hbe-container\" id=\"hexo-blog-encrypt\" data-wpm=\"Oh, this is an invalid password. Check and try again, please.\" data-whm=\"OOPS, these decrypted content may changed, but you can still have a look.\">\n  <script id=\"hbeData\" type=\"hbeData\" data-hmacdigest=\"075e2d16ba5601ab2aba9cc33cb0018dfe235a1708d2462411df17be42633158\">66852511a631ad87fd1101c971fa7f213c692e7d123cbcb307d59697d2f247f74c8510b10e447ea1d6daedc6fc12b2ef7f32f31e415ac05f297fe4455393de8a9ceb688f2e5e97feaecbd24dbd75a6e2fd785d9fe55e889f419a83c1161cdd244ce01220e168b811b5a710c6afbbe94f48a1d53423306485f53605729b5bc879da18de859ded9d87d3ff5b8af4d0dca524e80a7754fed480abd57f022b0f813bf1f6d766c69a02180d8ef49ae9f7f711c435b773a99c55da93947e13852dad075e5826c18ea8597ea0d5eb11964ef70dcdeb6676816aaa36a72e56c8484de43e2d82804f6e1c3e9477d2b70b2f4d441a22960e3a8cd5efee4b5e1c7248b316e238af49f7f6558e0354b3b186512ab8800006c60aee6730500f4687c208e0af232a9b3ea302adceb3f13c006e884f4ef33b861cd59390e514bcb7626b5bba10c262fc6b055a1628a09ae4c859e952a4174f280b44af6271e4a0c13224b7e2c398f1200abd48195b968646c78da79793888ca3b171e0980e6a4254e49efc5e16063a69712778191ef3e73fc10aaf61e933cb7794ba7747c53b3c8e0c307032602f0fea1f6831cd02a0db7e87ad97192178</script>\n  <div class=\"hbe hbe-content\">\n    <div class=\"hbe hbe-input hbe-input-default\">\n      <input class=\"hbe hbe-input-field hbe-input-field-default\" type=\"password\" id=\"hbePass\">\n      <label class=\"hbe hbe-input-label hbe-input-label-default\" for=\"hbePass\">\n        <span class=\"hbe hbe-input-label-content hbe-input-label-content-default\">Hey, password is required here.</span>\n      </label>\n    </div>\n  </div>\n</div>\n<script data-pjax src=\"/myBlog/lib/hbe.js\"></script><link href=\"/myBlog/css/hbe.style.css\" rel=\"stylesheet\" type=\"text/css\">","site":{"data":{}},"excerpt":"","more":"","origin":"<html><head></head><body><h1 id=\"Deep-Learning\"><span class=\"post-title-index\">1. </span><a href=\"#Deep-Learning\" class=\"headerlink\" title=\"Deep Learning\"></a>Deep Learning</h1><h2 id=\"Feature-Map-Multiplication\"><span class=\"post-title-index\">1.1. </span><a href=\"#Feature-Map-Multiplication\" class=\"headerlink\" title=\"Feature Map Multiplication\"></a>Feature Map Multiplication</h2></body></html>","encrypt":true},{"title":"Personal Thought","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-12-15T08:01:28.000Z","password":null,"summary":null,"description":"","_content":"\n\n\n# Deep Learning\n\n## \n\n\n\ni.e.\n\n\n\nA1A1\n\nmixup\n\n\n\n\n\n**MNIST, CIFAR-10100%**\n\n\n\n\n\n## \n\nResNet\n\n```python\nshortcut(x) + out\n# \nshortcut(x) * out\n```\n\n****\n\n1.  CNN\n2. ResNet3Dmaskattention module\n\n### \n\nCifar-100Cifar-10\n\n### \n\n\n\n1. \n2. \n\n\n\n\n\n1. bn``bn(shortcut(x)) * bn(out)``\n\n2. bnbias1bn(shortcut(x))bn(out)1 \n\n    **1. shortcut(x) + outshortcut(x)1out1**\n\n   **2. out 0shorcut**\n\n### sigmoid\n\n3. attentionsigmoid``bn(shortcut(x)) * out.sigmoid()``sigmoid sigmoid\n4. soft attentionsigmoid1.  2. 2d1dSE-Netattentionattention\n\n\n\n","source":"_posts/Personal-Thought.md","raw":"---\ntitle: Personal Thought\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-12-15 16:01:28\npassword:\nsummary:\ndescription: \ncategories:\n- About Papers\ntags:\n- Personal Thought\n- Papers\n- private\n---\n\n\n\n# Deep Learning\n\n## \n\n\n\ni.e.\n\n\n\nA1A1\n\nmixup\n\n\n\n\n\n**MNIST, CIFAR-10100%**\n\n\n\n\n\n## \n\nResNet\n\n```python\nshortcut(x) + out\n# \nshortcut(x) * out\n```\n\n****\n\n1.  CNN\n2. ResNet3Dmaskattention module\n\n### \n\nCifar-100Cifar-10\n\n### \n\n\n\n1. \n2. \n\n\n\n\n\n1. bn``bn(shortcut(x)) * bn(out)``\n\n2. bnbias1bn(shortcut(x))bn(out)1 \n\n    **1. shortcut(x) + outshortcut(x)1out1**\n\n   **2. out 0shorcut**\n\n### sigmoid\n\n3. attentionsigmoid``bn(shortcut(x)) * out.sigmoid()``sigmoid sigmoid\n4. soft attentionsigmoid1.  2. 2d1dSE-Netattentionattention\n\n\n\n","slug":"Personal-Thought","published":1,"updated":"2021-12-17T02:32:34.369Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckx9ug5490008s4ulfri8862d","content":"<div class=\"hbe hbe-container\" id=\"hexo-blog-encrypt\" data-wpm=\"Oh, this is an invalid password. Check and try again, please.\" data-whm=\"OOPS, these decrypted content may changed, but you can still have a look.\">\n  <script id=\"hbeData\" type=\"hbeData\" data-hmacdigest=\"95f39f1dc2fa4ae5b04afa17449ca16c1c53bcbfef5f0dd5c60fc56892627fbe\">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</script>\n  <div class=\"hbe hbe-content\">\n    <div class=\"hbe hbe-input hbe-input-default\">\n      <input class=\"hbe hbe-input-field hbe-input-field-default\" type=\"password\" id=\"hbePass\">\n      <label class=\"hbe hbe-input-label hbe-input-label-default\" for=\"hbePass\">\n        <span class=\"hbe hbe-input-label-content hbe-input-label-content-default\">Hey, password is required here.</span>\n      </label>\n    </div>\n  </div>\n</div>\n<script data-pjax src=\"/myBlog/lib/hbe.js\"></script><link href=\"/myBlog/css/hbe.style.css\" rel=\"stylesheet\" type=\"text/css\">","site":{"data":{}},"excerpt":"","more":"","origin":"<html><head></head><body><h1 id=\"Deep-Learning\"><span class=\"post-title-index\">1. </span><a href=\"#Deep-Learning\" class=\"headerlink\" title=\"Deep Learning\"></a>Deep Learning</h1><h2 id=\"\"><span class=\"post-title-index\">1.1. </span><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<p>i.e.</p>\n<p></p>\n<p>A1A1</p>\n<p>mixup</p>\n<p></p>\n<p></p>\n<p><strong>MNIST, CIFAR-10100%</strong></p>\n<p></p>\n<h2 id=\"\"><span class=\"post-title-index\">1.2. </span><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>ResNet</p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">shortcut(x) + out</span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\">shortcut(x) * out</span><br></pre></td></tr></tbody></table></figure>\n\n<p><strong></strong></p>\n<ol>\n<li> CNN</li>\n<li>ResNet3Dmaskattention module</li>\n</ol>\n<h3 id=\"\"><span class=\"post-title-index\">1.2.1. </span><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>Cifar-100Cifar-10</p>\n<h3 id=\"\"><span class=\"post-title-index\">1.2.2. </span><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<ol>\n<li></li>\n<li></li>\n</ol>\n<p></p>\n<p></p>\n<ol>\n<li><p>bn<code>bn(shortcut(x)) * bn(out)</code></p>\n</li>\n<li><p>bnbias1bn(shortcut(x))bn(out)1 </p>\n<p> <strong>1. shortcut(x) + outshortcut(x)1out1</strong></p>\n<p><strong>2. out 0shorcut</strong></p>\n</li>\n</ol>\n<h3 id=\"sigmoid\"><span class=\"post-title-index\">1.2.3. </span><a href=\"#sigmoid\" class=\"headerlink\" title=\"sigmoid\"></a>sigmoid</h3><ol start=\"3\">\n<li>attentionsigmoid<code>bn(shortcut(x)) * out.sigmoid()</code>sigmoid sigmoid</li>\n<li>soft attentionsigmoid1.  2. 2d1dSE-Netattentionattention</li>\n</ol>\n</body></html>","encrypt":true},{"title":"First Step to Reinforcement Learning","date":"2021-12-03T08:48:41.000Z","description":"(Policy Network)(Value Network)","_content":"\n\n\n# \n\n<font color=green size=3></font>\n\n<font color=green size=3></font>\n\n<font color=green size=3></font>\n\n\n\n* S\n* A\n* \n* \n* \n* /\n\n## \n\n****\n\n1\n\n2 agent\n\n<font color=red> agent</font>\n\n\n\n\n\n<font color=red>label</font>\n\n\n\n \n\n## \n\n\n\n## \n\n\n\n\n\n\n\n## \n\n\n\n\n\n\n\n<font color=green></font>\n\n## \n\n1. targetActionPS. targetAction\n\n2. lossloss\n\n   0.1\n\n3. 2\n\n4. ActionActionrewardreward\n\n   ActionrewardActionreward\n\n   <font color=green>Actionrewardreward</font>\n\n5. \n\n   \n\n\n\n\n\n**<font color=green>Actionadvatagereward</font>**\n\n## \n\n\n\nActionscore = 0.1 score\n\n\n\nreward\n\n**<font color=green>actionaction ActionrewardActionactionrewardActionActionAction(reward)</font>**\n\nrewardrewardActionrewardAction\n\n\n\n**<font color=green>  rewardAction</font>**\n\n**<font color=green>rewardrewardrewardAction</font>**\n\n\n\n**<font color=green></font>**\n\n# (Policy Network)(Value Network)\n\nAlphaGo \n\n<font color=green></font>ActionActionAction.\n\n\n\n**Policy-based,Value-based**Actionq\n\n\n\n<font color=red>Action+Action</font>ActionActionAction\n\n<font color=green></font>\n\n<font color=green>Value BasedActionPolicy BasedActionActionPolicy BasedValue Based</font>\n\n## (Policy Network)\n\n[Policy_Network.py](https://github.com/xyegithub/myBlog/blob/main/2021/12/03/First-Step-to-RL/policy_network.py) [Policy_Network.py](policy_network.py)\n\n\n\n ```python\n score = tf.matmul(layer1,W2)\n probability = tf.nn.sigmoid(score)#Action 1\n input_y = tf.placeholder(tf.float32,[None,1], \\\\\n                          name=\"input_y\")# \n advantages = tf.placeholder(tf.float32,name=\"reward_signal\") \n # \n loglik = tf.log(input_y*(input_y - probability) + \\\\\n                 (1 - input_y)*(input_y + probability)) \n # 1\n \n # 00\n #\n loss = -tf.reduce_mean(loglik * advantages) # \n #advantages\n #advantages \n #\n \n #\n #\n \n ##  \n #Policy_Network.py ,\n #0.501\n #\n \n ## action\n # + \n \n ## n\n #actionadvantages\n \n ## \n #\n #\n ```\n\n---\n\n\n\n0.5Action\n\n### \n\n\n\n```python\n#xAction 1\ntfprob = sess.run(probability,feed_dict={observations: x})\n# \naction = 1 if np.random.uniform() < tfprob else 0\n```\n\n\n\n```python\n# \n# tfprob = sess.run(probability,feed_dict={observations: x})\n# 0.5\ntfprob = 0.5\naction = 1 if np.random.uniform() < tfprob else 0\n```\n\n\n\n\n\n actionactionaction\n\n\n\n\n\n## (Value NetworkQ-learning)\n\nQ-Learing\n\n[Value_Network.py](https://github.com/xyegithub/myBlog/blob/main/2021/12/03/First-Step-to-RL/policy_network.py)\n\nActionreward\n\n\n\n```python\n#Save the experience to our episode buffer.\nepisodeBuffer.add(np.reshape(np.array([s,a,r,s1,d]),[1,5]))\n# saActionrActionreward\n# s1Actiond  \n```\n\n1. Q(s<sub>t</sub>, a<sub>t</sub>)areward\n\n2. Q<sub>desird</sub>rewardQ<sub>desired</sub>(s<sub>t</sub>, a<sub>t</sub>) = r + $\\lambda$ Max<sub>a</sub> Q<sub>desired</sub>(s<sub>t+1</sub>, a)\n\n3.   Q<sub>desired</sub>\n\n   \n\n\n\n```python\n#Choose an action by greedily (with e chance of random action)\n# from the Q-network\nif np.random.rand(1) < e or total_steps < pre_train_steps:\n    a = np.random.randint(0,4)\nelse:\n    a = sess.run(mainQN.predict,feed_dict={mainQN.scalarInput:[s]})[0]\n# total_steps < pre_train_steps\n# total_steps >= pre_train_steps\n# e1-eAction \n# \n# epre_train_steps\n# Action\n# \n# Action\n# \n```\n\n**\"by greedily (with e chance of random action) from the Q-network\"**\n\n**<font color=green></font>**\n\n\n\n```python\nif total_steps > pre_train_steps:\n    if e > endE:\n        e -= stepDrop\n# \n# \n# \n# pass\n# endE=0.1 \n#\n```\n\n\n\n\n\n```python \nif total_steps % (update_freq) == 0:\n    trainBatch = myBuffer.sample(batch_size) #Get a random batch of experiences.\n    #Below we perform the Double-DQN update to the target Q-values\n    # ActiontrainBatch[:,3]\n    # Q(st, at) = r + $\\lambda$ Max Q(s_t+1, a)\n    # Actiont+1Action\n    Q1 = sess.run(mainQN.predict,feed_dict={mainQN.scalarInput:np.vstack(trainBatch[:,3])})\n    # targetreward\n    Q2 = sess.run(targetQN.Qout,feed_dict={targetQN.scalarInput:np.vstack(trainBatch[:,3])})\n    end_multiplier = -(trainBatch[:,4] - 1)\n    # Actiontargetreward\n    # reward, Max Q(s_t+1, a)\n    doubleQ = Q2[range(batch_size),Q1]\n    # Q(st, at) = r + $\\lambda$ Max Q(s_t+1, a)\n    # rewardreward\n    targetQ = trainBatch[:,2] + (y*doubleQ * end_multiplier)\n    #Update the network with our target values.\n    # \n    # \n    _ = sess.run(mainQN.updateModel, \\\n                 feed_dict={mainQN.scalarInput:np.vstack(trainBatch[:,0]),mainQN.targetQ:targetQ, mainQN.actions:trainBatch[:,1]})\n    # target\n    updateTarget(targetOps,sess) #Update the target network toward the primary network.\n```\n\n\n\ntarget\n\n```python \ndef updateTargetGraph(tfVars,tau):\n    total_vars = len(tfVars)\n    op_holder = [] \n    # target\n    for idx,var in enumerate(tfVars[0:total_vars//2]):\n        # idx+total_varstarget\n        # target =  * tau + 1- tau*target\n        # target\n        # target\n        # target\n        # targetActionrewardAction\n        # target\n        # target\n        # \n        op_holder.append(tfVars[idx+total_vars//2].assign\\\\\n                         ((var.value()*tau) \\\\\n                      + ((1-tau)*tfVars[idx+total_vars//2].value())))\n        return op_holder\n\n    def updateTarget(op_holder,sess):\n        for op in op_holder:\n            sess.run(op)\n\n```\n\nstate of the arttrick\n\n1. CNN\n2. Experience replayNN batchsizeN=1\n3. target**targetQ-Learing********DQNQQ**targettargettargetQ\n4. Double DQNtricktargetActionactiontargetreward\n5. Dueling DQN\n\n```python \nself.AW = tf.Variable(xavier_init([h_size//2,env.actions]))\nself.VW = tf.Variable(xavier_init([h_size//2,1]))\nself.Advantage = tf.matmul(self.streamA,self.AW)\nself.Value = tf.matmul(self.streamV,self.VW)\n\n#Then combine them together to get our final Q-values.\n# QoutActionrewardValueAdvantage\n# Valueadvantage#action\n# Dueling DQNrewardValue\n# ActionAction\n# \n#out\n# Action\n# \nself.Qout = self.Value + tf.subtract(self.Advantage,tf.reduce_mean(self.Advantage,axis=1,keep_dims=True))\n\n```\n\n## \n\nreward\n\n1. Action\n2. Actionreward\n3. \n4. ActionAction1ActionrewardAction**rewardreward**\n\n\n\n# \n\n\n\n\n\nsgd\n\n\n\n\n\n\n\n\n\nreward \n\nQ<sub>desired</sub>(s<sub>t</sub>, a<sub>t</sub>) = r + $\\lambda$ Max<sub>a</sub> Q<sub>desired</sub>(s<sub>t+1</sub>, a)\n\n\n\n\n\n```python \nif done:\n    episode_number += 1\n    epx = np.vstack(xs)\n    epy = np.vstack(ys)\n    epr = np.vstack(drs)\n    tfp = tfps\n    xs,hs,dlogps,drs,ys,tfps = [],[],[],[],[],[]\n\n    discounted_epr = discount_rewards(epr)\n    discounted_epr -= np.mean(discounted_epr)\n    discounted_epr //= np.std(discounted_epr)\n\n    tGrad = sess.run(newGrads,feed_dict={observations: epx, input_y: epy, advantages: discounted_epr})\n    for ix,grad in enumerate(tGrad):\n        gradBuffer[ix] += grad\n\n        if episode_number % batch_size == 0:\n            sess.run(updateGrads,feed_dict={W1Grad: gradBuffer[0],W1_1Grad:gradBuffer[1],W2Grad:gradBuffer[2]})\n```\n\n\n\n\n\n","source":"_posts/First-Step-to-RL.md","raw":"---\ntitle: First Step to Reinforcement Learning\ndate: 2021-12-03 16:48:41\ndescription: (Policy Network)(Value Network)\ntags:\n- Reinforcement Learning\ncategories:\n- Reinforcement Learning\n\n\n---\n\n\n\n# \n\n<font color=green size=3></font>\n\n<font color=green size=3></font>\n\n<font color=green size=3></font>\n\n\n\n* S\n* A\n* \n* \n* \n* /\n\n## \n\n****\n\n1\n\n2 agent\n\n<font color=red> agent</font>\n\n\n\n\n\n<font color=red>label</font>\n\n\n\n \n\n## \n\n\n\n## \n\n\n\n\n\n\n\n## \n\n\n\n\n\n\n\n<font color=green></font>\n\n## \n\n1. targetActionPS. targetAction\n\n2. lossloss\n\n   0.1\n\n3. 2\n\n4. ActionActionrewardreward\n\n   ActionrewardActionreward\n\n   <font color=green>Actionrewardreward</font>\n\n5. \n\n   \n\n\n\n\n\n**<font color=green>Actionadvatagereward</font>**\n\n## \n\n\n\nActionscore = 0.1 score\n\n\n\nreward\n\n**<font color=green>actionaction ActionrewardActionactionrewardActionActionAction(reward)</font>**\n\nrewardrewardActionrewardAction\n\n\n\n**<font color=green>  rewardAction</font>**\n\n**<font color=green>rewardrewardrewardAction</font>**\n\n\n\n**<font color=green></font>**\n\n# (Policy Network)(Value Network)\n\nAlphaGo \n\n<font color=green></font>ActionActionAction.\n\n\n\n**Policy-based,Value-based**Actionq\n\n\n\n<font color=red>Action+Action</font>ActionActionAction\n\n<font color=green></font>\n\n<font color=green>Value BasedActionPolicy BasedActionActionPolicy BasedValue Based</font>\n\n## (Policy Network)\n\n[Policy_Network.py](https://github.com/xyegithub/myBlog/blob/main/2021/12/03/First-Step-to-RL/policy_network.py) [Policy_Network.py](policy_network.py)\n\n\n\n ```python\n score = tf.matmul(layer1,W2)\n probability = tf.nn.sigmoid(score)#Action 1\n input_y = tf.placeholder(tf.float32,[None,1], \\\\\n                          name=\"input_y\")# \n advantages = tf.placeholder(tf.float32,name=\"reward_signal\") \n # \n loglik = tf.log(input_y*(input_y - probability) + \\\\\n                 (1 - input_y)*(input_y + probability)) \n # 1\n \n # 00\n #\n loss = -tf.reduce_mean(loglik * advantages) # \n #advantages\n #advantages \n #\n \n #\n #\n \n ##  \n #Policy_Network.py ,\n #0.501\n #\n \n ## action\n # + \n \n ## n\n #actionadvantages\n \n ## \n #\n #\n ```\n\n---\n\n\n\n0.5Action\n\n### \n\n\n\n```python\n#xAction 1\ntfprob = sess.run(probability,feed_dict={observations: x})\n# \naction = 1 if np.random.uniform() < tfprob else 0\n```\n\n\n\n```python\n# \n# tfprob = sess.run(probability,feed_dict={observations: x})\n# 0.5\ntfprob = 0.5\naction = 1 if np.random.uniform() < tfprob else 0\n```\n\n\n\n\n\n actionactionaction\n\n\n\n\n\n## (Value NetworkQ-learning)\n\nQ-Learing\n\n[Value_Network.py](https://github.com/xyegithub/myBlog/blob/main/2021/12/03/First-Step-to-RL/policy_network.py)\n\nActionreward\n\n\n\n```python\n#Save the experience to our episode buffer.\nepisodeBuffer.add(np.reshape(np.array([s,a,r,s1,d]),[1,5]))\n# saActionrActionreward\n# s1Actiond  \n```\n\n1. Q(s<sub>t</sub>, a<sub>t</sub>)areward\n\n2. Q<sub>desird</sub>rewardQ<sub>desired</sub>(s<sub>t</sub>, a<sub>t</sub>) = r + $\\lambda$ Max<sub>a</sub> Q<sub>desired</sub>(s<sub>t+1</sub>, a)\n\n3.   Q<sub>desired</sub>\n\n   \n\n\n\n```python\n#Choose an action by greedily (with e chance of random action)\n# from the Q-network\nif np.random.rand(1) < e or total_steps < pre_train_steps:\n    a = np.random.randint(0,4)\nelse:\n    a = sess.run(mainQN.predict,feed_dict={mainQN.scalarInput:[s]})[0]\n# total_steps < pre_train_steps\n# total_steps >= pre_train_steps\n# e1-eAction \n# \n# epre_train_steps\n# Action\n# \n# Action\n# \n```\n\n**\"by greedily (with e chance of random action) from the Q-network\"**\n\n**<font color=green></font>**\n\n\n\n```python\nif total_steps > pre_train_steps:\n    if e > endE:\n        e -= stepDrop\n# \n# \n# \n# pass\n# endE=0.1 \n#\n```\n\n\n\n\n\n```python \nif total_steps % (update_freq) == 0:\n    trainBatch = myBuffer.sample(batch_size) #Get a random batch of experiences.\n    #Below we perform the Double-DQN update to the target Q-values\n    # ActiontrainBatch[:,3]\n    # Q(st, at) = r + $\\lambda$ Max Q(s_t+1, a)\n    # Actiont+1Action\n    Q1 = sess.run(mainQN.predict,feed_dict={mainQN.scalarInput:np.vstack(trainBatch[:,3])})\n    # targetreward\n    Q2 = sess.run(targetQN.Qout,feed_dict={targetQN.scalarInput:np.vstack(trainBatch[:,3])})\n    end_multiplier = -(trainBatch[:,4] - 1)\n    # Actiontargetreward\n    # reward, Max Q(s_t+1, a)\n    doubleQ = Q2[range(batch_size),Q1]\n    # Q(st, at) = r + $\\lambda$ Max Q(s_t+1, a)\n    # rewardreward\n    targetQ = trainBatch[:,2] + (y*doubleQ * end_multiplier)\n    #Update the network with our target values.\n    # \n    # \n    _ = sess.run(mainQN.updateModel, \\\n                 feed_dict={mainQN.scalarInput:np.vstack(trainBatch[:,0]),mainQN.targetQ:targetQ, mainQN.actions:trainBatch[:,1]})\n    # target\n    updateTarget(targetOps,sess) #Update the target network toward the primary network.\n```\n\n\n\ntarget\n\n```python \ndef updateTargetGraph(tfVars,tau):\n    total_vars = len(tfVars)\n    op_holder = [] \n    # target\n    for idx,var in enumerate(tfVars[0:total_vars//2]):\n        # idx+total_varstarget\n        # target =  * tau + 1- tau*target\n        # target\n        # target\n        # target\n        # targetActionrewardAction\n        # target\n        # target\n        # \n        op_holder.append(tfVars[idx+total_vars//2].assign\\\\\n                         ((var.value()*tau) \\\\\n                      + ((1-tau)*tfVars[idx+total_vars//2].value())))\n        return op_holder\n\n    def updateTarget(op_holder,sess):\n        for op in op_holder:\n            sess.run(op)\n\n```\n\nstate of the arttrick\n\n1. CNN\n2. Experience replayNN batchsizeN=1\n3. target**targetQ-Learing********DQNQQ**targettargettargetQ\n4. Double DQNtricktargetActionactiontargetreward\n5. Dueling DQN\n\n```python \nself.AW = tf.Variable(xavier_init([h_size//2,env.actions]))\nself.VW = tf.Variable(xavier_init([h_size//2,1]))\nself.Advantage = tf.matmul(self.streamA,self.AW)\nself.Value = tf.matmul(self.streamV,self.VW)\n\n#Then combine them together to get our final Q-values.\n# QoutActionrewardValueAdvantage\n# Valueadvantage#action\n# Dueling DQNrewardValue\n# ActionAction\n# \n#out\n# Action\n# \nself.Qout = self.Value + tf.subtract(self.Advantage,tf.reduce_mean(self.Advantage,axis=1,keep_dims=True))\n\n```\n\n## \n\nreward\n\n1. Action\n2. Actionreward\n3. \n4. ActionAction1ActionrewardAction**rewardreward**\n\n\n\n# \n\n\n\n\n\nsgd\n\n\n\n\n\n\n\n\n\nreward \n\nQ<sub>desired</sub>(s<sub>t</sub>, a<sub>t</sub>) = r + $\\lambda$ Max<sub>a</sub> Q<sub>desired</sub>(s<sub>t+1</sub>, a)\n\n\n\n\n\n```python \nif done:\n    episode_number += 1\n    epx = np.vstack(xs)\n    epy = np.vstack(ys)\n    epr = np.vstack(drs)\n    tfp = tfps\n    xs,hs,dlogps,drs,ys,tfps = [],[],[],[],[],[]\n\n    discounted_epr = discount_rewards(epr)\n    discounted_epr -= np.mean(discounted_epr)\n    discounted_epr //= np.std(discounted_epr)\n\n    tGrad = sess.run(newGrads,feed_dict={observations: epx, input_y: epy, advantages: discounted_epr})\n    for ix,grad in enumerate(tGrad):\n        gradBuffer[ix] += grad\n\n        if episode_number % batch_size == 0:\n            sess.run(updateGrads,feed_dict={W1Grad: gradBuffer[0],W1_1Grad:gradBuffer[1],W2Grad:gradBuffer[2]})\n```\n\n\n\n\n\n","slug":"First-Step-to-RL","published":1,"updated":"2021-12-16T02:39:14.208Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckx9ug5490009s4ul0iucgf8q","content":"<html><head></head><body><h1 id=\"\"><span class=\"post-title-index\">1. </span><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p><font color=\"green\" size=\"3\"></font></p>\n<p><font color=\"green\" size=\"3\"></font></p>\n<p><font color=\"green\" size=\"3\"></font></p>\n<p></p>\n<ul>\n<li>S</li>\n<li>A</li>\n<li></li>\n<li></li>\n<li></li>\n<li>/</li>\n</ul>\n<h2 id=\"\"><span class=\"post-title-index\">1.1. </span><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><strong></strong></p>\n<p>1</p>\n<p>2 agent</p>\n<p><font color=\"red\"> agent</font></p>\n<p></p>\n<p></p>\n<p><font color=\"red\">label</font></p>\n<p></p>\n<p> </p>\n<h2 id=\"\"><span class=\"post-title-index\">1.2. </span><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<h2 id=\"\"><span class=\"post-title-index\">1.3. </span><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<p></p>\n<p></p>\n<h2 id=\"\"><span class=\"post-title-index\">1.4. </span><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<p></p>\n<p></p>\n<p><font color=\"green\"></font></p>\n<h2 id=\"\"><span class=\"post-title-index\">1.5. </span><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ol>\n<li><p>targetActionPS. targetAction</p>\n</li>\n<li><p>lossloss</p>\n<p>0.1</p>\n</li>\n<li><p>2</p>\n</li>\n<li><p>ActionActionrewardreward</p>\n<p>ActionrewardActionreward</p>\n<p><font color=\"green\">Actionrewardreward</font></p>\n</li>\n<li><p></p>\n</li>\n</ol>\n<p></p>\n<p></p>\n<p><strong><font color=\"green\">Actionadvatagereward</font></strong></p>\n<h2 id=\"\"><span class=\"post-title-index\">1.6. </span><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<p>Actionscore = 0.1 score</p>\n<p></p>\n<p>reward</p>\n<p><strong><font color=\"green\">actionaction ActionrewardActionactionrewardActionActionAction(reward)</font></strong></p>\n<p>rewardrewardActionrewardAction</p>\n<p></p>\n<p><strong><font color=\"green\">  rewardAction</font></strong></p>\n<p><strong><font color=\"green\">rewardrewardrewardAction</font></strong></p>\n<p></p>\n<p><strong><font color=\"green\"></font></strong></p>\n<h1 id=\"-Policy-Network--Value-Network\"><span class=\"post-title-index\">2. </span><a href=\"#-Policy-Network--Value-Network\" class=\"headerlink\" title=\"(Policy Network)(Value Network)\"></a>(Policy Network)(Value Network)</h1><p>AlphaGo </p>\n<p><font color=\"green\"></font>ActionActionAction.</p>\n<p></p>\n<p><strong>Policy-based,Value-based</strong>Actionq</p>\n<p></p>\n<p><font color=\"red\">Action+Action</font>ActionActionAction</p>\n<p><font color=\"green\"></font></p>\n<p><font color=\"green\">Value BasedActionPolicy BasedActionActionPolicy BasedValue Based</font></p>\n<h2 id=\"-Policy-Network\"><span class=\"post-title-index\">2.1. </span><a href=\"#-Policy-Network\" class=\"headerlink\" title=\"(Policy Network)\"></a>(Policy Network)</h2><p><a href=\"https://github.com/xyegithub/myBlog/blob/main/2021/12/03/First-Step-to-RL/policy_network.py\">Policy_Network.py</a> <a href=\"policy_network.py\">Policy_Network.py</a></p>\n<p></p>\n <figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">score = tf.matmul(layer1,W2)</span><br><span class=\"line\">probability = tf.nn.sigmoid(score)<span class=\"comment\">#Action 1</span></span><br><span class=\"line\">input_y = tf.placeholder(tf.float32,[<span class=\"literal\">None</span>,<span class=\"number\">1</span>], \\\\</span><br><span class=\"line\">                         name=<span class=\"string\">\"input_y\"</span>)<span class=\"comment\"># </span></span><br><span class=\"line\">advantages = tf.placeholder(tf.float32,name=<span class=\"string\">\"reward_signal\"</span>) </span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\">loglik = tf.log(input_y*(input_y - probability) + \\\\</span><br><span class=\"line\">                (<span class=\"number\">1</span> - input_y)*(input_y + probability)) </span><br><span class=\"line\"><span class=\"comment\"># 1</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 00</span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\">loss = -tf.reduce_mean(loglik * advantages) <span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"comment\">#advantages</span></span><br><span class=\"line\"><span class=\"comment\">#advantages </span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">##  </span></span><br><span class=\"line\"><span class=\"comment\">#Policy_Network.py ,</span></span><br><span class=\"line\"><span class=\"comment\">#0.501</span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## action</span></span><br><span class=\"line\"><span class=\"comment\"># + </span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## n</span></span><br><span class=\"line\"><span class=\"comment\">#actionadvantages</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## </span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br></pre></td></tr></tbody></table></figure>\n\n<p></p>\n<p></p>\n<p>0.5Action</p>\n<h3 id=\"\"><span class=\"post-title-index\">2.1.1. </span><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#xAction 1</span></span><br><span class=\"line\">tfprob = sess.run(probability,feed_dict={observations: x})</span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\">action = <span class=\"number\">1</span> <span class=\"keyword\">if</span> np.random.uniform() &lt; tfprob <span class=\"keyword\">else</span> <span class=\"number\">0</span></span><br></pre></td></tr></tbody></table></figure>\n\n<p></p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"comment\"># tfprob = sess.run(probability,feed_dict={observations: x})</span></span><br><span class=\"line\"><span class=\"comment\"># 0.5</span></span><br><span class=\"line\">tfprob = <span class=\"number\">0.5</span></span><br><span class=\"line\">action = <span class=\"number\">1</span> <span class=\"keyword\">if</span> np.random.uniform() &lt; tfprob <span class=\"keyword\">else</span> <span class=\"number\">0</span></span><br></pre></td></tr></tbody></table></figure>\n\n<p></p>\n<p></p>\n<p> actionactionaction</p>\n<p></p>\n<p></p>\n<h2 id=\"-Value-NetworkQ-learning\"><span class=\"post-title-index\">2.2. </span><a href=\"#-Value-NetworkQ-learning\" class=\"headerlink\" title=\"(Value NetworkQ-learning)\"></a>(Value NetworkQ-learning)</h2><p>Q-Learing</p>\n<p><a href=\"https://github.com/xyegithub/myBlog/blob/main/2021/12/03/First-Step-to-RL/policy_network.py\">Value_Network.py</a></p>\n<p>Actionreward</p>\n<p></p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#Save the experience to our episode buffer.</span></span><br><span class=\"line\">episodeBuffer.add(np.reshape(np.array([s,a,r,s1,d]),[<span class=\"number\">1</span>,<span class=\"number\">5</span>]))</span><br><span class=\"line\"><span class=\"comment\"># saActionrActionreward</span></span><br><span class=\"line\"><span class=\"comment\"># s1Actiond  </span></span><br></pre></td></tr></tbody></table></figure>\n\n<ol>\n<li><p>Q(s<sub>t</sub>, a<sub>t</sub>)areward</p>\n</li>\n<li><p>Q<sub>desird</sub>rewardQ<sub>desired</sub>(s<sub>t</sub>, a<sub>t</sub>) = r + $\\lambda$ Max<sub>a</sub> Q<sub>desired</sub>(s<sub>t+1</sub>, a)</p>\n</li>\n<li><p>  Q<sub>desired</sub></p>\n</li>\n</ol>\n<p></p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#Choose an action by greedily (with e chance of random action)</span></span><br><span class=\"line\"><span class=\"comment\"># from the Q-network</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> np.random.rand(<span class=\"number\">1</span>) &lt; e <span class=\"keyword\">or</span> total_steps &lt; pre_train_steps:</span><br><span class=\"line\">    a = np.random.randint(<span class=\"number\">0</span>,<span class=\"number\">4</span>)</span><br><span class=\"line\"><span class=\"keyword\">else</span>:</span><br><span class=\"line\">    a = sess.run(mainQN.predict,feed_dict={mainQN.scalarInput:[s]})[<span class=\"number\">0</span>]</span><br><span class=\"line\"><span class=\"comment\"># total_steps &lt; pre_train_steps</span></span><br><span class=\"line\"><span class=\"comment\"># total_steps &gt;= pre_train_steps</span></span><br><span class=\"line\"><span class=\"comment\"># e1-eAction </span></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"comment\"># epre_train_steps</span></span><br><span class=\"line\"><span class=\"comment\"># Action</span></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"comment\"># Action</span></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br></pre></td></tr></tbody></table></figure>\n\n<p><strong>by greedily (with e chance of random action) from the Q-network</strong></p>\n<p><strong><font color=\"green\"></font></strong></p>\n<p></p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> total_steps &gt; pre_train_steps:</span><br><span class=\"line\">    <span class=\"keyword\">if</span> e &gt; endE:</span><br><span class=\"line\">        e -= stepDrop</span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"comment\"># pass</span></span><br><span class=\"line\"><span class=\"comment\"># endE=0.1 </span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br></pre></td></tr></tbody></table></figure>\n\n\n\n<p></p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> total_steps % (update_freq) == <span class=\"number\">0</span>:</span><br><span class=\"line\">    trainBatch = myBuffer.sample(batch_size) <span class=\"comment\">#Get a random batch of experiences.</span></span><br><span class=\"line\">    <span class=\"comment\">#Below we perform the Double-DQN update to the target Q-values</span></span><br><span class=\"line\">    <span class=\"comment\"># ActiontrainBatch[:,3]</span></span><br><span class=\"line\">    <span class=\"comment\"># Q(st, at) = r + $\\lambda$ Max Q(s_t+1, a)</span></span><br><span class=\"line\">    <span class=\"comment\"># Actiont+1Action</span></span><br><span class=\"line\">    Q1 = sess.run(mainQN.predict,feed_dict={mainQN.scalarInput:np.vstack(trainBatch[:,<span class=\"number\">3</span>])})</span><br><span class=\"line\">    <span class=\"comment\"># targetreward</span></span><br><span class=\"line\">    Q2 = sess.run(targetQN.Qout,feed_dict={targetQN.scalarInput:np.vstack(trainBatch[:,<span class=\"number\">3</span>])})</span><br><span class=\"line\">    end_multiplier = -(trainBatch[:,<span class=\"number\">4</span>] - <span class=\"number\">1</span>)</span><br><span class=\"line\">    <span class=\"comment\"># Actiontargetreward</span></span><br><span class=\"line\">    <span class=\"comment\"># reward, Max Q(s_t+1, a)</span></span><br><span class=\"line\">    doubleQ = Q2[<span class=\"built_in\">range</span>(batch_size),Q1]</span><br><span class=\"line\">    <span class=\"comment\"># Q(st, at) = r + $\\lambda$ Max Q(s_t+1, a)</span></span><br><span class=\"line\">    <span class=\"comment\"># rewardreward</span></span><br><span class=\"line\">    targetQ = trainBatch[:,<span class=\"number\">2</span>] + (y*doubleQ * end_multiplier)</span><br><span class=\"line\">    <span class=\"comment\">#Update the network with our target values.</span></span><br><span class=\"line\">    <span class=\"comment\"># </span></span><br><span class=\"line\">    <span class=\"comment\"># </span></span><br><span class=\"line\">    _ = sess.run(mainQN.updateModel, \\</span><br><span class=\"line\">                 feed_dict={mainQN.scalarInput:np.vstack(trainBatch[:,<span class=\"number\">0</span>]),mainQN.targetQ:targetQ, mainQN.actions:trainBatch[:,<span class=\"number\">1</span>]})</span><br><span class=\"line\">    <span class=\"comment\"># target</span></span><br><span class=\"line\">    updateTarget(targetOps,sess) <span class=\"comment\">#Update the target network toward the primary network.</span></span><br></pre></td></tr></tbody></table></figure>\n\n\n\n<p>target</p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">updateTargetGraph</span>(<span class=\"params\">tfVars,tau</span>):</span></span><br><span class=\"line\">    total_vars = <span class=\"built_in\">len</span>(tfVars)</span><br><span class=\"line\">    op_holder = [] </span><br><span class=\"line\">    <span class=\"comment\"># target</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> idx,var <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(tfVars[<span class=\"number\">0</span>:total_vars//<span class=\"number\">2</span>]):</span><br><span class=\"line\">        <span class=\"comment\"># idx+total_varstarget</span></span><br><span class=\"line\">        <span class=\"comment\"># target =  * tau + 1- tau*target</span></span><br><span class=\"line\">        <span class=\"comment\"># target</span></span><br><span class=\"line\">        <span class=\"comment\"># target</span></span><br><span class=\"line\">        <span class=\"comment\"># target</span></span><br><span class=\"line\">        <span class=\"comment\"># targetActionrewardAction</span></span><br><span class=\"line\">        <span class=\"comment\"># target</span></span><br><span class=\"line\">        <span class=\"comment\"># target</span></span><br><span class=\"line\">        <span class=\"comment\"># </span></span><br><span class=\"line\">        op_holder.append(tfVars[idx+total_vars//<span class=\"number\">2</span>].assign\\\\</span><br><span class=\"line\">                         ((var.value()*tau) \\\\</span><br><span class=\"line\">                      + ((<span class=\"number\">1</span>-tau)*tfVars[idx+total_vars//<span class=\"number\">2</span>].value())))</span><br><span class=\"line\">        <span class=\"keyword\">return</span> op_holder</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">updateTarget</span>(<span class=\"params\">op_holder,sess</span>):</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> op <span class=\"keyword\">in</span> op_holder:</span><br><span class=\"line\">            sess.run(op)</span><br><span class=\"line\"></span><br></pre></td></tr></tbody></table></figure>\n\n<p>state of the arttrick</p>\n<ol>\n<li>CNN</li>\n<li>Experience replayNN batchsizeN=1</li>\n<li>target<strong>targetQ-Learing</strong><strong></strong><strong>DQNQQ</strong>targettargettargetQ</li>\n<li>Double DQNtricktargetActionactiontargetreward</li>\n<li>Dueling DQN</li>\n</ol>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">self.AW = tf.Variable(xavier_init([h_size//<span class=\"number\">2</span>,env.actions]))</span><br><span class=\"line\">self.VW = tf.Variable(xavier_init([h_size//<span class=\"number\">2</span>,<span class=\"number\">1</span>]))</span><br><span class=\"line\">self.Advantage = tf.matmul(self.streamA,self.AW)</span><br><span class=\"line\">self.Value = tf.matmul(self.streamV,self.VW)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#Then combine them together to get our final Q-values.</span></span><br><span class=\"line\"><span class=\"comment\"># QoutActionrewardValueAdvantage</span></span><br><span class=\"line\"><span class=\"comment\"># Valueadvantage#action</span></span><br><span class=\"line\"><span class=\"comment\"># Dueling DQNrewardValue</span></span><br><span class=\"line\"><span class=\"comment\"># ActionAction</span></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"comment\">#out</span></span><br><span class=\"line\"><span class=\"comment\"># Action</span></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\">self.Qout = self.Value + tf.subtract(self.Advantage,tf.reduce_mean(self.Advantage,axis=<span class=\"number\">1</span>,keep_dims=<span class=\"literal\">True</span>))</span><br><span class=\"line\"></span><br></pre></td></tr></tbody></table></figure>\n\n<h2 id=\"\"><span class=\"post-title-index\">2.3. </span><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>reward</p>\n<ol>\n<li>Action</li>\n<li>Actionreward</li>\n<li></li>\n<li>ActionAction1ActionrewardAction<strong>rewardreward</strong></li>\n</ol>\n<h1 id=\"\"><span class=\"post-title-index\">3. </span><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n<p></p>\n<p>sgd</p>\n<p></p>\n<p></p>\n<p>reward </p>\n<p>Q<sub>desired</sub>(s<sub>t</sub>, a<sub>t</sub>) = r + $\\lambda$ Max<sub>a</sub> Q<sub>desired</sub>(s<sub>t+1</sub>, a)</p>\n<p></p>\n<p></p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> done:</span><br><span class=\"line\">    episode_number += <span class=\"number\">1</span></span><br><span class=\"line\">    epx = np.vstack(xs)</span><br><span class=\"line\">    epy = np.vstack(ys)</span><br><span class=\"line\">    epr = np.vstack(drs)</span><br><span class=\"line\">    tfp = tfps</span><br><span class=\"line\">    xs,hs,dlogps,drs,ys,tfps = [],[],[],[],[],[]</span><br><span class=\"line\"></span><br><span class=\"line\">    discounted_epr = discount_rewards(epr)</span><br><span class=\"line\">    discounted_epr -= np.mean(discounted_epr)</span><br><span class=\"line\">    discounted_epr //= np.std(discounted_epr)</span><br><span class=\"line\"></span><br><span class=\"line\">    tGrad = sess.run(newGrads,feed_dict={observations: epx, input_y: epy, advantages: discounted_epr})</span><br><span class=\"line\">    <span class=\"keyword\">for</span> ix,grad <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(tGrad):</span><br><span class=\"line\">        gradBuffer[ix] += grad</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> episode_number % batch_size == <span class=\"number\">0</span>:</span><br><span class=\"line\">            sess.run(updateGrads,feed_dict={W1Grad: gradBuffer[<span class=\"number\">0</span>],W1_1Grad:gradBuffer[<span class=\"number\">1</span>],W2Grad:gradBuffer[<span class=\"number\">2</span>]})</span><br></pre></td></tr></tbody></table></figure>\n\n<p></p>\n</body></html>","site":{"data":{}},"excerpt":"<html><head></head><body></body></html>","more":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p><font color=green size=3></font></p>\n<p><font color=green size=3></font></p>\n<p><font color=green size=3></font></p>\n<p></p>\n<ul>\n<li>S</li>\n<li>A</li>\n<li></li>\n<li></li>\n<li></li>\n<li>/</li>\n</ul>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><strong></strong></p>\n<p>1</p>\n<p>2 agent</p>\n<p><font color=red> agent</font></p>\n<p></p>\n<p></p>\n<p><font color=red>label</font></p>\n<p></p>\n<p> </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<p></p>\n<p></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<p></p>\n<p></p>\n<p><font color=green></font></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ol>\n<li><p>targetActionPS. targetAction</p>\n</li>\n<li><p>lossloss</p>\n<p>0.1</p>\n</li>\n<li><p>2</p>\n</li>\n<li><p>ActionActionrewardreward</p>\n<p>ActionrewardActionreward</p>\n<p><font color=green>Actionrewardreward</font></p>\n</li>\n<li><p></p>\n</li>\n</ol>\n<p></p>\n<p></p>\n<p><strong><font color=green>Actionadvatagereward</font></strong></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<p>Actionscore = 0.1 score</p>\n<p></p>\n<p>reward</p>\n<p><strong><font color=green>actionaction ActionrewardActionactionrewardActionActionAction(reward)</font></strong></p>\n<p>rewardrewardActionrewardAction</p>\n<p></p>\n<p><strong><font color=green>  rewardAction</font></strong></p>\n<p><strong><font color=green>rewardrewardrewardAction</font></strong></p>\n<p></p>\n<p><strong><font color=green></font></strong></p>\n<h1 id=\"-Policy-Network--Value-Network\"><a href=\"#-Policy-Network--Value-Network\" class=\"headerlink\" title=\"(Policy Network)(Value Network)\"></a>(Policy Network)(Value Network)</h1><p>AlphaGo </p>\n<p><font color=green></font>ActionActionAction.</p>\n<p></p>\n<p><strong>Policy-based,Value-based</strong>Actionq</p>\n<p></p>\n<p><font color=red>Action+Action</font>ActionActionAction</p>\n<p><font color=green></font></p>\n<p><font color=green>Value BasedActionPolicy BasedActionActionPolicy BasedValue Based</font></p>\n<h2 id=\"-Policy-Network\"><a href=\"#-Policy-Network\" class=\"headerlink\" title=\"(Policy Network)\"></a>(Policy Network)</h2><p><a href=\"https://github.com/xyegithub/myBlog/blob/main/2021/12/03/First-Step-to-RL/policy_network.py\">Policy_Network.py</a> <a href=\"policy_network.py\">Policy_Network.py</a></p>\n<p></p>\n <figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">score = tf.matmul(layer1,W2)</span><br><span class=\"line\">probability = tf.nn.sigmoid(score)<span class=\"comment\">#Action 1</span></span><br><span class=\"line\">input_y = tf.placeholder(tf.float32,[<span class=\"literal\">None</span>,<span class=\"number\">1</span>], \\\\</span><br><span class=\"line\">                         name=<span class=\"string\">&quot;input_y&quot;</span>)<span class=\"comment\"># </span></span><br><span class=\"line\">advantages = tf.placeholder(tf.float32,name=<span class=\"string\">&quot;reward_signal&quot;</span>) </span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\">loglik = tf.log(input_y*(input_y - probability) + \\\\</span><br><span class=\"line\">                (<span class=\"number\">1</span> - input_y)*(input_y + probability)) </span><br><span class=\"line\"><span class=\"comment\"># 1</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 00</span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\">loss = -tf.reduce_mean(loglik * advantages) <span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"comment\">#advantages</span></span><br><span class=\"line\"><span class=\"comment\">#advantages </span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">##  </span></span><br><span class=\"line\"><span class=\"comment\">#Policy_Network.py ,</span></span><br><span class=\"line\"><span class=\"comment\">#0.501</span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## action</span></span><br><span class=\"line\"><span class=\"comment\"># + </span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## n</span></span><br><span class=\"line\"><span class=\"comment\">#actionadvantages</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## </span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br></pre></td></tr></table></figure>\n\n<p></p>\n<p></p>\n<p>0.5Action</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#xAction 1</span></span><br><span class=\"line\">tfprob = sess.run(probability,feed_dict=&#123;observations: x&#125;)</span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\">action = <span class=\"number\">1</span> <span class=\"keyword\">if</span> np.random.uniform() &lt; tfprob <span class=\"keyword\">else</span> <span class=\"number\">0</span></span><br></pre></td></tr></table></figure>\n\n<p></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"comment\"># tfprob = sess.run(probability,feed_dict=&#123;observations: x&#125;)</span></span><br><span class=\"line\"><span class=\"comment\"># 0.5</span></span><br><span class=\"line\">tfprob = <span class=\"number\">0.5</span></span><br><span class=\"line\">action = <span class=\"number\">1</span> <span class=\"keyword\">if</span> np.random.uniform() &lt; tfprob <span class=\"keyword\">else</span> <span class=\"number\">0</span></span><br></pre></td></tr></table></figure>\n\n<p></p>\n<p></p>\n<p> actionactionaction</p>\n<p></p>\n<p></p>\n<h2 id=\"-Value-NetworkQ-learning\"><a href=\"#-Value-NetworkQ-learning\" class=\"headerlink\" title=\"(Value NetworkQ-learning)\"></a>(Value NetworkQ-learning)</h2><p>Q-Learing</p>\n<p><a href=\"https://github.com/xyegithub/myBlog/blob/main/2021/12/03/First-Step-to-RL/policy_network.py\">Value_Network.py</a></p>\n<p>Actionreward</p>\n<p></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#Save the experience to our episode buffer.</span></span><br><span class=\"line\">episodeBuffer.add(np.reshape(np.array([s,a,r,s1,d]),[<span class=\"number\">1</span>,<span class=\"number\">5</span>]))</span><br><span class=\"line\"><span class=\"comment\"># saActionrActionreward</span></span><br><span class=\"line\"><span class=\"comment\"># s1Actiond  </span></span><br></pre></td></tr></table></figure>\n\n<ol>\n<li><p>Q(s<sub>t</sub>, a<sub>t</sub>)areward</p>\n</li>\n<li><p>Q<sub>desird</sub>rewardQ<sub>desired</sub>(s<sub>t</sub>, a<sub>t</sub>) = r + $\\lambda$ Max<sub>a</sub> Q<sub>desired</sub>(s<sub>t+1</sub>, a)</p>\n</li>\n<li><p>  Q<sub>desired</sub></p>\n</li>\n</ol>\n<p></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#Choose an action by greedily (with e chance of random action)</span></span><br><span class=\"line\"><span class=\"comment\"># from the Q-network</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> np.random.rand(<span class=\"number\">1</span>) &lt; e <span class=\"keyword\">or</span> total_steps &lt; pre_train_steps:</span><br><span class=\"line\">    a = np.random.randint(<span class=\"number\">0</span>,<span class=\"number\">4</span>)</span><br><span class=\"line\"><span class=\"keyword\">else</span>:</span><br><span class=\"line\">    a = sess.run(mainQN.predict,feed_dict=&#123;mainQN.scalarInput:[s]&#125;)[<span class=\"number\">0</span>]</span><br><span class=\"line\"><span class=\"comment\"># total_steps &lt; pre_train_steps</span></span><br><span class=\"line\"><span class=\"comment\"># total_steps &gt;= pre_train_steps</span></span><br><span class=\"line\"><span class=\"comment\"># e1-eAction </span></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"comment\"># epre_train_steps</span></span><br><span class=\"line\"><span class=\"comment\"># Action</span></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"comment\"># Action</span></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br></pre></td></tr></table></figure>\n\n<p><strong>by greedily (with e chance of random action) from the Q-network</strong></p>\n<p><strong><font color=green></font></strong></p>\n<p></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> total_steps &gt; pre_train_steps:</span><br><span class=\"line\">    <span class=\"keyword\">if</span> e &gt; endE:</span><br><span class=\"line\">        e -= stepDrop</span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"comment\"># pass</span></span><br><span class=\"line\"><span class=\"comment\"># endE=0.1 </span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br></pre></td></tr></table></figure>\n\n\n\n<p></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> total_steps % (update_freq) == <span class=\"number\">0</span>:</span><br><span class=\"line\">    trainBatch = myBuffer.sample(batch_size) <span class=\"comment\">#Get a random batch of experiences.</span></span><br><span class=\"line\">    <span class=\"comment\">#Below we perform the Double-DQN update to the target Q-values</span></span><br><span class=\"line\">    <span class=\"comment\"># ActiontrainBatch[:,3]</span></span><br><span class=\"line\">    <span class=\"comment\"># Q(st, at) = r + $\\lambda$ Max Q(s_t+1, a)</span></span><br><span class=\"line\">    <span class=\"comment\"># Actiont+1Action</span></span><br><span class=\"line\">    Q1 = sess.run(mainQN.predict,feed_dict=&#123;mainQN.scalarInput:np.vstack(trainBatch[:,<span class=\"number\">3</span>])&#125;)</span><br><span class=\"line\">    <span class=\"comment\"># targetreward</span></span><br><span class=\"line\">    Q2 = sess.run(targetQN.Qout,feed_dict=&#123;targetQN.scalarInput:np.vstack(trainBatch[:,<span class=\"number\">3</span>])&#125;)</span><br><span class=\"line\">    end_multiplier = -(trainBatch[:,<span class=\"number\">4</span>] - <span class=\"number\">1</span>)</span><br><span class=\"line\">    <span class=\"comment\"># Actiontargetreward</span></span><br><span class=\"line\">    <span class=\"comment\"># reward, Max Q(s_t+1, a)</span></span><br><span class=\"line\">    doubleQ = Q2[<span class=\"built_in\">range</span>(batch_size),Q1]</span><br><span class=\"line\">    <span class=\"comment\"># Q(st, at) = r + $\\lambda$ Max Q(s_t+1, a)</span></span><br><span class=\"line\">    <span class=\"comment\"># rewardreward</span></span><br><span class=\"line\">    targetQ = trainBatch[:,<span class=\"number\">2</span>] + (y*doubleQ * end_multiplier)</span><br><span class=\"line\">    <span class=\"comment\">#Update the network with our target values.</span></span><br><span class=\"line\">    <span class=\"comment\"># </span></span><br><span class=\"line\">    <span class=\"comment\"># </span></span><br><span class=\"line\">    _ = sess.run(mainQN.updateModel, \\</span><br><span class=\"line\">                 feed_dict=&#123;mainQN.scalarInput:np.vstack(trainBatch[:,<span class=\"number\">0</span>]),mainQN.targetQ:targetQ, mainQN.actions:trainBatch[:,<span class=\"number\">1</span>]&#125;)</span><br><span class=\"line\">    <span class=\"comment\"># target</span></span><br><span class=\"line\">    updateTarget(targetOps,sess) <span class=\"comment\">#Update the target network toward the primary network.</span></span><br></pre></td></tr></table></figure>\n\n\n\n<p>target</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">updateTargetGraph</span>(<span class=\"params\">tfVars,tau</span>):</span></span><br><span class=\"line\">    total_vars = <span class=\"built_in\">len</span>(tfVars)</span><br><span class=\"line\">    op_holder = [] </span><br><span class=\"line\">    <span class=\"comment\"># target</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> idx,var <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(tfVars[<span class=\"number\">0</span>:total_vars//<span class=\"number\">2</span>]):</span><br><span class=\"line\">        <span class=\"comment\"># idx+total_varstarget</span></span><br><span class=\"line\">        <span class=\"comment\"># target =  * tau + 1- tau*target</span></span><br><span class=\"line\">        <span class=\"comment\"># target</span></span><br><span class=\"line\">        <span class=\"comment\"># target</span></span><br><span class=\"line\">        <span class=\"comment\"># target</span></span><br><span class=\"line\">        <span class=\"comment\"># targetActionrewardAction</span></span><br><span class=\"line\">        <span class=\"comment\"># target</span></span><br><span class=\"line\">        <span class=\"comment\"># target</span></span><br><span class=\"line\">        <span class=\"comment\"># </span></span><br><span class=\"line\">        op_holder.append(tfVars[idx+total_vars//<span class=\"number\">2</span>].assign\\\\</span><br><span class=\"line\">                         ((var.value()*tau) \\\\</span><br><span class=\"line\">                      + ((<span class=\"number\">1</span>-tau)*tfVars[idx+total_vars//<span class=\"number\">2</span>].value())))</span><br><span class=\"line\">        <span class=\"keyword\">return</span> op_holder</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">updateTarget</span>(<span class=\"params\">op_holder,sess</span>):</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> op <span class=\"keyword\">in</span> op_holder:</span><br><span class=\"line\">            sess.run(op)</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>state of the arttrick</p>\n<ol>\n<li>CNN</li>\n<li>Experience replayNN batchsizeN=1</li>\n<li>target<strong>targetQ-Learing</strong><strong></strong><strong>DQNQQ</strong>targettargettargetQ</li>\n<li>Double DQNtricktargetActionactiontargetreward</li>\n<li>Dueling DQN</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">self.AW = tf.Variable(xavier_init([h_size//<span class=\"number\">2</span>,env.actions]))</span><br><span class=\"line\">self.VW = tf.Variable(xavier_init([h_size//<span class=\"number\">2</span>,<span class=\"number\">1</span>]))</span><br><span class=\"line\">self.Advantage = tf.matmul(self.streamA,self.AW)</span><br><span class=\"line\">self.Value = tf.matmul(self.streamV,self.VW)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#Then combine them together to get our final Q-values.</span></span><br><span class=\"line\"><span class=\"comment\"># QoutActionrewardValueAdvantage</span></span><br><span class=\"line\"><span class=\"comment\"># Valueadvantage#action</span></span><br><span class=\"line\"><span class=\"comment\"># Dueling DQNrewardValue</span></span><br><span class=\"line\"><span class=\"comment\"># ActionAction</span></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"comment\">#out</span></span><br><span class=\"line\"><span class=\"comment\"># Action</span></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\">self.Qout = self.Value + tf.subtract(self.Advantage,tf.reduce_mean(self.Advantage,axis=<span class=\"number\">1</span>,keep_dims=<span class=\"literal\">True</span>))</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>reward</p>\n<ol>\n<li>Action</li>\n<li>Actionreward</li>\n<li></li>\n<li>ActionAction1ActionrewardAction<strong>rewardreward</strong></li>\n</ol>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n<p></p>\n<p>sgd</p>\n<p></p>\n<p></p>\n<p>reward </p>\n<p>Q<sub>desired</sub>(s<sub>t</sub>, a<sub>t</sub>) = r + $\\lambda$ Max<sub>a</sub> Q<sub>desired</sub>(s<sub>t+1</sub>, a)</p>\n<p></p>\n<p></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> done:</span><br><span class=\"line\">    episode_number += <span class=\"number\">1</span></span><br><span class=\"line\">    epx = np.vstack(xs)</span><br><span class=\"line\">    epy = np.vstack(ys)</span><br><span class=\"line\">    epr = np.vstack(drs)</span><br><span class=\"line\">    tfp = tfps</span><br><span class=\"line\">    xs,hs,dlogps,drs,ys,tfps = [],[],[],[],[],[]</span><br><span class=\"line\"></span><br><span class=\"line\">    discounted_epr = discount_rewards(epr)</span><br><span class=\"line\">    discounted_epr -= np.mean(discounted_epr)</span><br><span class=\"line\">    discounted_epr //= np.std(discounted_epr)</span><br><span class=\"line\"></span><br><span class=\"line\">    tGrad = sess.run(newGrads,feed_dict=&#123;observations: epx, input_y: epy, advantages: discounted_epr&#125;)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> ix,grad <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(tGrad):</span><br><span class=\"line\">        gradBuffer[ix] += grad</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> episode_number % batch_size == <span class=\"number\">0</span>:</span><br><span class=\"line\">            sess.run(updateGrads,feed_dict=&#123;W1Grad: gradBuffer[<span class=\"number\">0</span>],W1_1Grad:gradBuffer[<span class=\"number\">1</span>],W2Grad:gradBuffer[<span class=\"number\">2</span>]&#125;)</span><br></pre></td></tr></table></figure>\n\n<p></p>\n"},{"title":"Tips in Papers","top":false,"cover":false,"toc":true,"mathjax":true,"date":"2021-12-14T08:33:03.000Z","password":null,"summary":null,"description":"","_content":"\n# Hard Attention\n\n## 2019 Scacader: Improving Accuracy of Hard Attention Models for Vision\n\n### Hard AttentionSoft Attention\n\nTypical soft attention mechanisms rescale features at one or more stages of the network. The soft mask used for rescaling often to provide some insight into the model's decision-making process, but the model's final decision may nonetheless rely on information provided by features with small weights [2018, Learn to pay attention.].\n\n### Hard AttentionHard Attention\n\nAltough our aim in this work is to perform classification with only image-level class labels, out approach bears some resembalance to two-stage object detection models. \n\nThese models operate by generating many region proposals and then applying a classification model to each proposal. \n\nUnlike our work, these approaches use ground-truth bounding boxes to train the classification model, and modern architectures also use bounding boxes to supervise the proposal generator.\n\n**Hard AttentionHard Attention, i.e., **\n\n# Regularization \n\n## ADCM: Attentnion Dropout Convolutional Module\n\n![ADCM](ADCM.jpg)\n\nCBAMCBAMattention weightsDropfeature mapdropattentionhard attention\n","source":"_posts/Tips-in-Papers.md","raw":"---\ntitle: Tips in Papers\ntop: false\ncover: false\ntoc: true\nmathjax: true\ndate: 2021-12-14 16:33:03\npassword:\nsummary:\ndescription: \ncategories:\n- About Papers\ntags:\n- Papers\n---\n\n# Hard Attention\n\n## 2019 Scacader: Improving Accuracy of Hard Attention Models for Vision\n\n### Hard AttentionSoft Attention\n\nTypical soft attention mechanisms rescale features at one or more stages of the network. The soft mask used for rescaling often to provide some insight into the model's decision-making process, but the model's final decision may nonetheless rely on information provided by features with small weights [2018, Learn to pay attention.].\n\n### Hard AttentionHard Attention\n\nAltough our aim in this work is to perform classification with only image-level class labels, out approach bears some resembalance to two-stage object detection models. \n\nThese models operate by generating many region proposals and then applying a classification model to each proposal. \n\nUnlike our work, these approaches use ground-truth bounding boxes to train the classification model, and modern architectures also use bounding boxes to supervise the proposal generator.\n\n**Hard AttentionHard Attention, i.e., **\n\n# Regularization \n\n## ADCM: Attentnion Dropout Convolutional Module\n\n![ADCM](ADCM.jpg)\n\nCBAMCBAMattention weightsDropfeature mapdropattentionhard attention\n","slug":"Tips-in-Papers","published":1,"updated":"2021-12-17T01:24:42.949Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckx9ug54c000ds4ulg62s5peb","content":"<html><head></head><body><h1 id=\"Hard-Attention\"><span class=\"post-title-index\">1. </span><a href=\"#Hard-Attention\" class=\"headerlink\" title=\"Hard Attention\"></a>Hard Attention</h1><h2 id=\"2019-Scacader-Improving-Accuracy-of-Hard-Attention-Models-for-Vision\"><span class=\"post-title-index\">1.1. </span><a href=\"#2019-Scacader-Improving-Accuracy-of-Hard-Attention-Models-for-Vision\" class=\"headerlink\" title=\"2019 Scacader: Improving Accuracy of Hard Attention Models for Vision\"></a>2019 Scacader: Improving Accuracy of Hard Attention Models for Vision</h2><h3 id=\"Hard-AttentionSoft-Attention\"><span class=\"post-title-index\">1.1.1. </span><a href=\"#Hard-AttentionSoft-Attention\" class=\"headerlink\" title=\"Hard AttentionSoft Attention\"></a>Hard AttentionSoft Attention</h3><p>Typical soft attention mechanisms rescale features at one or more stages of the network. The soft mask used for rescaling often to provide some insight into the models decision-making process, but the models final decision may nonetheless rely on information provided by features with small weights [2018, Learn to pay attention.].</p>\n<h3 id=\"Hard-AttentionHard-Attention\"><span class=\"post-title-index\">1.1.2. </span><a href=\"#Hard-AttentionHard-Attention\" class=\"headerlink\" title=\"Hard AttentionHard Attention\"></a>Hard AttentionHard Attention</h3><p>Altough our aim in this work is to perform classification with only image-level class labels, out approach bears some resembalance to two-stage object detection models. </p>\n<p>These models operate by generating many region proposals and then applying a classification model to each proposal. </p>\n<p>Unlike our work, these approaches use ground-truth bounding boxes to train the classification model, and modern architectures also use bounding boxes to supervise the proposal generator.</p>\n<p><strong>Hard AttentionHard Attention, i.e., </strong></p>\n<h1 id=\"Regularization\"><span class=\"post-title-index\">2. </span><a href=\"#Regularization\" class=\"headerlink\" title=\"Regularization\"></a>Regularization</h1><h2 id=\"ADCM-Attentnion-Dropout-Convolutional-Module\"><span class=\"post-title-index\">2.1. </span><a href=\"#ADCM-Attentnion-Dropout-Convolutional-Module\" class=\"headerlink\" title=\"ADCM: Attentnion Dropout Convolutional Module\"></a>ADCM: Attentnion Dropout Convolutional Module</h2><p><img src=\"ADCM.jpg\" alt=\"ADCM\"></p>\n<p>CBAMCBAMattention weightsDropfeature mapdropattentionhard attention</p>\n</body></html>","site":{"data":{}},"excerpt":"<html><head></head><body></body></html>","more":"<h1 id=\"Hard-Attention\"><a href=\"#Hard-Attention\" class=\"headerlink\" title=\"Hard Attention\"></a>Hard Attention</h1><h2 id=\"2019-Scacader-Improving-Accuracy-of-Hard-Attention-Models-for-Vision\"><a href=\"#2019-Scacader-Improving-Accuracy-of-Hard-Attention-Models-for-Vision\" class=\"headerlink\" title=\"2019 Scacader: Improving Accuracy of Hard Attention Models for Vision\"></a>2019 Scacader: Improving Accuracy of Hard Attention Models for Vision</h2><h3 id=\"Hard-AttentionSoft-Attention\"><a href=\"#Hard-AttentionSoft-Attention\" class=\"headerlink\" title=\"Hard AttentionSoft Attention\"></a>Hard AttentionSoft Attention</h3><p>Typical soft attention mechanisms rescale features at one or more stages of the network. The soft mask used for rescaling often to provide some insight into the models decision-making process, but the models final decision may nonetheless rely on information provided by features with small weights [2018, Learn to pay attention.].</p>\n<h3 id=\"Hard-AttentionHard-Attention\"><a href=\"#Hard-AttentionHard-Attention\" class=\"headerlink\" title=\"Hard AttentionHard Attention\"></a>Hard AttentionHard Attention</h3><p>Altough our aim in this work is to perform classification with only image-level class labels, out approach bears some resembalance to two-stage object detection models. </p>\n<p>These models operate by generating many region proposals and then applying a classification model to each proposal. </p>\n<p>Unlike our work, these approaches use ground-truth bounding boxes to train the classification model, and modern architectures also use bounding boxes to supervise the proposal generator.</p>\n<p><strong>Hard AttentionHard Attention, i.e., </strong></p>\n<h1 id=\"Regularization\"><a href=\"#Regularization\" class=\"headerlink\" title=\"Regularization\"></a>Regularization</h1><h2 id=\"ADCM-Attentnion-Dropout-Convolutional-Module\"><a href=\"#ADCM-Attentnion-Dropout-Convolutional-Module\" class=\"headerlink\" title=\"ADCM: Attentnion Dropout Convolutional Module\"></a>ADCM: Attentnion Dropout Convolutional Module</h2><p><img src=\"ADCM.jpg\" alt=\"ADCM\"></p>\n<p>CBAMCBAMattention weightsDropfeature mapdropattentionhard attention</p>\n"}],"PostAsset":[{"_id":"source/_posts/An-Introduction-to-Git/git.jpg","slug":"git.jpg","post":"ckx9ug5410001s4ulb3dt9ug2","modified":0,"renderable":0},{"_id":"source/_posts/First-Step-to-RL/policy_network.py","slug":"policy_network.py","post":"ckx9ug5490009s4ul0iucgf8q","modified":0,"renderable":0},{"_id":"source/_posts/First-Step-to-RL/q_learning.py","slug":"q_learning.py","post":"ckx9ug5490009s4ul0iucgf8q","modified":0,"renderable":0},{"_id":"source/_posts/Tips-in-Papers/ADCM.jpg","slug":"ADCM.jpg","post":"ckx9ug54c000ds4ulg62s5peb","modified":0,"renderable":0}],"PostCategory":[{"post_id":"ckx9ug5480007s4ulebfkghcl","category_id":"ckx9ug54c000es4ulfnopgd96","_id":"ckx9ug54e000js4ul5i69f0ea"},{"post_id":"ckx9ug5490008s4ulfri8862d","category_id":"ckx9ug54d000hs4ul6oem5esz","_id":"ckx9ug54f000ns4ul1nc15c5z"},{"post_id":"ckx9ug5410001s4ulb3dt9ug2","category_id":"ckx9ug5460004s4ul3b8the3i","_id":"ckx9ug54f000rs4ule0tcfb4s"},{"post_id":"ckx9ug5410001s4ulb3dt9ug2","category_id":"ckx9ug54e000ks4ul3dfcbxn3","_id":"ckx9ug54g000us4ulh3qsep31"},{"post_id":"ckx9ug5490009s4ul0iucgf8q","category_id":"ckx9ug54f000ps4ul6agz06ki","_id":"ckx9ug54g000ws4ul7b3w13oc"},{"post_id":"ckx9ug54c000ds4ulg62s5peb","category_id":"ckx9ug54d000hs4ul6oem5esz","_id":"ckx9ug54h000zs4ulaz8fh7fi"},{"post_id":"ckx9ug5440003s4ul1onaa3g6","category_id":"ckx9ug5460004s4ul3b8the3i","_id":"ckx9ug54h0014s4ul4pdo4296"},{"post_id":"ckx9ug5440003s4ul1onaa3g6","category_id":"ckx9ug54g000vs4ul9s3vgmfs","_id":"ckx9ug54h0015s4ul9zh3djao"}],"PostTag":[{"post_id":"ckx9ug5410001s4ulb3dt9ug2","tag_id":"ckx9ug5470005s4ul3apnd8n2","_id":"ckx9ug54b000cs4ul2rly6a4z"},{"post_id":"ckx9ug5440003s4ul1onaa3g6","tag_id":"ckx9ug54a000bs4ul83xy3laz","_id":"ckx9ug54d000gs4ul1whv4zc5"},{"post_id":"ckx9ug5480007s4ulebfkghcl","tag_id":"ckx9ug54d000fs4ul7e69g57l","_id":"ckx9ug54f000ms4ulfhpq5arj"},{"post_id":"ckx9ug5480007s4ulebfkghcl","tag_id":"ckx9ug54e000is4ul94aoei3b","_id":"ckx9ug54f000os4uleyb3efix"},{"post_id":"ckx9ug5490008s4ulfri8862d","tag_id":"ckx9ug54e000ls4ulbt9s54rs","_id":"ckx9ug54h000ys4ulcvr30ueh"},{"post_id":"ckx9ug5490008s4ulfri8862d","tag_id":"ckx9ug54f000qs4ulbwemcgh4","_id":"ckx9ug54h0010s4ul618wedf8"},{"post_id":"ckx9ug5490008s4ulfri8862d","tag_id":"ckx9ug54e000is4ul94aoei3b","_id":"ckx9ug54h0012s4ulet2n3r6g"},{"post_id":"ckx9ug5490009s4ul0iucgf8q","tag_id":"ckx9ug54g000xs4ul575b6tun","_id":"ckx9ug54h0013s4ul76wtag0i"},{"post_id":"ckx9ug54c000ds4ulg62s5peb","tag_id":"ckx9ug54f000qs4ulbwemcgh4","_id":"ckx9ug54h0016s4ulf1ot5o8l"}],"Tag":[{"name":"Git","_id":"ckx9ug5470005s4ul3apnd8n2"},{"name":"Hexo","_id":"ckx9ug54a000bs4ul83xy3laz"},{"name":"Experiments","_id":"ckx9ug54d000fs4ul7e69g57l"},{"name":"private","_id":"ckx9ug54e000is4ul94aoei3b"},{"name":"Personal Thought","_id":"ckx9ug54e000ls4ulbt9s54rs"},{"name":"Papers","_id":"ckx9ug54f000qs4ulbwemcgh4"},{"name":"Reinforcement Learning","_id":"ckx9ug54g000xs4ul575b6tun"}]}}